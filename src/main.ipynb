{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Core Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Despite a lot of creeping Physics and Chemistry knowledge introduced in the description, this competition is more about Geometry and pattern matching.\n",
    "\n",
    "The hypothesis of this kernel is next:\n",
    "1. If we have two similar sets of atoms with the same distances between them and the same types - the scalar coupling constant should be very close.\n",
    "2. More closest atoms to the pair of atoms under prediction have higher influence on scalar coupling constant then those with higher distance\n",
    "\n",
    "So, basically, this problem could be dealt with some kind of K-Nearest Neighbor algorithm or any tree-based - e.g. LightGBM, in case we can find some representation which would describe similar configurations with similar feature sets.\n",
    "\n",
    "Each atom is described with 3 cartesian coordinates. This representation is not stable. Each coupling pair is located in a different point in space and two similar coupling sets would have very different X,Y,Z.\n",
    "\n",
    "So, instead of using coordinates let's consider next system:\n",
    "1. Take each pair of atoms as two first core atoms\n",
    "2. Calculate the center between the pair\n",
    "3. Find all n-nearest atoms to the center (excluding first two atoms)\n",
    "4. Take two closest atoms from step 3 - they will be 3rd and 4th core atoms\n",
    "5. Calculate the distances from 4 core atoms to the rest of the atoms and to the core atoms as well\n",
    "\n",
    "Using this representation each atom position can be described by 4 distances from the core atoms. This representation is stable to rotation and translation. And it's suitable for pattern-matching. So, we can take a sequence of atoms, describe each by 4 distances + atom type(H,O,etc) and looking up for the same pattern we can find similar configurations and detect scalar coupling constant.\n",
    "\n",
    "Here I used LightGBM, because sklearn KNN can't deal with the amount of data. My blind guess is that hand-crafted KNN can outperform LightGBM.\n",
    "\n",
    "Let's code the solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import modules, set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import os\n",
    "# os.listdir('../input/imputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '..\\\\input'\n",
    "SUBMISSIONS_PATH = '..\\\\output'\n",
    "# use atomic numbers to recode atomic names\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all data is read as `float64` and `int64`. We can trade this uneeded precision for memory and higher prediction speed. So, let's read with Pandas all the data in the minimal representation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    molecule_index  atom_index_0  atom_index_1  type  scalar_coupling_constant\n",
       "id                                                                            \n",
       "0   1               1             0             1JHC  84.807602               \n",
       "1   1               1             2             2JHH -11.257000               \n",
       "2   1               1             3             2JHH -11.254800               \n",
       "3   1               1             4             2JHH -11.254300               \n",
       "4   1               2             0             1JHC  84.807404               \n",
       "5   1               2             3             2JHH -11.254100               \n",
       "6   1               2             4             2JHH -11.254800               \n",
       "7   1               3             0             1JHC  84.809303               \n",
       "8   1               3             4             2JHH -11.254300               \n",
       "9   1               4             0             1JHC  84.809502               "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index_0': 'int8',\n",
    "    'atom_index_1': 'int8',\n",
    "    'type': 'category',\n",
    "    'scalar_coupling_constant': 'float32'\n",
    "}\n",
    "train_csv = pd.read_csv(f'{DATA_PATH}\\\\train.csv', index_col='id', dtype=train_dtypes)\n",
    "train_csv['molecule_index'] = train_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train_csv = train_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type', 'scalar_coupling_constant']]\n",
    "train_csv.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_csv, _ = train_test_split(train_csv, test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_CSV Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.658147e+06</td>\n",
       "      <td>4.658147e+06</td>\n",
       "      <td>4.658147e+06</td>\n",
       "      <td>4.658147e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.915783e+04</td>\n",
       "      <td>1.335689e+01</td>\n",
       "      <td>5.883966e+00</td>\n",
       "      <td>1.589904e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.661127e+04</td>\n",
       "      <td>3.267712e+00</td>\n",
       "      <td>4.993943e+00</td>\n",
       "      <td>3.477050e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-3.621860e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.900200e+04</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>-2.549780e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.160900e+04</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>2.281130e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.008060e+05</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>7.390655e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.338840e+05</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>2.048800e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       molecule_index  atom_index_0  atom_index_1  scalar_coupling_constant\n",
       "count  4.658147e+06    4.658147e+06  4.658147e+06  4.658147e+06            \n",
       "mean   6.915783e+04    1.335689e+01  5.883966e+00  1.589904e+01            \n",
       "std    3.661127e+04    3.267712e+00  4.993943e+00  3.477050e+01            \n",
       "min    1.000000e+00    0.000000e+00  0.000000e+00 -3.621860e+01            \n",
       "25%    3.900200e+04    1.100000e+01  2.000000e+00 -2.549780e-01            \n",
       "50%    7.160900e+04    1.300000e+01  5.000000e+00  2.281130e+00            \n",
       "75%    1.008060e+05    1.600000e+01  8.000000e+00  7.390655e+00            \n",
       "max    1.338840e+05    2.800000e+01  2.800000e+01  2.048800e+02            "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (4658147, 5)\n",
      "Total:  88505177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                       37265176\n",
       "molecule_index              18632588\n",
       "atom_index_0                4658147 \n",
       "atom_index_1                4658147 \n",
       "type                        4658531 \n",
       "scalar_coupling_constant    18632588\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', train_csv.shape)\n",
    "print('Total: ', train_csv.memory_usage().sum())\n",
    "train_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "submission_csv = pd.read_csv(f'{DATA_PATH}\\\\sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         molecule_index  atom_index_0  atom_index_1  type\n",
       "id                                                       \n",
       "4658147  4               2             0             2JHC\n",
       "4658148  4               2             1             1JHC\n",
       "4658149  4               2             3             3JHH\n",
       "4658150  4               3             0             1JHC\n",
       "4658151  4               3             1             2JHC\n",
       "4658152  15              3             0             1JHC\n",
       "4658153  15              3             2             3JHC\n",
       "4658154  15              3             4             2JHH\n",
       "4658155  15              3             5             2JHH\n",
       "4658156  15              4             0             1JHC"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(f'{DATA_PATH}\\\\test.csv', index_col='id', dtype=train_dtypes)\n",
    "test_csv['molecule_index'] = test_csv['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test_csv = test_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type']]\n",
    "test_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>-0.028758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>-0.775543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molecule_index  atom_index  atom         x         y         z\n",
       "0  1               0           6    -0.012698  1.085804  0.008001\n",
       "1  1               1           1     0.002150 -0.006031  0.001976\n",
       "2  1               2           1     1.011731  1.463751  0.000277\n",
       "3  1               3           1    -0.540815  1.447527 -0.876644\n",
       "4  1               4           1    -0.523814  1.437933  0.906397\n",
       "5  2               0           7    -0.040426  1.024108  0.062564\n",
       "6  2               1           1     0.017257  0.012545 -0.027377\n",
       "7  2               2           1     0.915789  1.358745 -0.028758\n",
       "8  2               3           1    -0.520278  1.343532 -0.775543\n",
       "9  3               0           8    -0.034360  0.977540  0.007602"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index': 'int8',\n",
    "    'atom': 'category',\n",
    "    'x': 'float32',\n",
    "    'y': 'float32',\n",
    "    'z': 'float32'\n",
    "}\n",
    "structures_csv = pd.read_csv(f'{DATA_PATH}\\\\structures.csv', dtype=structures_dtypes)\n",
    "structures_csv['molecule_index'] = structures_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "structures_csv = structures_csv[['molecule_index', 'atom_index', 'atom', 'x', 'y', 'z']]\n",
    "structures_csv['atom'] = structures_csv['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "structures_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2358657, 6)\n",
      "Total:  42455906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index             80     \n",
       "molecule_index    9434628\n",
       "atom_index        2358657\n",
       "atom              2358657\n",
       "x                 9434628\n",
       "y                 9434628\n",
       "z                 9434628\n",
       "dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', structures_csv.shape)\n",
    "print('Total: ', structures_csv.memory_usage().sum())\n",
    "structures_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Distance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_index'].isin(base['molecule_index'])]\n",
    "    return base, structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_index'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_couple_dataframeOld(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    \n",
    "    \n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    output = df[labels]\n",
    "    atoms_names = list([col for col in output if col.startswith('atom_')])[2:]\n",
    "    output = output.drop(atoms_names, axis=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df, atom_idx):\n",
    "    structures = structures_csv[['molecule_index', 'atom_index', 'atom']]\n",
    "    structures = structures_csv\n",
    "    df = pd.merge(df, structures, how = 'left',\n",
    "                  left_on  = ['molecule_index', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_index',  'atom_index'])\n",
    "    df = df.rename(columns={'atom': f'atom_{atom_idx}'});\n",
    "    #df = df.drop('atom_index', axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Проверяем, что для каждого типа молекулы только  atom_1 принимает только одно значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1JHC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1JHN</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2JHC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2JHH</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2JHN</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3JHC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3JHH</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3JHN</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      atom_1\n",
       "type        \n",
       "1JHC  6     \n",
       "1JHN  7     \n",
       "2JHC  6     \n",
       "2JHH  1     \n",
       "2JHN  7     \n",
       "3JHC  6     \n",
       "3JHH  1     \n",
       "3JHN  7     "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invest0 = map_atom_info(train_csv, 1)\n",
    "invest0 = invest0[['type','atom_1']]\n",
    "invest0.groupby(['type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Regressions for a simple type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_atoms(base_from, structures_from, n_atoms):\n",
    "    base = base_from\n",
    "    structures = structures_from\n",
    "\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in atoms:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "\n",
    "    add_center(atoms)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "        \n",
    "    add_distance_to_center(atoms)\n",
    "\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "    \n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "    atoms = atoms.drop(['atom_index'], axis=1)\n",
    "    atoms = atoms.set_index(['x_c', 'y_c', 'z_c', \n",
    "        'molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "\n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    return atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        ( df['x'] -  df['x_c'])**np.float32(2) +\n",
    "        ( df['y'] -  df['y_c'])**np.float32(2) + \n",
    "        ( df['z'] -  df['z_c'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "    \n",
    "\n",
    "def cross_prod(v1, v2):\n",
    "    outp0 = v1[1] * v2[2] - v1[2] * v2[1]\n",
    "    outp1 = v1[2] * v2[0] - v1[0] * v2[2]\n",
    "    outp2 = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "    outp = pd.concat([outp0, outp1,outp2], axis=1)\n",
    "    return outp\n",
    "\n",
    "\n",
    "def add_axis_x(df):\n",
    "    n_x = df.x_0 - df.x_c\n",
    "    n_y = df.y_0 - df.y_c\n",
    "    n_z = df.z_0 - df.z_c\n",
    "    axisFrame = pd.concat([n_x, n_y, n_z], axis=1)\n",
    "    axisNorm = np.sqrt(np.square(axisFrame).sum(axis=1))\n",
    "    df['ax_x'] = axisFrame[0] / axisNorm\n",
    "    df['ax_y'] = axisFrame[1] / axisNorm\n",
    "    df['ax_z'] = axisFrame[2] / axisNorm\n",
    "\n",
    "\n",
    "def add_axis_y(df):\n",
    "    r_vec = pd.concat([df.x_2 - df.x_c, \n",
    "                 df.y_2 - df.y_c,\n",
    "                 df.z_2 - df.z_c], axis=1)\n",
    "    axis_vec = pd.concat([df['ax_x'], \n",
    "                          df['ax_y'], \n",
    "                          df['ax_z']], axis=1)\n",
    "    axis_vec.columns = [0, 1, 2]\n",
    "    dist =  axis_vec[0] * r_vec[0] + axis_vec[1] * r_vec[1] + axis_vec[2] * r_vec[2]\n",
    "    yDir = r_vec - axis_vec.multiply(dist, axis=\"index\")\n",
    "    yDirNorm = np.sqrt(np.square(yDir).sum(axis=1))\n",
    "    df['ay_x'] = yDir[0] / yDirNorm\n",
    "    df['ay_y'] = yDir[1] / yDirNorm\n",
    "    df['ay_z'] = yDir[2] / yDirNorm    \n",
    "\n",
    "def add_axis_z(df):    \n",
    "    r_vec = pd.concat([df.x_2 - df.x_c, \n",
    "         df.y_2 - df.y_c,\n",
    "         df.z_2 - df.z_c], axis=1)\n",
    "    axis_x_vec = pd.concat([df['ax_x'], \n",
    "                      df['ax_y'], \n",
    "                      df['ax_z']], axis=1)\n",
    "    axis_x_vec.columns = [0, 1, 2]\n",
    "    axis_y_vec = pd.concat([df['ay_x'], \n",
    "                      df['ay_y'], \n",
    "                      df['ay_z']], axis=1)\n",
    "    axis_y_vec.columns = [0, 1, 2]\n",
    "    axis_z_vec = cross_prod(axis_x_vec, axis_y_vec)\n",
    "    df['az_x'] = axis_z_vec[0] \n",
    "    df['az_y'] = axis_z_vec[1] \n",
    "    df['az_z'] = axis_z_vec[2] \n",
    "\n",
    "\n",
    "    \n",
    "#add coordinates in frame ax,ay,az\n",
    "def add_r_per_atom(df, suffix):\n",
    "    x_loc = df[f'x_{suffix}'] - df.x_c\n",
    "    y_loc = df[f'y_{suffix}'] - df.y_c\n",
    "    z_loc = df[f'z_{suffix}'] - df.z_c\n",
    "    r_x =  df['ax_x'] * x_loc + df['ax_y'] * y_loc + df['ax_z'] * z_loc\n",
    "    r_y =  df['ay_x'] * x_loc + df['ay_y'] * y_loc + df['ay_z'] * z_loc\n",
    "    r_z =  df['az_x'] * x_loc + df['az_y'] * y_loc + df['az_z'] * z_loc\n",
    "    df[f'r_x_{suffix}'] = r_x\n",
    "    df[f'r_y_{suffix}'] = r_y\n",
    "    df[f'r_z_{suffix}'] = r_z\n",
    "            \n",
    "def add_r(df):    \n",
    "    n_atoms = len([col for col in df if col.startswith('x_')]) - 1\n",
    "    for i in range(1, n_atoms):\n",
    "            add_r_per_atom(df, i)\n",
    "            \n",
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    \n",
    "    atoms = build_atoms(base, structures, n_atoms)\n",
    "    df = add_atoms(base, atoms)\n",
    "    \n",
    "    add_axis_x(df)\n",
    "    add_axis_y(df)\n",
    "    add_axis_z(df)\n",
    "    add_r(df)\n",
    "\n",
    "    df.sort_values('id', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 127 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>z_c</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>z_8</th>\n",
       "      <th>z_9</th>\n",
       "      <th>ax_x</th>\n",
       "      <th>ax_y</th>\n",
       "      <th>ax_z</th>\n",
       "      <th>ay_x</th>\n",
       "      <th>ay_y</th>\n",
       "      <th>ay_z</th>\n",
       "      <th>az_x</th>\n",
       "      <th>az_y</th>\n",
       "      <th>az_z</th>\n",
       "      <th>r_x_1</th>\n",
       "      <th>r_y_1</th>\n",
       "      <th>r_z_1</th>\n",
       "      <th>r_x_2</th>\n",
       "      <th>r_y_2</th>\n",
       "      <th>r_z_2</th>\n",
       "      <th>r_x_3</th>\n",
       "      <th>r_y_3</th>\n",
       "      <th>r_z_3</th>\n",
       "      <th>r_x_4</th>\n",
       "      <th>r_y_4</th>\n",
       "      <th>r_z_4</th>\n",
       "      <th>r_x_5</th>\n",
       "      <th>r_y_5</th>\n",
       "      <th>r_z_5</th>\n",
       "      <th>r_x_6</th>\n",
       "      <th>r_y_6</th>\n",
       "      <th>r_z_6</th>\n",
       "      <th>r_x_7</th>\n",
       "      <th>r_y_7</th>\n",
       "      <th>r_z_7</th>\n",
       "      <th>r_x_8</th>\n",
       "      <th>r_y_8</th>\n",
       "      <th>r_z_8</th>\n",
       "      <th>r_x_9</th>\n",
       "      <th>r_y_9</th>\n",
       "      <th>r_z_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1567330</td>\n",
       "      <td>50893</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>140.645004</td>\n",
       "      <td>0.634779</td>\n",
       "      <td>-0.462826</td>\n",
       "      <td>-0.739286</td>\n",
       "      <td>-0.133810</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>0.250485</td>\n",
       "      <td>-0.212392</td>\n",
       "      <td>-0.444989</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.256479</td>\n",
       "      <td>-1.090539</td>\n",
       "      <td>0.509465</td>\n",
       "      <td>-0.941471</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-1.970939</td>\n",
       "      <td>-2.699512</td>\n",
       "      <td>-1.220216</td>\n",
       "      <td>1.252988</td>\n",
       "      <td>-0.831051</td>\n",
       "      <td>1.787187</td>\n",
       "      <td>-2.158229</td>\n",
       "      <td>-2.629475</td>\n",
       "      <td>-2.850358</td>\n",
       "      <td>-2.328591</td>\n",
       "      <td>-4.609975</td>\n",
       "      <td>0.143031</td>\n",
       "      <td>0.318055</td>\n",
       "      <td>-0.264027</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-0.643397</td>\n",
       "      <td>0.563172</td>\n",
       "      <td>1.023855</td>\n",
       "      <td>-0.179480</td>\n",
       "      <td>0.705145</td>\n",
       "      <td>-0.459522</td>\n",
       "      <td>-0.540008</td>\n",
       "      <td>0.459768</td>\n",
       "      <td>0.876096</td>\n",
       "      <td>-0.145150</td>\n",
       "      <td>0.539799</td>\n",
       "      <td>-0.145927</td>\n",
       "      <td>0.829049</td>\n",
       "      <td>-0.544986</td>\n",
       "      <td>8.690331e-09</td>\n",
       "      <td>-1.344103e-08</td>\n",
       "      <td>-1.348394</td>\n",
       "      <td>0.965377</td>\n",
       "      <td>1.665335e-16</td>\n",
       "      <td>-1.073379</td>\n",
       "      <td>-1.269321</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.833953</td>\n",
       "      <td>1.844628</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.188789</td>\n",
       "      <td>-2.317930</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>1.013565</td>\n",
       "      <td>-2.221993</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>-0.898638</td>\n",
       "      <td>-3.478787</td>\n",
       "      <td>0.021642</td>\n",
       "      <td>-1.900923</td>\n",
       "      <td>-3.423511</td>\n",
       "      <td>-0.065852</td>\n",
       "      <td>0.840353</td>\n",
       "      <td>-4.567426</td>\n",
       "      <td>0.067962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1567340</td>\n",
       "      <td>50893</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>103.942001</td>\n",
       "      <td>-1.220216</td>\n",
       "      <td>-4.609975</td>\n",
       "      <td>-0.179480</td>\n",
       "      <td>-2.127082</td>\n",
       "      <td>-4.268234</td>\n",
       "      <td>0.327516</td>\n",
       "      <td>-1.673649</td>\n",
       "      <td>-4.439105</td>\n",
       "      <td>0.074018</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>-2.210247</td>\n",
       "      <td>-1.970939</td>\n",
       "      <td>-3.300507</td>\n",
       "      <td>-0.941471</td>\n",
       "      <td>-2.699512</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-4.236725</td>\n",
       "      <td>-1.090539</td>\n",
       "      <td>-4.815596</td>\n",
       "      <td>-2.850358</td>\n",
       "      <td>-4.583531</td>\n",
       "      <td>-2.158229</td>\n",
       "      <td>-2.328591</td>\n",
       "      <td>-2.629475</td>\n",
       "      <td>-4.827504</td>\n",
       "      <td>-0.831051</td>\n",
       "      <td>1.273320</td>\n",
       "      <td>0.563172</td>\n",
       "      <td>-0.501114</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>1.023855</td>\n",
       "      <td>-0.643397</td>\n",
       "      <td>-1.131620</td>\n",
       "      <td>0.318055</td>\n",
       "      <td>0.829152</td>\n",
       "      <td>-0.312455</td>\n",
       "      <td>-0.463550</td>\n",
       "      <td>0.187651</td>\n",
       "      <td>-0.625536</td>\n",
       "      <td>0.757293</td>\n",
       "      <td>-0.526587</td>\n",
       "      <td>-0.714896</td>\n",
       "      <td>-0.460032</td>\n",
       "      <td>-0.546864</td>\n",
       "      <td>-3.206483e-07</td>\n",
       "      <td>-2.781151e-07</td>\n",
       "      <td>-0.883221</td>\n",
       "      <td>1.043038</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>-0.969658</td>\n",
       "      <td>-0.679172</td>\n",
       "      <td>-1.204267</td>\n",
       "      <td>-1.037184</td>\n",
       "      <td>-0.650480</td>\n",
       "      <td>1.224511</td>\n",
       "      <td>-0.073115</td>\n",
       "      <td>-1.342422</td>\n",
       "      <td>-1.983922</td>\n",
       "      <td>-1.950334</td>\n",
       "      <td>-0.793401</td>\n",
       "      <td>-1.405548</td>\n",
       "      <td>1.122323</td>\n",
       "      <td>-1.368580</td>\n",
       "      <td>-1.824335</td>\n",
       "      <td>-1.444950</td>\n",
       "      <td>-1.151026</td>\n",
       "      <td>2.181979</td>\n",
       "      <td>-0.756991</td>\n",
       "      <td>-1.962738</td>\n",
       "      <td>-2.998708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1567346</td>\n",
       "      <td>50893</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>92.774101</td>\n",
       "      <td>-2.210247</td>\n",
       "      <td>-4.815596</td>\n",
       "      <td>1.273320</td>\n",
       "      <td>-2.127082</td>\n",
       "      <td>-4.268234</td>\n",
       "      <td>0.327516</td>\n",
       "      <td>-2.168664</td>\n",
       "      <td>-4.541915</td>\n",
       "      <td>0.800418</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>-1.220216</td>\n",
       "      <td>-1.970939</td>\n",
       "      <td>-3.300507</td>\n",
       "      <td>-2.699512</td>\n",
       "      <td>-0.941471</td>\n",
       "      <td>-4.236725</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-1.090539</td>\n",
       "      <td>-4.609975</td>\n",
       "      <td>-2.850358</td>\n",
       "      <td>-4.583531</td>\n",
       "      <td>-2.328591</td>\n",
       "      <td>-2.158229</td>\n",
       "      <td>-4.827504</td>\n",
       "      <td>-2.629475</td>\n",
       "      <td>-0.831051</td>\n",
       "      <td>-0.179480</td>\n",
       "      <td>0.563172</td>\n",
       "      <td>-0.501114</td>\n",
       "      <td>1.023855</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-1.131620</td>\n",
       "      <td>-0.643397</td>\n",
       "      <td>0.318055</td>\n",
       "      <td>-0.075885</td>\n",
       "      <td>-0.499449</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.846727</td>\n",
       "      <td>-0.489362</td>\n",
       "      <td>-0.208753</td>\n",
       "      <td>0.526587</td>\n",
       "      <td>0.714896</td>\n",
       "      <td>0.460032</td>\n",
       "      <td>-0.547966</td>\n",
       "      <td>-2.080969e-07</td>\n",
       "      <td>-1.118382e-07</td>\n",
       "      <td>-0.883646</td>\n",
       "      <td>1.040940</td>\n",
       "      <td>-1.110223e-16</td>\n",
       "      <td>-1.064597</td>\n",
       "      <td>-0.610838</td>\n",
       "      <td>1.204266</td>\n",
       "      <td>-1.016565</td>\n",
       "      <td>-0.666298</td>\n",
       "      <td>-1.224512</td>\n",
       "      <td>-0.872329</td>\n",
       "      <td>-1.579242</td>\n",
       "      <td>1.405547</td>\n",
       "      <td>-1.970999</td>\n",
       "      <td>0.038874</td>\n",
       "      <td>1.983921</td>\n",
       "      <td>-1.367803</td>\n",
       "      <td>-1.208008</td>\n",
       "      <td>-2.181981</td>\n",
       "      <td>-2.362792</td>\n",
       "      <td>1.168588</td>\n",
       "      <td>1.824335</td>\n",
       "      <td>-2.351486</td>\n",
       "      <td>-0.802381</td>\n",
       "      <td>2.998706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  molecule_index  atom_index_0  atom_index_1  \\\n",
       "0  1567330  50893           10            1              \n",
       "1  1567340  50893           12            6              \n",
       "2  1567346  50893           13            6              \n",
       "\n",
       "   scalar_coupling_constant       x_0       y_0       z_0       x_1       y_1  \\\n",
       "0  140.645004                0.634779 -0.462826 -0.739286 -0.133810  0.038041   \n",
       "1  103.942001               -1.220216 -4.609975 -0.179480 -2.127082 -4.268234   \n",
       "2  92.774101                -2.210247 -4.815596  1.273320 -2.127082 -4.268234   \n",
       "\n",
       "        z_1       x_c       y_c       z_c  atom_2  atom_3  atom_4  atom_5  \\\n",
       "0 -0.150691  0.250485 -0.212392 -0.444989  7       8       1       6        \n",
       "1  0.327516 -1.673649 -4.439105  0.074018  1       7       6       6        \n",
       "2  0.327516 -2.168664 -4.541915  0.800418  1       7       6       1        \n",
       "\n",
       "   atom_6  atom_7  atom_8  atom_9       x_2       x_3       x_4       x_5  \\\n",
       "0  8       7       1       1      -0.256479 -1.090539  0.509465 -0.941471   \n",
       "1  1       8       7       8      -2.210247 -1.970939 -3.300507 -0.941471   \n",
       "2  6       7       8       8      -1.220216 -1.970939 -3.300507 -2.699512   \n",
       "\n",
       "        x_6       x_7       x_8       x_9       y_2       y_3       y_4  \\\n",
       "0 -0.039216 -1.970939 -2.699512 -1.220216  1.252988 -0.831051  1.787187   \n",
       "1 -2.699512 -0.039216 -4.236725 -1.090539 -4.815596 -2.850358 -4.583531   \n",
       "2 -0.941471 -4.236725 -0.039216 -1.090539 -4.609975 -2.850358 -4.583531   \n",
       "\n",
       "        y_5       y_6       y_7       y_8       y_9       z_2       z_3  \\\n",
       "0 -2.158229 -2.629475 -2.850358 -2.328591 -4.609975  0.143031  0.318055   \n",
       "1 -2.158229 -2.328591 -2.629475 -4.827504 -0.831051  1.273320  0.563172   \n",
       "2 -2.328591 -2.158229 -4.827504 -2.629475 -0.831051 -0.179480  0.563172   \n",
       "\n",
       "        z_4       z_5       z_6       z_7       z_8       z_9      ax_x  \\\n",
       "0 -0.264027  0.003972 -0.643397  0.563172  1.023855 -0.179480  0.705145   \n",
       "1 -0.501114  0.003972  1.023855 -0.643397 -1.131620  0.318055  0.829152   \n",
       "2 -0.501114  1.023855  0.003972 -1.131620 -0.643397  0.318055 -0.075885   \n",
       "\n",
       "       ax_y      ax_z      ay_x      ay_y      ay_z      az_x      az_y  \\\n",
       "0 -0.459522 -0.540008  0.459768  0.876096 -0.145150  0.539799 -0.145927   \n",
       "1 -0.312455 -0.463550  0.187651 -0.625536  0.757293 -0.526587 -0.714896   \n",
       "2 -0.499449  0.863014  0.846727 -0.489362 -0.208753  0.526587  0.714896   \n",
       "\n",
       "       az_z     r_x_1         r_y_1         r_z_1     r_x_2     r_y_2  \\\n",
       "0  0.829049 -0.544986  8.690331e-09 -1.344103e-08 -1.348394  0.965377   \n",
       "1 -0.460032 -0.546864 -3.206483e-07 -2.781151e-07 -0.883221  1.043038   \n",
       "2  0.460032 -0.547966 -2.080969e-07 -1.118382e-07 -0.883646  1.040940   \n",
       "\n",
       "          r_z_2     r_x_3     r_y_3     r_z_3     r_x_4     r_y_4     r_z_4  \\\n",
       "0  1.665335e-16 -1.073379 -1.269321 -0.001004 -0.833953  1.844628 -0.001969   \n",
       "1 -1.110223e-16 -0.969658 -0.679172 -1.204267 -1.037184 -0.650480  1.224511   \n",
       "2 -1.110223e-16 -1.064597 -0.610838  1.204266 -1.016565 -0.666298 -1.224512   \n",
       "\n",
       "      r_x_5     r_y_5     r_z_5     r_x_6     r_y_6     r_z_6     r_x_7  \\\n",
       "0 -0.188789 -2.317930  0.012743  1.013565 -2.221993  0.031846 -0.898638   \n",
       "1 -0.073115 -1.342422 -1.983922 -1.950334 -0.793401 -1.405548  1.122323   \n",
       "2 -0.872329 -1.579242  1.405547 -1.970999  0.038874  1.983921 -1.367803   \n",
       "\n",
       "      r_y_7     r_z_7     r_x_8     r_y_8     r_z_8     r_x_9     r_y_9  \\\n",
       "0 -3.478787  0.021642 -1.900923 -3.423511 -0.065852  0.840353 -4.567426   \n",
       "1 -1.368580 -1.824335 -1.444950 -1.151026  2.181979 -0.756991 -1.962738   \n",
       "2 -1.208008 -2.181981 -2.362792  1.168588  1.824335 -2.351486 -0.802381   \n",
       "\n",
       "      r_z_9  \n",
       "0  0.067962  \n",
       "1 -2.998708  \n",
       "2  2.998706  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "molecule_index = 50893\n",
    "some_csv = train_csv[train_csv.molecule_index == molecule_index]\n",
    "#some_csv = train_csv #[:6000]\n",
    "coupling_type = '1JHC'\n",
    "n_atoms = 10\n",
    "full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>z_c</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>z_8</th>\n",
       "      <th>z_9</th>\n",
       "      <th>ax_x</th>\n",
       "      <th>ax_y</th>\n",
       "      <th>ax_z</th>\n",
       "      <th>ay_x</th>\n",
       "      <th>ay_y</th>\n",
       "      <th>ay_z</th>\n",
       "      <th>az_x</th>\n",
       "      <th>az_y</th>\n",
       "      <th>az_z</th>\n",
       "      <th>r_x_1</th>\n",
       "      <th>r_y_1</th>\n",
       "      <th>r_z_1</th>\n",
       "      <th>r_x_2</th>\n",
       "      <th>r_y_2</th>\n",
       "      <th>r_z_2</th>\n",
       "      <th>r_x_3</th>\n",
       "      <th>r_y_3</th>\n",
       "      <th>r_z_3</th>\n",
       "      <th>r_x_4</th>\n",
       "      <th>r_y_4</th>\n",
       "      <th>r_z_4</th>\n",
       "      <th>r_x_5</th>\n",
       "      <th>r_y_5</th>\n",
       "      <th>r_z_5</th>\n",
       "      <th>r_x_6</th>\n",
       "      <th>r_y_6</th>\n",
       "      <th>r_z_6</th>\n",
       "      <th>r_x_7</th>\n",
       "      <th>r_y_7</th>\n",
       "      <th>r_z_7</th>\n",
       "      <th>r_x_8</th>\n",
       "      <th>r_y_8</th>\n",
       "      <th>r_z_8</th>\n",
       "      <th>r_x_9</th>\n",
       "      <th>r_y_9</th>\n",
       "      <th>r_z_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84.807602</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.005274</td>\n",
       "      <td>0.539886</td>\n",
       "      <td>0.004989</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013598</td>\n",
       "      <td>-0.999892</td>\n",
       "      <td>-0.005518</td>\n",
       "      <td>0.999862</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>-0.009453</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>-0.005388</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>-0.545976</td>\n",
       "      <td>-1.050371e-09</td>\n",
       "      <td>2.263989e-10</td>\n",
       "      <td>-0.909910</td>\n",
       "      <td>1.029520e+00</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>-0.909960</td>\n",
       "      <td>-0.514744</td>\n",
       "      <td>-0.891572</td>\n",
       "      <td>-0.909974</td>\n",
       "      <td>-0.514731</td>\n",
       "      <td>0.891575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84.807404</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.499516</td>\n",
       "      <td>1.274778</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938163</td>\n",
       "      <td>0.346121</td>\n",
       "      <td>-0.007074</td>\n",
       "      <td>0.346062</td>\n",
       "      <td>-0.938175</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.009528</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.545976</td>\n",
       "      <td>-7.734600e-09</td>\n",
       "      <td>2.711641e-10</td>\n",
       "      <td>-0.909910</td>\n",
       "      <td>1.029521e+00</td>\n",
       "      <td>-4.336809e-19</td>\n",
       "      <td>-0.909962</td>\n",
       "      <td>-0.514740</td>\n",
       "      <td>-0.891575</td>\n",
       "      <td>-0.909978</td>\n",
       "      <td>-0.514731</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>84.809303</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.276757</td>\n",
       "      <td>1.266665</td>\n",
       "      <td>-0.434321</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.483647</td>\n",
       "      <td>0.331264</td>\n",
       "      <td>-0.810154</td>\n",
       "      <td>-0.667473</td>\n",
       "      <td>0.459163</td>\n",
       "      <td>0.586216</td>\n",
       "      <td>0.566185</td>\n",
       "      <td>0.824277</td>\n",
       "      <td>-0.000963</td>\n",
       "      <td>-0.545973</td>\n",
       "      <td>3.020596e-08</td>\n",
       "      <td>-1.268035e-08</td>\n",
       "      <td>-0.909965</td>\n",
       "      <td>1.029495e+00</td>\n",
       "      <td>1.084202e-17</td>\n",
       "      <td>-0.909959</td>\n",
       "      <td>-0.514773</td>\n",
       "      <td>-0.891563</td>\n",
       "      <td>-0.909977</td>\n",
       "      <td>-0.514767</td>\n",
       "      <td>0.891557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>84.809502</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>-0.268256</td>\n",
       "      <td>1.261868</td>\n",
       "      <td>0.457199</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.468077</td>\n",
       "      <td>0.322477</td>\n",
       "      <td>0.822747</td>\n",
       "      <td>-0.678482</td>\n",
       "      <td>0.465376</td>\n",
       "      <td>-0.568407</td>\n",
       "      <td>-0.566185</td>\n",
       "      <td>-0.824277</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>-0.545974</td>\n",
       "      <td>3.428866e-10</td>\n",
       "      <td>1.268035e-08</td>\n",
       "      <td>-0.909966</td>\n",
       "      <td>1.029493e+00</td>\n",
       "      <td>-2.992398e-17</td>\n",
       "      <td>-0.909961</td>\n",
       "      <td>-0.514779</td>\n",
       "      <td>-0.891557</td>\n",
       "      <td>-0.909973</td>\n",
       "      <td>-0.514764</td>\n",
       "      <td>0.891563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>171.220001</td>\n",
       "      <td>-0.027803</td>\n",
       "      <td>2.198949</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>-0.013324</td>\n",
       "      <td>1.132466</td>\n",
       "      <td>0.008276</td>\n",
       "      <td>-0.020563</td>\n",
       "      <td>1.665708</td>\n",
       "      <td>0.011215</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.019159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013575</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.524973</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.851115</td>\n",
       "      <td>0.851010</td>\n",
       "      <td>0.014447</td>\n",
       "      <td>-0.524950</td>\n",
       "      <td>-0.533299</td>\n",
       "      <td>4.108457e-08</td>\n",
       "      <td>-1.370526e-10</td>\n",
       "      <td>-1.685047</td>\n",
       "      <td>1.296874e-07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  molecule_index  atom_index_0  atom_index_1  scalar_coupling_constant  \\\n",
       "0  0   1               1             0             84.807602                  \n",
       "1  4   1               2             0             84.807404                  \n",
       "2  7   1               3             0             84.809303                  \n",
       "3  9   1               4             0             84.809502                  \n",
       "4  17  5               2             0             171.220001                 \n",
       "\n",
       "        x_0       y_0       z_0       x_1       y_1       z_1       x_c  \\\n",
       "0  0.002150 -0.006031  0.001976 -0.012698  1.085804  0.008001 -0.005274   \n",
       "1  1.011731  1.463751  0.000277 -0.012698  1.085804  0.008001  0.499516   \n",
       "2 -0.540815  1.447527 -0.876644 -0.012698  1.085804  0.008001 -0.276757   \n",
       "3 -0.523814  1.437933  0.906397 -0.012698  1.085804  0.008001 -0.268256   \n",
       "4 -0.027803  2.198949  0.014154 -0.013324  1.132466  0.008276 -0.020563   \n",
       "\n",
       "        y_c       z_c  atom_2  atom_3  atom_4  atom_5  atom_6  atom_7  atom_8  \\\n",
       "0  0.539886  0.004989  1       1       1       0       0       0       0        \n",
       "1  1.274778  0.004139  1       1       1       0       0       0       0        \n",
       "2  1.266665 -0.434321  1       1       1       0       0       0       0        \n",
       "3  1.261868  0.457199  1       1       1       0       0       0       0        \n",
       "4  1.665708  0.011215  7       0       0       0       0       0       0        \n",
       "\n",
       "   atom_9       x_2       x_3       x_4  x_5  x_6  x_7  x_8  x_9       y_2  \\\n",
       "0  0       1.011731 -0.540815 -0.523814 NaN  NaN  NaN  NaN  NaN   1.463751   \n",
       "1  0       0.002150 -0.523814 -0.540815 NaN  NaN  NaN  NaN  NaN  -0.006031   \n",
       "2  0      -0.523814  0.002150  1.011731 NaN  NaN  NaN  NaN  NaN   1.437933   \n",
       "3  0      -0.540815  1.011731  0.002150 NaN  NaN  NaN  NaN  NaN   1.447527   \n",
       "4  0       0.002311 NaN       NaN       NaN  NaN  NaN  NaN  NaN  -0.019159   \n",
       "\n",
       "        y_3       y_4  y_5  y_6  y_7  y_8  y_9       z_2       z_3       z_4  \\\n",
       "0  1.447527  1.437933 NaN  NaN  NaN  NaN  NaN   0.000277 -0.876644  0.906397   \n",
       "1  1.437933  1.447527 NaN  NaN  NaN  NaN  NaN   0.001976  0.906397 -0.876644   \n",
       "2 -0.006031  1.463751 NaN  NaN  NaN  NaN  NaN   0.906397  0.001976  0.000277   \n",
       "3  1.463751 -0.006031 NaN  NaN  NaN  NaN  NaN  -0.876644  0.000277  0.001976   \n",
       "4 NaN       NaN       NaN  NaN  NaN  NaN  NaN   0.001929 NaN       NaN         \n",
       "\n",
       "   z_5  z_6  z_7  z_8  z_9      ax_x      ax_y      ax_z      ay_x      ay_y  \\\n",
       "0 NaN  NaN  NaN  NaN  NaN   0.013598 -0.999892 -0.005518  0.999862  0.013650   \n",
       "1 NaN  NaN  NaN  NaN  NaN   0.938163  0.346121 -0.007074  0.346062 -0.938175   \n",
       "2 NaN  NaN  NaN  NaN  NaN  -0.483647  0.331264 -0.810154 -0.667473  0.459163   \n",
       "3 NaN  NaN  NaN  NaN  NaN  -0.468077  0.322477  0.822747 -0.678482  0.465376   \n",
       "4 NaN  NaN  NaN  NaN  NaN  -0.013575  0.999893  0.005511  0.524973  0.002436   \n",
       "\n",
       "       ay_z      az_x      az_y      az_z     r_x_1         r_y_1  \\\n",
       "0 -0.009453  0.009528 -0.005388  0.999940 -0.545976 -1.050371e-09   \n",
       "1 -0.008353 -0.009528  0.005388 -0.999940 -0.545976 -7.734600e-09   \n",
       "2  0.586216  0.566185  0.824277 -0.000963 -0.545973  3.020596e-08   \n",
       "3 -0.568407 -0.566185 -0.824277  0.000963 -0.545974  3.428866e-10   \n",
       "4  0.851115  0.851010  0.014447 -0.524950 -0.533299  4.108457e-08   \n",
       "\n",
       "          r_z_1     r_x_2         r_y_2         r_z_2     r_x_3     r_y_3  \\\n",
       "0  2.263989e-10 -0.909910  1.029520e+00  3.469447e-18 -0.909960 -0.514744   \n",
       "1  2.711641e-10 -0.909910  1.029521e+00 -4.336809e-19 -0.909962 -0.514740   \n",
       "2 -1.268035e-08 -0.909965  1.029495e+00  1.084202e-17 -0.909959 -0.514773   \n",
       "3  1.268035e-08 -0.909966  1.029493e+00 -2.992398e-17 -0.909961 -0.514779   \n",
       "4 -1.370526e-10 -1.685047  1.296874e-07  0.000000e+00 NaN       NaN         \n",
       "\n",
       "      r_z_3     r_x_4     r_y_4     r_z_4  r_x_5  r_y_5  r_z_5  r_x_6  r_y_6  \\\n",
       "0 -0.891572 -0.909974 -0.514731  0.891575 NaN    NaN    NaN    NaN    NaN      \n",
       "1 -0.891575 -0.909978 -0.514731  0.891572 NaN    NaN    NaN    NaN    NaN      \n",
       "2 -0.891563 -0.909977 -0.514767  0.891557 NaN    NaN    NaN    NaN    NaN      \n",
       "3 -0.891557 -0.909973 -0.514764  0.891563 NaN    NaN    NaN    NaN    NaN      \n",
       "4 NaN       NaN       NaN       NaN       NaN    NaN    NaN    NaN    NaN      \n",
       "\n",
       "   r_z_6  r_x_7  r_y_7  r_z_7  r_x_8  r_y_8  r_z_8  r_x_9  r_y_9  r_z_9  \n",
       "0 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "1 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "2 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "3 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     \n",
       "4 NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "full = build_couple_dataframe(train_csv, structures_csv, '1JHC', n_atoms=10)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(1, n_atoms):\n",
    "        labels.append(f'r_x_{i}')\n",
    "    for i in range(2, n_atoms):\n",
    "        labels.append(f'r_y_{i}')\n",
    "    for i in range(3, n_atoms):\n",
    "        labels.append(f'r_z_{i}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    output = df[labels]\n",
    "    #atoms_names = list([col for col in output if col.startswith('atom_')])[2:]\n",
    "    #output = output.drop(atoms_names, axis=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>r_x_1</th>\n",
       "      <th>r_x_2</th>\n",
       "      <th>r_x_3</th>\n",
       "      <th>r_x_4</th>\n",
       "      <th>r_x_5</th>\n",
       "      <th>r_x_6</th>\n",
       "      <th>r_x_7</th>\n",
       "      <th>r_x_8</th>\n",
       "      <th>r_x_9</th>\n",
       "      <th>r_y_2</th>\n",
       "      <th>r_y_3</th>\n",
       "      <th>r_y_4</th>\n",
       "      <th>r_y_5</th>\n",
       "      <th>r_y_6</th>\n",
       "      <th>r_y_7</th>\n",
       "      <th>r_y_8</th>\n",
       "      <th>r_y_9</th>\n",
       "      <th>r_z_3</th>\n",
       "      <th>r_z_4</th>\n",
       "      <th>r_z_5</th>\n",
       "      <th>r_z_6</th>\n",
       "      <th>r_z_7</th>\n",
       "      <th>r_z_8</th>\n",
       "      <th>r_z_9</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.545976</td>\n",
       "      <td>-0.909910</td>\n",
       "      <td>-0.909960</td>\n",
       "      <td>-0.909974</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029520e+00</td>\n",
       "      <td>-0.514744</td>\n",
       "      <td>-0.514731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.891572</td>\n",
       "      <td>0.891575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.807602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.545976</td>\n",
       "      <td>-0.909910</td>\n",
       "      <td>-0.909962</td>\n",
       "      <td>-0.909978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029521e+00</td>\n",
       "      <td>-0.514740</td>\n",
       "      <td>-0.514731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.891575</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.545973</td>\n",
       "      <td>-0.909965</td>\n",
       "      <td>-0.909959</td>\n",
       "      <td>-0.909977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029495e+00</td>\n",
       "      <td>-0.514773</td>\n",
       "      <td>-0.514767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.891563</td>\n",
       "      <td>0.891557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.809303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.545974</td>\n",
       "      <td>-0.909966</td>\n",
       "      <td>-0.909961</td>\n",
       "      <td>-0.909973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.029493e+00</td>\n",
       "      <td>-0.514779</td>\n",
       "      <td>-0.514764</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.891557</td>\n",
       "      <td>0.891563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.809502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.533299</td>\n",
       "      <td>-1.685047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.296874e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171.220001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atom_2  atom_3  atom_4  atom_5  atom_6  atom_7  atom_8  atom_9     r_x_1  \\\n",
       "0  1       1       1       0       0       0       0       0      -0.545976   \n",
       "1  1       1       1       0       0       0       0       0      -0.545976   \n",
       "2  1       1       1       0       0       0       0       0      -0.545973   \n",
       "3  1       1       1       0       0       0       0       0      -0.545974   \n",
       "4  7       0       0       0       0       0       0       0      -0.533299   \n",
       "\n",
       "      r_x_2     r_x_3     r_x_4  r_x_5  r_x_6  r_x_7  r_x_8  r_x_9  \\\n",
       "0 -0.909910 -0.909960 -0.909974 NaN    NaN    NaN    NaN    NaN      \n",
       "1 -0.909910 -0.909962 -0.909978 NaN    NaN    NaN    NaN    NaN      \n",
       "2 -0.909965 -0.909959 -0.909977 NaN    NaN    NaN    NaN    NaN      \n",
       "3 -0.909966 -0.909961 -0.909973 NaN    NaN    NaN    NaN    NaN      \n",
       "4 -1.685047 NaN       NaN       NaN    NaN    NaN    NaN    NaN      \n",
       "\n",
       "          r_y_2     r_y_3     r_y_4  r_y_5  r_y_6  r_y_7  r_y_8  r_y_9  \\\n",
       "0  1.029520e+00 -0.514744 -0.514731 NaN    NaN    NaN    NaN    NaN      \n",
       "1  1.029521e+00 -0.514740 -0.514731 NaN    NaN    NaN    NaN    NaN      \n",
       "2  1.029495e+00 -0.514773 -0.514767 NaN    NaN    NaN    NaN    NaN      \n",
       "3  1.029493e+00 -0.514779 -0.514764 NaN    NaN    NaN    NaN    NaN      \n",
       "4  1.296874e-07 NaN       NaN       NaN    NaN    NaN    NaN    NaN      \n",
       "\n",
       "      r_z_3     r_z_4  r_z_5  r_z_6  r_z_7  r_z_8  r_z_9  \\\n",
       "0 -0.891572  0.891575 NaN    NaN    NaN    NaN    NaN      \n",
       "1 -0.891575  0.891572 NaN    NaN    NaN    NaN    NaN      \n",
       "2 -0.891563  0.891557 NaN    NaN    NaN    NaN    NaN      \n",
       "3 -0.891557  0.891563 NaN    NaN    NaN    NaN    NaN      \n",
       "4 NaN       NaN       NaN    NaN    NaN    NaN    NaN      \n",
       "\n",
       "   scalar_coupling_constant  \n",
       "0  84.807602                 \n",
       "1  84.807404                 \n",
       "2  84.809303                 \n",
       "3  84.809502                 \n",
       "4  171.220001                "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = take_n_atoms(full, 10)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For experiments, full dataset can be built with higher number of atoms, and for building a training/validation sets we can trim them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
       "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
       "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
       "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
       "       'r_z_9', 'scalar_coupling_constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = take_n_atoms(full, 9)\n",
    "\n",
    "#inverse of distances\n",
    "#filter_col = [col for col in df if col.startswith('d_')]\n",
    "#df[filter_col] = 1 / (df[filter_col])\n",
    "#df.head()\n",
    "\n",
    "# LightGBM performs better with 0-s then with NaN-s\n",
    "df = df.fillna(0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.hist(bins=10, figsize = [20,20] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.plot.scatter(x='dist_along_1', y = 'scalar_coupling_constant') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((567532, 32), (141884, 32), (567532,), (141884,))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "#y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "X_data = df.drop(['scalar_coupling_constant'], axis=1)\n",
    "y_data = df['scalar_coupling_constant']\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=128)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 98.2955513\ttest: 140.5825043\tbest: 140.5825043 (0)\ttotal: 3.04ms\tremaining: 149ms\n",
      "1:\tlearn: 98.2330513\ttest: 140.5200043\tbest: 140.5200043 (1)\ttotal: 5.91ms\tremaining: 142ms\n",
      "2:\tlearn: 98.1705513\ttest: 140.4575043\tbest: 140.4575043 (2)\ttotal: 8.36ms\tremaining: 131ms\n",
      "3:\tlearn: 98.1080513\ttest: 140.3950043\tbest: 140.3950043 (3)\ttotal: 11ms\tremaining: 126ms\n",
      "4:\tlearn: 98.0455513\ttest: 140.3325043\tbest: 140.3325043 (4)\ttotal: 13.7ms\tremaining: 123ms\n",
      "5:\tlearn: 97.9830513\ttest: 140.2700043\tbest: 140.2700043 (5)\ttotal: 16.1ms\tremaining: 118ms\n",
      "6:\tlearn: 97.9205513\ttest: 140.2075043\tbest: 140.2075043 (6)\ttotal: 18.7ms\tremaining: 115ms\n",
      "7:\tlearn: 97.8580513\ttest: 140.1450043\tbest: 140.1450043 (7)\ttotal: 21.1ms\tremaining: 111ms\n",
      "8:\tlearn: 97.7955513\ttest: 140.0825043\tbest: 140.0825043 (8)\ttotal: 23.6ms\tremaining: 107ms\n",
      "9:\tlearn: 97.7330513\ttest: 140.0200043\tbest: 140.0200043 (9)\ttotal: 26.4ms\tremaining: 106ms\n",
      "10:\tlearn: 97.6705513\ttest: 139.9575043\tbest: 139.9575043 (10)\ttotal: 28.9ms\tremaining: 102ms\n",
      "11:\tlearn: 97.6080513\ttest: 139.8950043\tbest: 139.8950043 (11)\ttotal: 31.3ms\tremaining: 99ms\n",
      "12:\tlearn: 97.5455513\ttest: 139.8325043\tbest: 139.8325043 (12)\ttotal: 33.8ms\tremaining: 96.2ms\n",
      "13:\tlearn: 97.4830513\ttest: 139.7700043\tbest: 139.7700043 (13)\ttotal: 36.2ms\tremaining: 93.1ms\n",
      "14:\tlearn: 97.4205513\ttest: 139.7075043\tbest: 139.7075043 (14)\ttotal: 38.7ms\tremaining: 90.2ms\n",
      "15:\tlearn: 97.3580513\ttest: 139.6450043\tbest: 139.6450043 (15)\ttotal: 41.5ms\tremaining: 88.1ms\n",
      "16:\tlearn: 97.2955513\ttest: 139.5825043\tbest: 139.5825043 (16)\ttotal: 43.9ms\tremaining: 85.3ms\n",
      "17:\tlearn: 97.2330513\ttest: 139.5200043\tbest: 139.5200043 (17)\ttotal: 46.5ms\tremaining: 82.7ms\n",
      "18:\tlearn: 97.1705513\ttest: 139.4575043\tbest: 139.4575043 (18)\ttotal: 51.4ms\tremaining: 83.8ms\n",
      "19:\tlearn: 97.1080513\ttest: 139.3950043\tbest: 139.3950043 (19)\ttotal: 54ms\tremaining: 81ms\n",
      "20:\tlearn: 97.0455513\ttest: 139.3325043\tbest: 139.3325043 (20)\ttotal: 56.9ms\tremaining: 78.6ms\n",
      "21:\tlearn: 96.9830513\ttest: 139.2700043\tbest: 139.2700043 (21)\ttotal: 59.4ms\tremaining: 75.6ms\n",
      "22:\tlearn: 96.9205513\ttest: 139.2075043\tbest: 139.2075043 (22)\ttotal: 61.8ms\tremaining: 72.5ms\n",
      "23:\tlearn: 96.8580513\ttest: 139.1450043\tbest: 139.1450043 (23)\ttotal: 64.3ms\tremaining: 69.7ms\n",
      "24:\tlearn: 96.7955513\ttest: 139.0825043\tbest: 139.0825043 (24)\ttotal: 66.8ms\tremaining: 66.8ms\n",
      "25:\tlearn: 96.7330513\ttest: 139.0200043\tbest: 139.0200043 (25)\ttotal: 69.2ms\tremaining: 63.9ms\n",
      "26:\tlearn: 96.6705513\ttest: 138.9575043\tbest: 138.9575043 (26)\ttotal: 72.1ms\tremaining: 61.4ms\n",
      "27:\tlearn: 96.6080513\ttest: 138.8950043\tbest: 138.8950043 (27)\ttotal: 75ms\tremaining: 58.9ms\n",
      "28:\tlearn: 96.5455513\ttest: 138.8325043\tbest: 138.8325043 (28)\ttotal: 77.5ms\tremaining: 56.1ms\n",
      "29:\tlearn: 96.4830513\ttest: 138.7700043\tbest: 138.7700043 (29)\ttotal: 80ms\tremaining: 53.3ms\n",
      "30:\tlearn: 96.4205513\ttest: 138.7075043\tbest: 138.7075043 (30)\ttotal: 82.6ms\tremaining: 50.6ms\n",
      "31:\tlearn: 96.3580513\ttest: 138.6450043\tbest: 138.6450043 (31)\ttotal: 85.2ms\tremaining: 47.9ms\n",
      "32:\tlearn: 96.2955513\ttest: 138.5825043\tbest: 138.5825043 (32)\ttotal: 87.8ms\tremaining: 45.2ms\n",
      "33:\tlearn: 96.2330513\ttest: 138.5200043\tbest: 138.5200043 (33)\ttotal: 91.3ms\tremaining: 43ms\n",
      "34:\tlearn: 96.1705513\ttest: 138.4575043\tbest: 138.4575043 (34)\ttotal: 94.3ms\tremaining: 40.4ms\n",
      "35:\tlearn: 96.1080513\ttest: 138.3950043\tbest: 138.3950043 (35)\ttotal: 96.7ms\tremaining: 37.6ms\n",
      "36:\tlearn: 96.0455513\ttest: 138.3325043\tbest: 138.3325043 (36)\ttotal: 99.4ms\tremaining: 34.9ms\n",
      "37:\tlearn: 95.9830513\ttest: 138.2700043\tbest: 138.2700043 (37)\ttotal: 102ms\tremaining: 32.3ms\n",
      "38:\tlearn: 95.9205513\ttest: 138.2075043\tbest: 138.2075043 (38)\ttotal: 105ms\tremaining: 29.6ms\n",
      "39:\tlearn: 95.8580513\ttest: 138.1450043\tbest: 138.1450043 (39)\ttotal: 108ms\tremaining: 26.9ms\n",
      "40:\tlearn: 95.7955513\ttest: 138.0825043\tbest: 138.0825043 (40)\ttotal: 110ms\tremaining: 24.2ms\n",
      "41:\tlearn: 95.7330513\ttest: 138.0200043\tbest: 138.0200043 (41)\ttotal: 113ms\tremaining: 21.4ms\n",
      "42:\tlearn: 95.6705513\ttest: 137.9575043\tbest: 137.9575043 (42)\ttotal: 115ms\tremaining: 18.8ms\n",
      "43:\tlearn: 95.6080513\ttest: 137.8950043\tbest: 137.8950043 (43)\ttotal: 118ms\tremaining: 16ms\n",
      "44:\tlearn: 95.5455513\ttest: 137.8325043\tbest: 137.8325043 (44)\ttotal: 121ms\tremaining: 13.4ms\n",
      "45:\tlearn: 95.4830513\ttest: 137.7700043\tbest: 137.7700043 (45)\ttotal: 124ms\tremaining: 10.7ms\n",
      "46:\tlearn: 95.4205513\ttest: 137.7075043\tbest: 137.7075043 (46)\ttotal: 126ms\tremaining: 8.05ms\n",
      "47:\tlearn: 95.3580513\ttest: 137.6450043\tbest: 137.6450043 (47)\ttotal: 129ms\tremaining: 5.36ms\n",
      "48:\tlearn: 95.2955513\ttest: 137.5825043\tbest: 137.5825043 (48)\ttotal: 131ms\tremaining: 2.68ms\n",
      "49:\tlearn: 95.2330513\ttest: 137.5200043\tbest: 137.5200043 (49)\ttotal: 134ms\tremaining: 0us\n",
      "\n",
      "bestTest = 137.5200043\n",
      "bestIteration = 49\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.923769392142518"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT_PARAMS = {\n",
    "          'learning_rate': 0.5,\n",
    "           'max_depth': 5,    \n",
    "           'n_estimators': 50\n",
    "         }\n",
    "#categorical features\n",
    "\n",
    "categorical_features = [col for col in X_train if col.startswith('atom_')]\n",
    "model = CatBoostRegressor(eval_metric='MAE', **CAT_PARAMS, loss_function='MAE')\n",
    "model.fit(X_train, y_train, eval_set=((X_val, y_val)), \n",
    "          cat_features = categorical_features,\n",
    "          use_best_model=True,\n",
    "          verbose=True)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "np.log(mean_absolute_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = list(X_train.columns)\n",
    "#cols.remove('scalar_coupling_constant')\n",
    "df_importance = pd.DataFrame({'feature': cols, 'importance': model.feature_importances_})\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df_importance.sort_values('importance', ascending=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d063f24e0>]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_val, y_pred - y_val, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration params are copied from @artgor kernel:\n",
    "# https://www.kaggle.com/artgor/brute-force-feature-engineering\n",
    "if False:\n",
    "    LGB_PARAMS = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.2,\n",
    "        'num_leaves': 128,\n",
    "        'min_child_samples': 79,\n",
    "        'max_depth': 9,\n",
    "        'subsample_freq': 1,\n",
    "        'subsample': 0.9,\n",
    "        'bagging_seed': 11,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.3,\n",
    "        'colsample_bytree': 1.0\n",
    "    }\n",
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.2,\n",
    "    'num_leaves': 64,\n",
    "    'min_child_samples': 60,\n",
    "    'max_depth': 6,\n",
    "    'subsample_freq': 1,\n",
    "    'subsample': 0.9,\n",
    "    'bagging_seed': 11,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.3,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 500 rounds.\n",
      "[100]\ttraining's l1: 1.55161\tvalid_1's l1: 1.58178\n",
      "[200]\ttraining's l1: 1.36037\tvalid_1's l1: 1.40363\n",
      "[300]\ttraining's l1: 1.25043\tvalid_1's l1: 1.30687\n",
      "[400]\ttraining's l1: 1.17537\tvalid_1's l1: 1.24248\n",
      "[500]\ttraining's l1: 1.11944\tvalid_1's l1: 1.19707\n",
      "[600]\ttraining's l1: 1.07301\tvalid_1's l1: 1.16039\n",
      "[700]\ttraining's l1: 1.0329\tvalid_1's l1: 1.12977\n",
      "[800]\ttraining's l1: 1.00001\tvalid_1's l1: 1.10551\n",
      "[900]\ttraining's l1: 0.970685\tvalid_1's l1: 1.08476\n",
      "[1000]\ttraining's l1: 0.945939\tvalid_1's l1: 1.06762\n",
      "[1100]\ttraining's l1: 0.923102\tvalid_1's l1: 1.05244\n",
      "[1200]\ttraining's l1: 0.901672\tvalid_1's l1: 1.03821\n",
      "[1300]\ttraining's l1: 0.881791\tvalid_1's l1: 1.02571\n",
      "[1400]\ttraining's l1: 0.863749\tvalid_1's l1: 1.01424\n",
      "[1500]\ttraining's l1: 0.846797\tvalid_1's l1: 1.00393\n",
      "[1600]\ttraining's l1: 0.831073\tvalid_1's l1: 0.994356\n",
      "[1700]\ttraining's l1: 0.816278\tvalid_1's l1: 0.985238\n",
      "[1800]\ttraining's l1: 0.802415\tvalid_1's l1: 0.977053\n",
      "[1900]\ttraining's l1: 0.789684\tvalid_1's l1: 0.969895\n",
      "[2000]\ttraining's l1: 0.777118\tvalid_1's l1: 0.962716\n",
      "[2100]\ttraining's l1: 0.765227\tvalid_1's l1: 0.956114\n",
      "[2200]\ttraining's l1: 0.754224\tvalid_1's l1: 0.950091\n",
      "[2300]\ttraining's l1: 0.743298\tvalid_1's l1: 0.944009\n",
      "[2400]\ttraining's l1: 0.733062\tvalid_1's l1: 0.938872\n",
      "[2500]\ttraining's l1: 0.723062\tvalid_1's l1: 0.933566\n",
      "[2600]\ttraining's l1: 0.713567\tvalid_1's l1: 0.928729\n",
      "[2700]\ttraining's l1: 0.704388\tvalid_1's l1: 0.924137\n",
      "[2800]\ttraining's l1: 0.695591\tvalid_1's l1: 0.919668\n",
      "[2900]\ttraining's l1: 0.687489\tvalid_1's l1: 0.915871\n",
      "[3000]\ttraining's l1: 0.679277\tvalid_1's l1: 0.912042\n",
      "[3100]\ttraining's l1: 0.671355\tvalid_1's l1: 0.908438\n",
      "[3200]\ttraining's l1: 0.663302\tvalid_1's l1: 0.904632\n",
      "[3300]\ttraining's l1: 0.655655\tvalid_1's l1: 0.901018\n",
      "[3400]\ttraining's l1: 0.648501\tvalid_1's l1: 0.898014\n",
      "[3500]\ttraining's l1: 0.641445\tvalid_1's l1: 0.894624\n",
      "[3600]\ttraining's l1: 0.63452\tvalid_1's l1: 0.891751\n",
      "[3700]\ttraining's l1: 0.627739\tvalid_1's l1: 0.888785\n",
      "[3800]\ttraining's l1: 0.620982\tvalid_1's l1: 0.885895\n",
      "[3900]\ttraining's l1: 0.614428\tvalid_1's l1: 0.882865\n",
      "[4000]\ttraining's l1: 0.607932\tvalid_1's l1: 0.880371\n",
      "[4100]\ttraining's l1: 0.60177\tvalid_1's l1: 0.877965\n",
      "[4200]\ttraining's l1: 0.596106\tvalid_1's l1: 0.875762\n",
      "[4300]\ttraining's l1: 0.590541\tvalid_1's l1: 0.873568\n",
      "[4400]\ttraining's l1: 0.584896\tvalid_1's l1: 0.871388\n",
      "[4500]\ttraining's l1: 0.579408\tvalid_1's l1: 0.869061\n",
      "[4600]\ttraining's l1: 0.573909\tvalid_1's l1: 0.866946\n",
      "[4700]\ttraining's l1: 0.568747\tvalid_1's l1: 0.864967\n",
      "[4800]\ttraining's l1: 0.563225\tvalid_1's l1: 0.862937\n",
      "[4900]\ttraining's l1: 0.558283\tvalid_1's l1: 0.861176\n",
      "[5000]\ttraining's l1: 0.553403\tvalid_1's l1: 0.859198\n",
      "[5100]\ttraining's l1: 0.548351\tvalid_1's l1: 0.85719\n",
      "[5200]\ttraining's l1: 0.543329\tvalid_1's l1: 0.855197\n",
      "[5300]\ttraining's l1: 0.538546\tvalid_1's l1: 0.85339\n",
      "[5400]\ttraining's l1: 0.533875\tvalid_1's l1: 0.851538\n",
      "[5500]\ttraining's l1: 0.529164\tvalid_1's l1: 0.849938\n",
      "[5600]\ttraining's l1: 0.524711\tvalid_1's l1: 0.848439\n",
      "[5700]\ttraining's l1: 0.520353\tvalid_1's l1: 0.846992\n",
      "[5800]\ttraining's l1: 0.516123\tvalid_1's l1: 0.845644\n",
      "[5900]\ttraining's l1: 0.51186\tvalid_1's l1: 0.844113\n",
      "[6000]\ttraining's l1: 0.507801\tvalid_1's l1: 0.842696\n",
      "[6100]\ttraining's l1: 0.503808\tvalid_1's l1: 0.841402\n",
      "[6200]\ttraining's l1: 0.499803\tvalid_1's l1: 0.839989\n",
      "[6300]\ttraining's l1: 0.495798\tvalid_1's l1: 0.838683\n",
      "[6400]\ttraining's l1: 0.491897\tvalid_1's l1: 0.837361\n",
      "[6500]\ttraining's l1: 0.488334\tvalid_1's l1: 0.836215\n",
      "[6600]\ttraining's l1: 0.484491\tvalid_1's l1: 0.834943\n",
      "[6700]\ttraining's l1: 0.480836\tvalid_1's l1: 0.833737\n",
      "[6800]\ttraining's l1: 0.477285\tvalid_1's l1: 0.832583\n",
      "[6900]\ttraining's l1: 0.473601\tvalid_1's l1: 0.831433\n",
      "[7000]\ttraining's l1: 0.470228\tvalid_1's l1: 0.830231\n",
      "[7100]\ttraining's l1: 0.46664\tvalid_1's l1: 0.829008\n",
      "[7200]\ttraining's l1: 0.463132\tvalid_1's l1: 0.828065\n",
      "[7300]\ttraining's l1: 0.459818\tvalid_1's l1: 0.82709\n",
      "[7400]\ttraining's l1: 0.456522\tvalid_1's l1: 0.8262\n",
      "[7500]\ttraining's l1: 0.453173\tvalid_1's l1: 0.825222\n",
      "[7600]\ttraining's l1: 0.449877\tvalid_1's l1: 0.824142\n",
      "[7700]\ttraining's l1: 0.446706\tvalid_1's l1: 0.823213\n",
      "[7800]\ttraining's l1: 0.443568\tvalid_1's l1: 0.822326\n",
      "[7900]\ttraining's l1: 0.440535\tvalid_1's l1: 0.821534\n",
      "[8000]\ttraining's l1: 0.43741\tvalid_1's l1: 0.820538\n",
      "[8100]\ttraining's l1: 0.434243\tvalid_1's l1: 0.819552\n",
      "[8200]\ttraining's l1: 0.431221\tvalid_1's l1: 0.818659\n",
      "[8300]\ttraining's l1: 0.428361\tvalid_1's l1: 0.817914\n",
      "[8400]\ttraining's l1: 0.425505\tvalid_1's l1: 0.817076\n",
      "[8500]\ttraining's l1: 0.422747\tvalid_1's l1: 0.816357\n",
      "[8600]\ttraining's l1: 0.419989\tvalid_1's l1: 0.815615\n",
      "[8700]\ttraining's l1: 0.41716\tvalid_1's l1: 0.81475\n",
      "[8800]\ttraining's l1: 0.41442\tvalid_1's l1: 0.814019\n",
      "[8900]\ttraining's l1: 0.411697\tvalid_1's l1: 0.813217\n",
      "[9000]\ttraining's l1: 0.409004\tvalid_1's l1: 0.812421\n",
      "[9100]\ttraining's l1: 0.406281\tvalid_1's l1: 0.811719\n",
      "[9200]\ttraining's l1: 0.403759\tvalid_1's l1: 0.811039\n",
      "[9300]\ttraining's l1: 0.401184\tvalid_1's l1: 0.810249\n",
      "[9400]\ttraining's l1: 0.398703\tvalid_1's l1: 0.809657\n",
      "[9500]\ttraining's l1: 0.396166\tvalid_1's l1: 0.809045\n",
      "[9600]\ttraining's l1: 0.393729\tvalid_1's l1: 0.808284\n",
      "[9700]\ttraining's l1: 0.391334\tvalid_1's l1: 0.807639\n",
      "[9800]\ttraining's l1: 0.388746\tvalid_1's l1: 0.806891\n",
      "[9900]\ttraining's l1: 0.38638\tvalid_1's l1: 0.806264\n",
      "[10000]\ttraining's l1: 0.383939\tvalid_1's l1: 0.805576\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.383939\tvalid_1's l1: 0.805576\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.21619738888727927"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LGBMRegressor(**LGB_PARAMS, n_estimators=10000, n_jobs = -1)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "        verbose=100, early_stopping_rounds=500)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "np.log(mean_absolute_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad score for such a simple set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    141884.000000\n",
       "mean     0.005461     \n",
       "std      1.217053     \n",
       "min     -45.175956    \n",
       "25%     -0.511672     \n",
       "50%      0.015885     \n",
       "75%      0.528240     \n",
       "max      23.178317    \n",
       "Name: scalar_coupling_constant, dtype: float64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = y_pred- y_val\n",
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('scalar_coupling_constant')\n",
    "cols\n",
    "df_importance = pd.DataFrame({'feature': cols, 'importance': model.feature_importances_})\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df_importance.sort_values('importance', ascending=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25d236fd630>]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_val, y_pred- y_val, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(2,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's funny, but looks like atom types aren't used a lot in the final decision. Quite a contrary to what a man would do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_y_data(some_csv, coupling_type, n_atoms):\n",
    "    full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    \n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    print(df.columns)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1)\n",
    "        y_data = df['scalar_coupling_constant']\n",
    "    else:\n",
    "        X_data = df\n",
    "        y_data = None\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_for_one_coupling_type(coupling_type, submission, n_atoms, n_folds=5, n_splits=5, random_state=128):\n",
    "    model_type =  'lgb' #lgb  cat\n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    \n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms)\n",
    "    columns = X_data.columns \n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "\n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        #X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        #y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "        X_train, X_val = X_data[columns].iloc[train_index], X_data[columns].iloc[val_index]\n",
    "        y_train, y_val = y_data.iloc[train_index], y_data.iloc[val_index]\n",
    "\n",
    "        model = \"\"\n",
    "        if model_type == 'lgb':\n",
    "            model = LGBMRegressor(**LGB_PARAMS, n_estimators=10000, n_jobs = -1)\n",
    "            #model = LGBMRegressor(**LGB_PARAMS, n_estimators=6000, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "                verbose=100, early_stopping_rounds=200)\n",
    "        \n",
    "        if model_type == 'cat': \n",
    "            categorical_features = [col for col in X_train if col.startswith('atom_')]\n",
    "            model = CatBoostRegressor(eval_metric='MAE', **CAT_PARAMS, loss_function='MAE')\n",
    "            X_trainGlob = X_train\n",
    "            model.fit(X_train, y_train, eval_set=((X_val, y_val)), \n",
    "                      cat_features = categorical_features,\n",
    "                      use_best_model=True,\n",
    "                      verbose=False)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        \n",
    "        cv_score += val_score / n_folds\n",
    "        y_pred += model.predict(X_test) / n_folds\n",
    "        \n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a separate model for each type of coupling. Dataset is split into 5 pieces and in this kernel we will use only 3 folds for speed up.\n",
    "\n",
    "Main tuning parameter is the number of atoms. I took good numbers, but accuracy can be improved a bit by tuning them for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    model_params = {\n",
    "        '1JHC': 10,\n",
    "        '1JHN': 7,    \n",
    "        '2JHH': 9,\n",
    "        '2JHN': 9,\n",
    "        '2JHC': 9,\n",
    "        '3JHH': 9,\n",
    "        '3JHC': 10,\n",
    "        '3JHN': 10\n",
    "    }\n",
    "model_params = {\n",
    "        '1JHC': 10,\n",
    "        '1JHN': 7,    \n",
    "        '2JHH': 9,\n",
    "        '2JHN': 9,\n",
    "        '2JHC': 9,\n",
    "        '3JHH': 9,\n",
    "        '3JHC': 10,\n",
    "        '3JHN': 10\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking cross-validation scores for each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training Model for 1JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.55222\tvalid_1's l1: 1.58407\n",
      "[200]\ttraining's l1: 1.36133\tvalid_1's l1: 1.40663\n",
      "[300]\ttraining's l1: 1.254\tvalid_1's l1: 1.3116\n",
      "[400]\ttraining's l1: 1.17299\tvalid_1's l1: 1.24183\n",
      "[500]\ttraining's l1: 1.11469\tvalid_1's l1: 1.19375\n",
      "[600]\ttraining's l1: 1.06672\tvalid_1's l1: 1.15515\n",
      "[700]\ttraining's l1: 1.02855\tvalid_1's l1: 1.12588\n",
      "[800]\ttraining's l1: 0.996094\tvalid_1's l1: 1.1017\n",
      "[900]\ttraining's l1: 0.965993\tvalid_1's l1: 1.07997\n",
      "[1000]\ttraining's l1: 0.940724\tvalid_1's l1: 1.0626\n",
      "[1100]\ttraining's l1: 0.916484\tvalid_1's l1: 1.04587\n",
      "[1200]\ttraining's l1: 0.895513\tvalid_1's l1: 1.03196\n",
      "[1300]\ttraining's l1: 0.877219\tvalid_1's l1: 1.02013\n",
      "[1400]\ttraining's l1: 0.858941\tvalid_1's l1: 1.00912\n",
      "[1500]\ttraining's l1: 0.842987\tvalid_1's l1: 0.999141\n",
      "[1600]\ttraining's l1: 0.827086\tvalid_1's l1: 0.989837\n",
      "[1700]\ttraining's l1: 0.812343\tvalid_1's l1: 0.981197\n",
      "[1800]\ttraining's l1: 0.798906\tvalid_1's l1: 0.973477\n",
      "[1900]\ttraining's l1: 0.786891\tvalid_1's l1: 0.966755\n",
      "[2000]\ttraining's l1: 0.774703\tvalid_1's l1: 0.96022\n",
      "[2100]\ttraining's l1: 0.763279\tvalid_1's l1: 0.954264\n",
      "[2200]\ttraining's l1: 0.751693\tvalid_1's l1: 0.947732\n",
      "[2300]\ttraining's l1: 0.740849\tvalid_1's l1: 0.941928\n",
      "[2400]\ttraining's l1: 0.730015\tvalid_1's l1: 0.936171\n",
      "[2500]\ttraining's l1: 0.720287\tvalid_1's l1: 0.931245\n",
      "[2600]\ttraining's l1: 0.710922\tvalid_1's l1: 0.92646\n",
      "[2700]\ttraining's l1: 0.701757\tvalid_1's l1: 0.922046\n",
      "[2800]\ttraining's l1: 0.692762\tvalid_1's l1: 0.917375\n",
      "[2900]\ttraining's l1: 0.684378\tvalid_1's l1: 0.913586\n",
      "[3000]\ttraining's l1: 0.676094\tvalid_1's l1: 0.909669\n",
      "[3100]\ttraining's l1: 0.668185\tvalid_1's l1: 0.90627\n",
      "[3200]\ttraining's l1: 0.660534\tvalid_1's l1: 0.902905\n",
      "[3300]\ttraining's l1: 0.653407\tvalid_1's l1: 0.899589\n",
      "[3400]\ttraining's l1: 0.646495\tvalid_1's l1: 0.896598\n",
      "[3500]\ttraining's l1: 0.639564\tvalid_1's l1: 0.893545\n",
      "[3600]\ttraining's l1: 0.632693\tvalid_1's l1: 0.890451\n",
      "[3700]\ttraining's l1: 0.626298\tvalid_1's l1: 0.887899\n",
      "[3800]\ttraining's l1: 0.619554\tvalid_1's l1: 0.884728\n",
      "[3900]\ttraining's l1: 0.61312\tvalid_1's l1: 0.881972\n",
      "[4000]\ttraining's l1: 0.606856\tvalid_1's l1: 0.879132\n",
      "[4100]\ttraining's l1: 0.601039\tvalid_1's l1: 0.876726\n",
      "[4200]\ttraining's l1: 0.594931\tvalid_1's l1: 0.874133\n",
      "[4300]\ttraining's l1: 0.58902\tvalid_1's l1: 0.87186\n",
      "[4400]\ttraining's l1: 0.583186\tvalid_1's l1: 0.869477\n",
      "[4500]\ttraining's l1: 0.577698\tvalid_1's l1: 0.867282\n",
      "[4600]\ttraining's l1: 0.572326\tvalid_1's l1: 0.86507\n",
      "[4700]\ttraining's l1: 0.56697\tvalid_1's l1: 0.863155\n",
      "[4800]\ttraining's l1: 0.561853\tvalid_1's l1: 0.861164\n",
      "[4900]\ttraining's l1: 0.556856\tvalid_1's l1: 0.859268\n",
      "[5000]\ttraining's l1: 0.551893\tvalid_1's l1: 0.857125\n",
      "[5100]\ttraining's l1: 0.547088\tvalid_1's l1: 0.855341\n",
      "[5200]\ttraining's l1: 0.542441\tvalid_1's l1: 0.853766\n",
      "[5300]\ttraining's l1: 0.537788\tvalid_1's l1: 0.851958\n",
      "[5400]\ttraining's l1: 0.53315\tvalid_1's l1: 0.850399\n",
      "[5500]\ttraining's l1: 0.528856\tvalid_1's l1: 0.848768\n",
      "[5600]\ttraining's l1: 0.524228\tvalid_1's l1: 0.847002\n",
      "[5700]\ttraining's l1: 0.519733\tvalid_1's l1: 0.84548\n",
      "[5800]\ttraining's l1: 0.515583\tvalid_1's l1: 0.843958\n",
      "[5900]\ttraining's l1: 0.511479\tvalid_1's l1: 0.842513\n",
      "[6000]\ttraining's l1: 0.507385\tvalid_1's l1: 0.840895\n",
      "[6100]\ttraining's l1: 0.50342\tvalid_1's l1: 0.839661\n",
      "[6200]\ttraining's l1: 0.499553\tvalid_1's l1: 0.838278\n",
      "[6300]\ttraining's l1: 0.495672\tvalid_1's l1: 0.837003\n",
      "[6400]\ttraining's l1: 0.491931\tvalid_1's l1: 0.83571\n",
      "[6500]\ttraining's l1: 0.488189\tvalid_1's l1: 0.834513\n",
      "[6600]\ttraining's l1: 0.484335\tvalid_1's l1: 0.833236\n",
      "[6700]\ttraining's l1: 0.480732\tvalid_1's l1: 0.832024\n",
      "[6800]\ttraining's l1: 0.477231\tvalid_1's l1: 0.830982\n",
      "[6900]\ttraining's l1: 0.47374\tvalid_1's l1: 0.82984\n",
      "[7000]\ttraining's l1: 0.470255\tvalid_1's l1: 0.828798\n",
      "[7100]\ttraining's l1: 0.466826\tvalid_1's l1: 0.827696\n",
      "[7200]\ttraining's l1: 0.463571\tvalid_1's l1: 0.826592\n",
      "[7300]\ttraining's l1: 0.460115\tvalid_1's l1: 0.825524\n",
      "[7400]\ttraining's l1: 0.456999\tvalid_1's l1: 0.824582\n",
      "[7500]\ttraining's l1: 0.453695\tvalid_1's l1: 0.823489\n",
      "[7600]\ttraining's l1: 0.450373\tvalid_1's l1: 0.822326\n",
      "[7700]\ttraining's l1: 0.447251\tvalid_1's l1: 0.821323\n",
      "[7800]\ttraining's l1: 0.444061\tvalid_1's l1: 0.820399\n",
      "[7900]\ttraining's l1: 0.441119\tvalid_1's l1: 0.819513\n",
      "[8000]\ttraining's l1: 0.438023\tvalid_1's l1: 0.818629\n",
      "[8100]\ttraining's l1: 0.434902\tvalid_1's l1: 0.817761\n",
      "[8200]\ttraining's l1: 0.431956\tvalid_1's l1: 0.816768\n",
      "[8300]\ttraining's l1: 0.429034\tvalid_1's l1: 0.815941\n",
      "[8400]\ttraining's l1: 0.426157\tvalid_1's l1: 0.815089\n",
      "[8500]\ttraining's l1: 0.423378\tvalid_1's l1: 0.814337\n",
      "[8600]\ttraining's l1: 0.420584\tvalid_1's l1: 0.813447\n",
      "[8700]\ttraining's l1: 0.41783\tvalid_1's l1: 0.81267\n",
      "[8800]\ttraining's l1: 0.41496\tvalid_1's l1: 0.811823\n",
      "[8900]\ttraining's l1: 0.412195\tvalid_1's l1: 0.811025\n",
      "[9000]\ttraining's l1: 0.409496\tvalid_1's l1: 0.810289\n",
      "[9100]\ttraining's l1: 0.406853\tvalid_1's l1: 0.809398\n",
      "[9200]\ttraining's l1: 0.404289\tvalid_1's l1: 0.808567\n",
      "[9300]\ttraining's l1: 0.401628\tvalid_1's l1: 0.807698\n",
      "[9400]\ttraining's l1: 0.399057\tvalid_1's l1: 0.806999\n",
      "[9500]\ttraining's l1: 0.3966\tvalid_1's l1: 0.806315\n",
      "[9600]\ttraining's l1: 0.394055\tvalid_1's l1: 0.805652\n",
      "[9700]\ttraining's l1: 0.391714\tvalid_1's l1: 0.805057\n",
      "[9800]\ttraining's l1: 0.389183\tvalid_1's l1: 0.804447\n",
      "[9900]\ttraining's l1: 0.386745\tvalid_1's l1: 0.803785\n",
      "[10000]\ttraining's l1: 0.384363\tvalid_1's l1: 0.803131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.384363\tvalid_1's l1: 0.803131\n",
      "1JHC Fold 0, logMAE: -0.2192375962197757\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.56643\tvalid_1's l1: 1.58465\n",
      "[200]\ttraining's l1: 1.35784\tvalid_1's l1: 1.39273\n",
      "[300]\ttraining's l1: 1.24777\tvalid_1's l1: 1.29701\n",
      "[400]\ttraining's l1: 1.17262\tvalid_1's l1: 1.23347\n",
      "[500]\ttraining's l1: 1.11567\tvalid_1's l1: 1.18744\n",
      "[600]\ttraining's l1: 1.06901\tvalid_1's l1: 1.15138\n",
      "[700]\ttraining's l1: 1.02921\tvalid_1's l1: 1.12124\n",
      "[800]\ttraining's l1: 0.99727\tvalid_1's l1: 1.09826\n",
      "[900]\ttraining's l1: 0.967652\tvalid_1's l1: 1.07678\n",
      "[1000]\ttraining's l1: 0.941524\tvalid_1's l1: 1.05936\n",
      "[1100]\ttraining's l1: 0.917413\tvalid_1's l1: 1.04303\n",
      "[1200]\ttraining's l1: 0.89698\tvalid_1's l1: 1.02909\n",
      "[1300]\ttraining's l1: 0.878112\tvalid_1's l1: 1.01707\n",
      "[1400]\ttraining's l1: 0.860642\tvalid_1's l1: 1.00585\n",
      "[1500]\ttraining's l1: 0.844059\tvalid_1's l1: 0.995505\n",
      "[1600]\ttraining's l1: 0.828574\tvalid_1's l1: 0.98618\n",
      "[1700]\ttraining's l1: 0.814776\tvalid_1's l1: 0.978347\n",
      "[1800]\ttraining's l1: 0.800598\tvalid_1's l1: 0.970141\n",
      "[1900]\ttraining's l1: 0.787073\tvalid_1's l1: 0.962441\n",
      "[2000]\ttraining's l1: 0.774841\tvalid_1's l1: 0.955544\n",
      "[2100]\ttraining's l1: 0.763424\tvalid_1's l1: 0.949004\n",
      "[2200]\ttraining's l1: 0.751791\tvalid_1's l1: 0.942689\n",
      "[2300]\ttraining's l1: 0.741437\tvalid_1's l1: 0.937169\n",
      "[2400]\ttraining's l1: 0.730466\tvalid_1's l1: 0.931457\n",
      "[2500]\ttraining's l1: 0.720988\tvalid_1's l1: 0.926471\n",
      "[2600]\ttraining's l1: 0.711132\tvalid_1's l1: 0.921585\n",
      "[2700]\ttraining's l1: 0.701918\tvalid_1's l1: 0.916999\n",
      "[2800]\ttraining's l1: 0.693541\tvalid_1's l1: 0.913046\n",
      "[2900]\ttraining's l1: 0.685136\tvalid_1's l1: 0.909084\n",
      "[3000]\ttraining's l1: 0.676913\tvalid_1's l1: 0.905188\n",
      "[3100]\ttraining's l1: 0.668888\tvalid_1's l1: 0.901388\n",
      "[3200]\ttraining's l1: 0.660681\tvalid_1's l1: 0.897425\n",
      "[3300]\ttraining's l1: 0.652954\tvalid_1's l1: 0.893924\n",
      "[3400]\ttraining's l1: 0.645575\tvalid_1's l1: 0.890301\n",
      "[3500]\ttraining's l1: 0.638334\tvalid_1's l1: 0.887054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600]\ttraining's l1: 0.631981\tvalid_1's l1: 0.884295\n",
      "[3700]\ttraining's l1: 0.625224\tvalid_1's l1: 0.881349\n",
      "[3800]\ttraining's l1: 0.618516\tvalid_1's l1: 0.87827\n",
      "[3900]\ttraining's l1: 0.612379\tvalid_1's l1: 0.875794\n",
      "[4000]\ttraining's l1: 0.605921\tvalid_1's l1: 0.873401\n",
      "[4100]\ttraining's l1: 0.59991\tvalid_1's l1: 0.870891\n",
      "[4200]\ttraining's l1: 0.593794\tvalid_1's l1: 0.868508\n",
      "[4300]\ttraining's l1: 0.587888\tvalid_1's l1: 0.866083\n",
      "[4400]\ttraining's l1: 0.582058\tvalid_1's l1: 0.863794\n",
      "[4500]\ttraining's l1: 0.576815\tvalid_1's l1: 0.861778\n",
      "[4600]\ttraining's l1: 0.571276\tvalid_1's l1: 0.85968\n",
      "[4700]\ttraining's l1: 0.565848\tvalid_1's l1: 0.857582\n",
      "[4800]\ttraining's l1: 0.560746\tvalid_1's l1: 0.855437\n",
      "[4900]\ttraining's l1: 0.555819\tvalid_1's l1: 0.853401\n",
      "[5000]\ttraining's l1: 0.550853\tvalid_1's l1: 0.851599\n",
      "[5100]\ttraining's l1: 0.546127\tvalid_1's l1: 0.849888\n",
      "[5200]\ttraining's l1: 0.541229\tvalid_1's l1: 0.848161\n",
      "[5300]\ttraining's l1: 0.536477\tvalid_1's l1: 0.84634\n",
      "[5400]\ttraining's l1: 0.531704\tvalid_1's l1: 0.844691\n",
      "[5500]\ttraining's l1: 0.527433\tvalid_1's l1: 0.843175\n",
      "[5600]\ttraining's l1: 0.522989\tvalid_1's l1: 0.84162\n",
      "[5700]\ttraining's l1: 0.518697\tvalid_1's l1: 0.840259\n",
      "[5800]\ttraining's l1: 0.514474\tvalid_1's l1: 0.838714\n",
      "[5900]\ttraining's l1: 0.510421\tvalid_1's l1: 0.837305\n",
      "[6000]\ttraining's l1: 0.506259\tvalid_1's l1: 0.835973\n",
      "[6100]\ttraining's l1: 0.502235\tvalid_1's l1: 0.834492\n",
      "[6200]\ttraining's l1: 0.498005\tvalid_1's l1: 0.833101\n",
      "[6300]\ttraining's l1: 0.494185\tvalid_1's l1: 0.831825\n",
      "[6400]\ttraining's l1: 0.490349\tvalid_1's l1: 0.830563\n",
      "[6500]\ttraining's l1: 0.486502\tvalid_1's l1: 0.829239\n",
      "[6600]\ttraining's l1: 0.482901\tvalid_1's l1: 0.82806\n",
      "[6700]\ttraining's l1: 0.479135\tvalid_1's l1: 0.826873\n",
      "[6800]\ttraining's l1: 0.475693\tvalid_1's l1: 0.825893\n",
      "[6900]\ttraining's l1: 0.472233\tvalid_1's l1: 0.824737\n",
      "[7000]\ttraining's l1: 0.468799\tvalid_1's l1: 0.823622\n",
      "[7100]\ttraining's l1: 0.465321\tvalid_1's l1: 0.822461\n",
      "[7200]\ttraining's l1: 0.46195\tvalid_1's l1: 0.821392\n",
      "[7300]\ttraining's l1: 0.45865\tvalid_1's l1: 0.820558\n",
      "[7400]\ttraining's l1: 0.455307\tvalid_1's l1: 0.819586\n",
      "[7500]\ttraining's l1: 0.452044\tvalid_1's l1: 0.818537\n",
      "[7600]\ttraining's l1: 0.448937\tvalid_1's l1: 0.817725\n",
      "[7700]\ttraining's l1: 0.445917\tvalid_1's l1: 0.816701\n",
      "[7800]\ttraining's l1: 0.442865\tvalid_1's l1: 0.815858\n",
      "[7900]\ttraining's l1: 0.439638\tvalid_1's l1: 0.814803\n",
      "[8000]\ttraining's l1: 0.436544\tvalid_1's l1: 0.814004\n",
      "[8100]\ttraining's l1: 0.433565\tvalid_1's l1: 0.813031\n",
      "[8200]\ttraining's l1: 0.430702\tvalid_1's l1: 0.812237\n",
      "[8300]\ttraining's l1: 0.427825\tvalid_1's l1: 0.811493\n",
      "[8400]\ttraining's l1: 0.424826\tvalid_1's l1: 0.810577\n",
      "[8500]\ttraining's l1: 0.421959\tvalid_1's l1: 0.809819\n",
      "[8600]\ttraining's l1: 0.419127\tvalid_1's l1: 0.809096\n",
      "[8700]\ttraining's l1: 0.41646\tvalid_1's l1: 0.808292\n",
      "[8800]\ttraining's l1: 0.413595\tvalid_1's l1: 0.80752\n",
      "[8900]\ttraining's l1: 0.410851\tvalid_1's l1: 0.806843\n",
      "[9000]\ttraining's l1: 0.408138\tvalid_1's l1: 0.806145\n",
      "[9100]\ttraining's l1: 0.405541\tvalid_1's l1: 0.805469\n",
      "[9200]\ttraining's l1: 0.402788\tvalid_1's l1: 0.804758\n",
      "[9300]\ttraining's l1: 0.400193\tvalid_1's l1: 0.804019\n",
      "[9400]\ttraining's l1: 0.397694\tvalid_1's l1: 0.803278\n",
      "[9500]\ttraining's l1: 0.395095\tvalid_1's l1: 0.802601\n",
      "[9600]\ttraining's l1: 0.39254\tvalid_1's l1: 0.801865\n",
      "[9700]\ttraining's l1: 0.390051\tvalid_1's l1: 0.801152\n",
      "[9800]\ttraining's l1: 0.387649\tvalid_1's l1: 0.800413\n",
      "[9900]\ttraining's l1: 0.385295\tvalid_1's l1: 0.799883\n",
      "[10000]\ttraining's l1: 0.382886\tvalid_1's l1: 0.799289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.382886\tvalid_1's l1: 0.799289\n",
      "1JHC Fold 1, logMAE: -0.22403290014777905\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 1.56693\tvalid_1's l1: 1.58971\n",
      "[200]\ttraining's l1: 1.36398\tvalid_1's l1: 1.40156\n",
      "[300]\ttraining's l1: 1.25538\tvalid_1's l1: 1.30446\n",
      "[400]\ttraining's l1: 1.1803\tvalid_1's l1: 1.24061\n",
      "[500]\ttraining's l1: 1.12164\tvalid_1's l1: 1.19256\n",
      "[600]\ttraining's l1: 1.07528\tvalid_1's l1: 1.1557\n",
      "[700]\ttraining's l1: 1.03557\tvalid_1's l1: 1.1254\n",
      "[800]\ttraining's l1: 1.00135\tvalid_1's l1: 1.10044\n",
      "[900]\ttraining's l1: 0.972605\tvalid_1's l1: 1.08011\n",
      "[1000]\ttraining's l1: 0.946465\tvalid_1's l1: 1.06194\n",
      "[1100]\ttraining's l1: 0.924163\tvalid_1's l1: 1.04676\n",
      "[1200]\ttraining's l1: 0.90379\tvalid_1's l1: 1.03297\n",
      "[1300]\ttraining's l1: 0.884175\tvalid_1's l1: 1.02074\n",
      "[1400]\ttraining's l1: 0.866269\tvalid_1's l1: 1.00987\n",
      "[1500]\ttraining's l1: 0.850256\tvalid_1's l1: 0.999933\n",
      "[1600]\ttraining's l1: 0.833336\tvalid_1's l1: 0.988999\n",
      "[1700]\ttraining's l1: 0.818221\tvalid_1's l1: 0.980046\n",
      "[1800]\ttraining's l1: 0.80529\tvalid_1's l1: 0.972567\n",
      "[1900]\ttraining's l1: 0.792413\tvalid_1's l1: 0.96512\n",
      "[2000]\ttraining's l1: 0.77955\tvalid_1's l1: 0.957728\n",
      "[2100]\ttraining's l1: 0.767935\tvalid_1's l1: 0.951571\n",
      "[2200]\ttraining's l1: 0.756089\tvalid_1's l1: 0.945333\n",
      "[2300]\ttraining's l1: 0.745711\tvalid_1's l1: 0.939603\n",
      "[2400]\ttraining's l1: 0.735949\tvalid_1's l1: 0.93438\n",
      "[2500]\ttraining's l1: 0.725852\tvalid_1's l1: 0.929042\n",
      "[2600]\ttraining's l1: 0.716308\tvalid_1's l1: 0.924155\n",
      "[2700]\ttraining's l1: 0.707419\tvalid_1's l1: 0.919749\n",
      "[2800]\ttraining's l1: 0.698408\tvalid_1's l1: 0.91555\n",
      "[2900]\ttraining's l1: 0.689794\tvalid_1's l1: 0.911229\n",
      "[3000]\ttraining's l1: 0.681557\tvalid_1's l1: 0.907151\n",
      "[3100]\ttraining's l1: 0.673618\tvalid_1's l1: 0.903392\n",
      "[3200]\ttraining's l1: 0.666185\tvalid_1's l1: 0.900082\n",
      "[3300]\ttraining's l1: 0.658493\tvalid_1's l1: 0.896415\n",
      "[3400]\ttraining's l1: 0.651138\tvalid_1's l1: 0.892896\n",
      "[3500]\ttraining's l1: 0.644245\tvalid_1's l1: 0.889794\n",
      "[3600]\ttraining's l1: 0.637219\tvalid_1's l1: 0.886561\n",
      "[3700]\ttraining's l1: 0.63078\tvalid_1's l1: 0.883741\n",
      "[3800]\ttraining's l1: 0.624289\tvalid_1's l1: 0.881073\n",
      "[3900]\ttraining's l1: 0.61797\tvalid_1's l1: 0.87853\n",
      "[4000]\ttraining's l1: 0.611966\tvalid_1's l1: 0.876188\n",
      "[4100]\ttraining's l1: 0.605888\tvalid_1's l1: 0.873583\n",
      "[4200]\ttraining's l1: 0.599702\tvalid_1's l1: 0.870896\n",
      "[4300]\ttraining's l1: 0.593907\tvalid_1's l1: 0.868576\n",
      "[4400]\ttraining's l1: 0.588079\tvalid_1's l1: 0.86599\n",
      "[4500]\ttraining's l1: 0.582612\tvalid_1's l1: 0.863968\n",
      "[4600]\ttraining's l1: 0.577324\tvalid_1's l1: 0.862045\n",
      "[4700]\ttraining's l1: 0.572034\tvalid_1's l1: 0.859959\n",
      "[4800]\ttraining's l1: 0.566952\tvalid_1's l1: 0.858255\n",
      "[4900]\ttraining's l1: 0.561904\tvalid_1's l1: 0.856353\n",
      "[5000]\ttraining's l1: 0.556494\tvalid_1's l1: 0.854398\n",
      "[5100]\ttraining's l1: 0.551689\tvalid_1's l1: 0.85259\n",
      "[5200]\ttraining's l1: 0.547097\tvalid_1's l1: 0.85095\n",
      "[5300]\ttraining's l1: 0.542336\tvalid_1's l1: 0.849111\n",
      "[5400]\ttraining's l1: 0.537564\tvalid_1's l1: 0.847321\n",
      "[5500]\ttraining's l1: 0.533116\tvalid_1's l1: 0.845951\n",
      "[5600]\ttraining's l1: 0.528635\tvalid_1's l1: 0.844356\n",
      "[5700]\ttraining's l1: 0.524281\tvalid_1's l1: 0.842856\n",
      "[5800]\ttraining's l1: 0.520089\tvalid_1's l1: 0.841398\n",
      "[5900]\ttraining's l1: 0.515914\tvalid_1's l1: 0.839831\n",
      "[6000]\ttraining's l1: 0.511729\tvalid_1's l1: 0.838535\n",
      "[6100]\ttraining's l1: 0.507695\tvalid_1's l1: 0.837165\n",
      "[6200]\ttraining's l1: 0.503752\tvalid_1's l1: 0.835908\n",
      "[6300]\ttraining's l1: 0.499949\tvalid_1's l1: 0.834716\n",
      "[6400]\ttraining's l1: 0.49605\tvalid_1's l1: 0.833359\n",
      "[6500]\ttraining's l1: 0.492142\tvalid_1's l1: 0.832088\n",
      "[6600]\ttraining's l1: 0.488394\tvalid_1's l1: 0.830767\n",
      "[6700]\ttraining's l1: 0.484683\tvalid_1's l1: 0.829544\n",
      "[6800]\ttraining's l1: 0.480903\tvalid_1's l1: 0.82838\n",
      "[6900]\ttraining's l1: 0.477102\tvalid_1's l1: 0.827002\n",
      "[7000]\ttraining's l1: 0.473573\tvalid_1's l1: 0.825988\n",
      "[7100]\ttraining's l1: 0.470011\tvalid_1's l1: 0.82481\n",
      "[7200]\ttraining's l1: 0.466511\tvalid_1's l1: 0.823757\n",
      "[7300]\ttraining's l1: 0.463056\tvalid_1's l1: 0.822545\n",
      "[7400]\ttraining's l1: 0.45972\tvalid_1's l1: 0.821449\n",
      "[7500]\ttraining's l1: 0.45635\tvalid_1's l1: 0.820375\n",
      "[7600]\ttraining's l1: 0.453043\tvalid_1's l1: 0.819316\n",
      "[7700]\ttraining's l1: 0.449644\tvalid_1's l1: 0.818209\n",
      "[7800]\ttraining's l1: 0.446375\tvalid_1's l1: 0.817246\n",
      "[7900]\ttraining's l1: 0.443228\tvalid_1's l1: 0.816356\n",
      "[8000]\ttraining's l1: 0.440143\tvalid_1's l1: 0.815554\n",
      "[8100]\ttraining's l1: 0.43712\tvalid_1's l1: 0.81464\n",
      "[8200]\ttraining's l1: 0.434134\tvalid_1's l1: 0.813827\n",
      "[8300]\ttraining's l1: 0.431236\tvalid_1's l1: 0.812898\n",
      "[8400]\ttraining's l1: 0.428226\tvalid_1's l1: 0.8119\n",
      "[8500]\ttraining's l1: 0.425274\tvalid_1's l1: 0.811214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8600]\ttraining's l1: 0.422384\tvalid_1's l1: 0.810333\n",
      "[8700]\ttraining's l1: 0.419586\tvalid_1's l1: 0.809607\n",
      "[8800]\ttraining's l1: 0.416853\tvalid_1's l1: 0.80876\n",
      "[8900]\ttraining's l1: 0.414215\tvalid_1's l1: 0.808151\n",
      "[9000]\ttraining's l1: 0.411525\tvalid_1's l1: 0.807454\n",
      "[9100]\ttraining's l1: 0.408947\tvalid_1's l1: 0.806854\n",
      "[9200]\ttraining's l1: 0.406365\tvalid_1's l1: 0.806133\n",
      "[9300]\ttraining's l1: 0.40373\tvalid_1's l1: 0.80533\n",
      "[9400]\ttraining's l1: 0.40117\tvalid_1's l1: 0.804723\n",
      "[9500]\ttraining's l1: 0.398687\tvalid_1's l1: 0.804057\n",
      "[9600]\ttraining's l1: 0.39614\tvalid_1's l1: 0.803376\n",
      "[9700]\ttraining's l1: 0.393622\tvalid_1's l1: 0.802753\n",
      "[9800]\ttraining's l1: 0.391083\tvalid_1's l1: 0.802128\n",
      "[9900]\ttraining's l1: 0.388576\tvalid_1's l1: 0.801427\n",
      "[10000]\ttraining's l1: 0.386215\tvalid_1's l1: 0.80091\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.386215\tvalid_1's l1: 0.80091\n",
      "1JHC Fold 2, logMAE: -0.22200663940382329\n",
      "*** Training Model for 1JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'r_x_1', 'r_x_2',\n",
      "       'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5',\n",
      "       'r_y_6', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'r_x_1', 'r_x_2',\n",
      "       'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5',\n",
      "       'r_y_6', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.605773\tvalid_1's l1: 0.676496\n",
      "[200]\ttraining's l1: 0.509514\tvalid_1's l1: 0.607546\n",
      "[300]\ttraining's l1: 0.451249\tvalid_1's l1: 0.569874\n",
      "[400]\ttraining's l1: 0.412426\tvalid_1's l1: 0.546831\n",
      "[500]\ttraining's l1: 0.381559\tvalid_1's l1: 0.529997\n",
      "[600]\ttraining's l1: 0.35596\tvalid_1's l1: 0.51745\n",
      "[700]\ttraining's l1: 0.334943\tvalid_1's l1: 0.508719\n",
      "[800]\ttraining's l1: 0.31649\tvalid_1's l1: 0.501064\n",
      "[900]\ttraining's l1: 0.30055\tvalid_1's l1: 0.495414\n",
      "[1000]\ttraining's l1: 0.28642\tvalid_1's l1: 0.48985\n",
      "[1100]\ttraining's l1: 0.27286\tvalid_1's l1: 0.484833\n",
      "[1200]\ttraining's l1: 0.261247\tvalid_1's l1: 0.48102\n",
      "[1300]\ttraining's l1: 0.251142\tvalid_1's l1: 0.477697\n",
      "[1400]\ttraining's l1: 0.240684\tvalid_1's l1: 0.47468\n",
      "[1500]\ttraining's l1: 0.231381\tvalid_1's l1: 0.472263\n",
      "[1600]\ttraining's l1: 0.222779\tvalid_1's l1: 0.469362\n",
      "[1700]\ttraining's l1: 0.214507\tvalid_1's l1: 0.46676\n",
      "[1800]\ttraining's l1: 0.206631\tvalid_1's l1: 0.465683\n",
      "[1900]\ttraining's l1: 0.199359\tvalid_1's l1: 0.464006\n",
      "[2000]\ttraining's l1: 0.192738\tvalid_1's l1: 0.462309\n",
      "[2100]\ttraining's l1: 0.186403\tvalid_1's l1: 0.461216\n",
      "[2200]\ttraining's l1: 0.180523\tvalid_1's l1: 0.460035\n",
      "[2300]\ttraining's l1: 0.174891\tvalid_1's l1: 0.459455\n",
      "[2400]\ttraining's l1: 0.169694\tvalid_1's l1: 0.458465\n",
      "[2500]\ttraining's l1: 0.16432\tvalid_1's l1: 0.457359\n",
      "[2600]\ttraining's l1: 0.159392\tvalid_1's l1: 0.456249\n",
      "[2700]\ttraining's l1: 0.154778\tvalid_1's l1: 0.456125\n",
      "[2800]\ttraining's l1: 0.150503\tvalid_1's l1: 0.455536\n",
      "[2900]\ttraining's l1: 0.146266\tvalid_1's l1: 0.454711\n",
      "[3000]\ttraining's l1: 0.141953\tvalid_1's l1: 0.45417\n",
      "[3100]\ttraining's l1: 0.137982\tvalid_1's l1: 0.45329\n",
      "[3200]\ttraining's l1: 0.134199\tvalid_1's l1: 0.453077\n",
      "[3300]\ttraining's l1: 0.130828\tvalid_1's l1: 0.452795\n",
      "[3400]\ttraining's l1: 0.127382\tvalid_1's l1: 0.452465\n",
      "[3500]\ttraining's l1: 0.124172\tvalid_1's l1: 0.452215\n",
      "[3600]\ttraining's l1: 0.121248\tvalid_1's l1: 0.451736\n",
      "[3700]\ttraining's l1: 0.118306\tvalid_1's l1: 0.451337\n",
      "[3800]\ttraining's l1: 0.115398\tvalid_1's l1: 0.450812\n",
      "[3900]\ttraining's l1: 0.112522\tvalid_1's l1: 0.450476\n",
      "[4000]\ttraining's l1: 0.109787\tvalid_1's l1: 0.450286\n",
      "[4100]\ttraining's l1: 0.107058\tvalid_1's l1: 0.450082\n",
      "[4200]\ttraining's l1: 0.104484\tvalid_1's l1: 0.449697\n",
      "[4300]\ttraining's l1: 0.101919\tvalid_1's l1: 0.44956\n",
      "[4400]\ttraining's l1: 0.0995467\tvalid_1's l1: 0.449443\n",
      "[4500]\ttraining's l1: 0.0972422\tvalid_1's l1: 0.449228\n",
      "[4600]\ttraining's l1: 0.0950747\tvalid_1's l1: 0.449176\n",
      "[4700]\ttraining's l1: 0.092922\tvalid_1's l1: 0.448815\n",
      "[4800]\ttraining's l1: 0.090852\tvalid_1's l1: 0.44848\n",
      "[4900]\ttraining's l1: 0.0888593\tvalid_1's l1: 0.448237\n",
      "[5000]\ttraining's l1: 0.0869178\tvalid_1's l1: 0.447902\n",
      "[5100]\ttraining's l1: 0.0849422\tvalid_1's l1: 0.44789\n",
      "[5200]\ttraining's l1: 0.0831415\tvalid_1's l1: 0.447705\n",
      "[5300]\ttraining's l1: 0.0813877\tvalid_1's l1: 0.447467\n",
      "[5400]\ttraining's l1: 0.0796527\tvalid_1's l1: 0.447257\n",
      "[5500]\ttraining's l1: 0.0780128\tvalid_1's l1: 0.447024\n",
      "[5600]\ttraining's l1: 0.0763561\tvalid_1's l1: 0.446886\n",
      "[5700]\ttraining's l1: 0.0748392\tvalid_1's l1: 0.446779\n",
      "[5800]\ttraining's l1: 0.0732392\tvalid_1's l1: 0.446792\n",
      "[5900]\ttraining's l1: 0.071701\tvalid_1's l1: 0.446647\n",
      "[6000]\ttraining's l1: 0.0702672\tvalid_1's l1: 0.446418\n",
      "[6100]\ttraining's l1: 0.0689091\tvalid_1's l1: 0.446313\n",
      "[6200]\ttraining's l1: 0.0675125\tvalid_1's l1: 0.446278\n",
      "[6300]\ttraining's l1: 0.0662086\tvalid_1's l1: 0.446102\n",
      "[6400]\ttraining's l1: 0.0649407\tvalid_1's l1: 0.446082\n",
      "[6500]\ttraining's l1: 0.0636477\tvalid_1's l1: 0.445927\n",
      "[6600]\ttraining's l1: 0.0625116\tvalid_1's l1: 0.445846\n",
      "[6700]\ttraining's l1: 0.0613944\tvalid_1's l1: 0.445758\n",
      "[6800]\ttraining's l1: 0.0602659\tvalid_1's l1: 0.445643\n",
      "[6900]\ttraining's l1: 0.0591526\tvalid_1's l1: 0.445528\n",
      "[7000]\ttraining's l1: 0.0581166\tvalid_1's l1: 0.445462\n",
      "[7100]\ttraining's l1: 0.0570474\tvalid_1's l1: 0.445436\n",
      "[7200]\ttraining's l1: 0.0560389\tvalid_1's l1: 0.445405\n",
      "[7300]\ttraining's l1: 0.0550337\tvalid_1's l1: 0.445348\n",
      "[7400]\ttraining's l1: 0.0540419\tvalid_1's l1: 0.445103\n",
      "[7500]\ttraining's l1: 0.0530341\tvalid_1's l1: 0.444992\n",
      "[7600]\ttraining's l1: 0.0521236\tvalid_1's l1: 0.444922\n",
      "[7700]\ttraining's l1: 0.0512755\tvalid_1's l1: 0.444919\n",
      "[7800]\ttraining's l1: 0.0503452\tvalid_1's l1: 0.444802\n",
      "[7900]\ttraining's l1: 0.0494412\tvalid_1's l1: 0.444745\n",
      "[8000]\ttraining's l1: 0.0486136\tvalid_1's l1: 0.444682\n",
      "[8100]\ttraining's l1: 0.0477833\tvalid_1's l1: 0.444657\n",
      "[8200]\ttraining's l1: 0.0469809\tvalid_1's l1: 0.444617\n",
      "[8300]\ttraining's l1: 0.0461957\tvalid_1's l1: 0.444568\n",
      "[8400]\ttraining's l1: 0.0454078\tvalid_1's l1: 0.444505\n",
      "[8500]\ttraining's l1: 0.044625\tvalid_1's l1: 0.444413\n",
      "[8600]\ttraining's l1: 0.0438894\tvalid_1's l1: 0.444465\n",
      "[8700]\ttraining's l1: 0.0431828\tvalid_1's l1: 0.444409\n",
      "[8800]\ttraining's l1: 0.0424399\tvalid_1's l1: 0.444377\n",
      "[8900]\ttraining's l1: 0.0417112\tvalid_1's l1: 0.444313\n",
      "[9000]\ttraining's l1: 0.041033\tvalid_1's l1: 0.444259\n",
      "[9100]\ttraining's l1: 0.0403599\tvalid_1's l1: 0.444299\n",
      "Early stopping, best iteration is:\n",
      "[8965]\ttraining's l1: 0.0412783\tvalid_1's l1: 0.444242\n",
      "1JHN Fold 0, logMAE: -0.8113861541640491\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.603116\tvalid_1's l1: 0.669928\n",
      "[200]\ttraining's l1: 0.506586\tvalid_1's l1: 0.597051\n",
      "[300]\ttraining's l1: 0.449156\tvalid_1's l1: 0.560484\n",
      "[400]\ttraining's l1: 0.409103\tvalid_1's l1: 0.539128\n",
      "[500]\ttraining's l1: 0.379752\tvalid_1's l1: 0.524824\n",
      "[600]\ttraining's l1: 0.355204\tvalid_1's l1: 0.514944\n",
      "[700]\ttraining's l1: 0.333298\tvalid_1's l1: 0.505397\n",
      "[800]\ttraining's l1: 0.314165\tvalid_1's l1: 0.498209\n",
      "[900]\ttraining's l1: 0.297723\tvalid_1's l1: 0.491654\n",
      "[1000]\ttraining's l1: 0.284011\tvalid_1's l1: 0.487666\n",
      "[1100]\ttraining's l1: 0.271292\tvalid_1's l1: 0.483625\n",
      "[1200]\ttraining's l1: 0.25947\tvalid_1's l1: 0.480361\n",
      "[1300]\ttraining's l1: 0.248662\tvalid_1's l1: 0.477527\n",
      "[1400]\ttraining's l1: 0.237876\tvalid_1's l1: 0.474946\n",
      "[1500]\ttraining's l1: 0.228505\tvalid_1's l1: 0.472161\n",
      "[1600]\ttraining's l1: 0.219998\tvalid_1's l1: 0.470676\n",
      "[1700]\ttraining's l1: 0.212438\tvalid_1's l1: 0.468327\n",
      "[1800]\ttraining's l1: 0.204229\tvalid_1's l1: 0.466612\n",
      "[1900]\ttraining's l1: 0.196042\tvalid_1's l1: 0.464745\n",
      "[2000]\ttraining's l1: 0.189608\tvalid_1's l1: 0.463134\n",
      "[2100]\ttraining's l1: 0.183343\tvalid_1's l1: 0.461713\n",
      "[2200]\ttraining's l1: 0.177557\tvalid_1's l1: 0.461272\n",
      "[2300]\ttraining's l1: 0.172046\tvalid_1's l1: 0.459859\n",
      "[2400]\ttraining's l1: 0.166709\tvalid_1's l1: 0.458691\n",
      "[2500]\ttraining's l1: 0.161572\tvalid_1's l1: 0.458153\n",
      "[2600]\ttraining's l1: 0.156906\tvalid_1's l1: 0.457206\n",
      "[2700]\ttraining's l1: 0.15203\tvalid_1's l1: 0.456477\n",
      "[2800]\ttraining's l1: 0.147638\tvalid_1's l1: 0.455795\n",
      "[2900]\ttraining's l1: 0.143797\tvalid_1's l1: 0.455038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttraining's l1: 0.139825\tvalid_1's l1: 0.454343\n",
      "[3100]\ttraining's l1: 0.135829\tvalid_1's l1: 0.453788\n",
      "[3200]\ttraining's l1: 0.132082\tvalid_1's l1: 0.453497\n",
      "[3300]\ttraining's l1: 0.128505\tvalid_1's l1: 0.452952\n",
      "[3400]\ttraining's l1: 0.125117\tvalid_1's l1: 0.452408\n",
      "[3500]\ttraining's l1: 0.121862\tvalid_1's l1: 0.451944\n",
      "[3600]\ttraining's l1: 0.118805\tvalid_1's l1: 0.451818\n",
      "[3700]\ttraining's l1: 0.115768\tvalid_1's l1: 0.451795\n",
      "[3800]\ttraining's l1: 0.112814\tvalid_1's l1: 0.451237\n",
      "[3900]\ttraining's l1: 0.110139\tvalid_1's l1: 0.450831\n",
      "[4000]\ttraining's l1: 0.107529\tvalid_1's l1: 0.450542\n",
      "[4100]\ttraining's l1: 0.105004\tvalid_1's l1: 0.450083\n",
      "[4200]\ttraining's l1: 0.102632\tvalid_1's l1: 0.45002\n",
      "[4300]\ttraining's l1: 0.100018\tvalid_1's l1: 0.44984\n",
      "[4400]\ttraining's l1: 0.0976369\tvalid_1's l1: 0.449336\n",
      "[4500]\ttraining's l1: 0.0953979\tvalid_1's l1: 0.449193\n",
      "[4600]\ttraining's l1: 0.0931709\tvalid_1's l1: 0.449081\n",
      "[4700]\ttraining's l1: 0.091012\tvalid_1's l1: 0.448759\n",
      "[4800]\ttraining's l1: 0.0889902\tvalid_1's l1: 0.448599\n",
      "[4900]\ttraining's l1: 0.087066\tvalid_1's l1: 0.448385\n",
      "[5000]\ttraining's l1: 0.0851983\tvalid_1's l1: 0.44809\n",
      "[5100]\ttraining's l1: 0.0833348\tvalid_1's l1: 0.447994\n",
      "[5200]\ttraining's l1: 0.0816128\tvalid_1's l1: 0.447788\n",
      "[5300]\ttraining's l1: 0.0798992\tvalid_1's l1: 0.447705\n",
      "[5400]\ttraining's l1: 0.0783873\tvalid_1's l1: 0.447601\n",
      "[5500]\ttraining's l1: 0.0767269\tvalid_1's l1: 0.447444\n",
      "[5600]\ttraining's l1: 0.0751663\tvalid_1's l1: 0.447417\n",
      "[5700]\ttraining's l1: 0.0735264\tvalid_1's l1: 0.447171\n",
      "[5800]\ttraining's l1: 0.071998\tvalid_1's l1: 0.447054\n",
      "[5900]\ttraining's l1: 0.0705101\tvalid_1's l1: 0.446989\n",
      "[6000]\ttraining's l1: 0.0691057\tvalid_1's l1: 0.446865\n",
      "[6100]\ttraining's l1: 0.0677438\tvalid_1's l1: 0.44663\n",
      "[6200]\ttraining's l1: 0.0664104\tvalid_1's l1: 0.446359\n",
      "[6300]\ttraining's l1: 0.0651431\tvalid_1's l1: 0.446285\n",
      "[6400]\ttraining's l1: 0.0639532\tvalid_1's l1: 0.446203\n",
      "[6500]\ttraining's l1: 0.0627254\tvalid_1's l1: 0.446069\n",
      "[6600]\ttraining's l1: 0.0614729\tvalid_1's l1: 0.446019\n",
      "[6700]\ttraining's l1: 0.0602945\tvalid_1's l1: 0.446002\n",
      "[6800]\ttraining's l1: 0.0592019\tvalid_1's l1: 0.445886\n",
      "[6900]\ttraining's l1: 0.0581091\tvalid_1's l1: 0.44585\n",
      "[7000]\ttraining's l1: 0.0569855\tvalid_1's l1: 0.445767\n",
      "[7100]\ttraining's l1: 0.0559462\tvalid_1's l1: 0.445658\n",
      "[7200]\ttraining's l1: 0.054938\tvalid_1's l1: 0.445596\n",
      "[7300]\ttraining's l1: 0.0538793\tvalid_1's l1: 0.445483\n",
      "[7400]\ttraining's l1: 0.052922\tvalid_1's l1: 0.445479\n",
      "[7500]\ttraining's l1: 0.0519718\tvalid_1's l1: 0.445428\n",
      "[7600]\ttraining's l1: 0.0510519\tvalid_1's l1: 0.445325\n",
      "[7700]\ttraining's l1: 0.0501434\tvalid_1's l1: 0.445342\n",
      "[7800]\ttraining's l1: 0.0492046\tvalid_1's l1: 0.44535\n",
      "[7900]\ttraining's l1: 0.0482796\tvalid_1's l1: 0.445434\n",
      "Early stopping, best iteration is:\n",
      "[7768]\ttraining's l1: 0.0495048\tvalid_1's l1: 0.445253\n",
      "1JHN Fold 1, logMAE: -0.8091115579647301\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.607646\tvalid_1's l1: 0.664671\n",
      "[200]\ttraining's l1: 0.509489\tvalid_1's l1: 0.598735\n",
      "[300]\ttraining's l1: 0.448052\tvalid_1's l1: 0.56318\n",
      "[400]\ttraining's l1: 0.408962\tvalid_1's l1: 0.541679\n",
      "[500]\ttraining's l1: 0.37989\tvalid_1's l1: 0.528046\n",
      "[600]\ttraining's l1: 0.354906\tvalid_1's l1: 0.516046\n",
      "[700]\ttraining's l1: 0.333882\tvalid_1's l1: 0.507565\n",
      "[800]\ttraining's l1: 0.316408\tvalid_1's l1: 0.499968\n",
      "[900]\ttraining's l1: 0.299335\tvalid_1's l1: 0.493139\n",
      "[1000]\ttraining's l1: 0.28452\tvalid_1's l1: 0.487414\n",
      "[1100]\ttraining's l1: 0.271835\tvalid_1's l1: 0.483623\n",
      "[1200]\ttraining's l1: 0.259443\tvalid_1's l1: 0.479472\n",
      "[1300]\ttraining's l1: 0.248722\tvalid_1's l1: 0.476573\n",
      "[1400]\ttraining's l1: 0.238085\tvalid_1's l1: 0.474077\n",
      "[1500]\ttraining's l1: 0.229825\tvalid_1's l1: 0.471132\n",
      "[1600]\ttraining's l1: 0.221457\tvalid_1's l1: 0.469382\n",
      "[1700]\ttraining's l1: 0.213368\tvalid_1's l1: 0.467421\n",
      "[1800]\ttraining's l1: 0.205755\tvalid_1's l1: 0.465587\n",
      "[1900]\ttraining's l1: 0.198606\tvalid_1's l1: 0.4641\n",
      "[2000]\ttraining's l1: 0.192153\tvalid_1's l1: 0.462446\n",
      "[2100]\ttraining's l1: 0.185618\tvalid_1's l1: 0.460732\n",
      "[2200]\ttraining's l1: 0.179403\tvalid_1's l1: 0.459452\n",
      "[2300]\ttraining's l1: 0.173995\tvalid_1's l1: 0.458099\n",
      "[2400]\ttraining's l1: 0.16875\tvalid_1's l1: 0.457341\n",
      "[2500]\ttraining's l1: 0.16376\tvalid_1's l1: 0.456731\n",
      "[2600]\ttraining's l1: 0.158895\tvalid_1's l1: 0.455769\n",
      "[2700]\ttraining's l1: 0.154015\tvalid_1's l1: 0.455146\n",
      "[2800]\ttraining's l1: 0.149541\tvalid_1's l1: 0.454031\n",
      "[2900]\ttraining's l1: 0.145227\tvalid_1's l1: 0.453563\n",
      "[3000]\ttraining's l1: 0.140945\tvalid_1's l1: 0.453134\n",
      "[3100]\ttraining's l1: 0.137025\tvalid_1's l1: 0.452761\n",
      "[3200]\ttraining's l1: 0.13352\tvalid_1's l1: 0.45213\n",
      "[3300]\ttraining's l1: 0.12986\tvalid_1's l1: 0.451643\n",
      "[3400]\ttraining's l1: 0.126497\tvalid_1's l1: 0.451113\n",
      "[3500]\ttraining's l1: 0.123235\tvalid_1's l1: 0.450727\n",
      "[3600]\ttraining's l1: 0.120186\tvalid_1's l1: 0.450064\n",
      "[3700]\ttraining's l1: 0.117341\tvalid_1's l1: 0.449902\n",
      "[3800]\ttraining's l1: 0.114543\tvalid_1's l1: 0.44967\n",
      "[3900]\ttraining's l1: 0.11179\tvalid_1's l1: 0.449355\n",
      "[4000]\ttraining's l1: 0.109072\tvalid_1's l1: 0.448877\n",
      "[4100]\ttraining's l1: 0.106506\tvalid_1's l1: 0.448536\n",
      "[4200]\ttraining's l1: 0.104021\tvalid_1's l1: 0.448221\n",
      "[4300]\ttraining's l1: 0.101773\tvalid_1's l1: 0.4478\n",
      "[4400]\ttraining's l1: 0.0995025\tvalid_1's l1: 0.447473\n",
      "[4500]\ttraining's l1: 0.0972799\tvalid_1's l1: 0.447403\n",
      "[4600]\ttraining's l1: 0.0950611\tvalid_1's l1: 0.447012\n",
      "[4700]\ttraining's l1: 0.0928069\tvalid_1's l1: 0.446996\n",
      "[4800]\ttraining's l1: 0.0907526\tvalid_1's l1: 0.446791\n",
      "[4900]\ttraining's l1: 0.0887358\tvalid_1's l1: 0.446658\n",
      "[5000]\ttraining's l1: 0.0868864\tvalid_1's l1: 0.446575\n",
      "[5100]\ttraining's l1: 0.0849196\tvalid_1's l1: 0.446452\n",
      "[5200]\ttraining's l1: 0.0831301\tvalid_1's l1: 0.446117\n",
      "[5300]\ttraining's l1: 0.0813852\tvalid_1's l1: 0.445949\n",
      "[5400]\ttraining's l1: 0.0798262\tvalid_1's l1: 0.44573\n",
      "[5500]\ttraining's l1: 0.0782064\tvalid_1's l1: 0.445618\n",
      "[5600]\ttraining's l1: 0.0765919\tvalid_1's l1: 0.445455\n",
      "[5700]\ttraining's l1: 0.0750051\tvalid_1's l1: 0.445269\n",
      "[5800]\ttraining's l1: 0.0735321\tvalid_1's l1: 0.445163\n",
      "[5900]\ttraining's l1: 0.0720973\tvalid_1's l1: 0.445036\n",
      "[6000]\ttraining's l1: 0.0706324\tvalid_1's l1: 0.444876\n",
      "[6100]\ttraining's l1: 0.0691048\tvalid_1's l1: 0.44471\n",
      "[6200]\ttraining's l1: 0.0678057\tvalid_1's l1: 0.444663\n",
      "[6300]\ttraining's l1: 0.0664975\tvalid_1's l1: 0.444539\n",
      "[6400]\ttraining's l1: 0.065225\tvalid_1's l1: 0.444514\n",
      "[6500]\ttraining's l1: 0.0640055\tvalid_1's l1: 0.444414\n",
      "[6600]\ttraining's l1: 0.062858\tvalid_1's l1: 0.444402\n",
      "[6700]\ttraining's l1: 0.0616469\tvalid_1's l1: 0.444265\n",
      "[6800]\ttraining's l1: 0.060544\tvalid_1's l1: 0.444136\n",
      "[6900]\ttraining's l1: 0.0594426\tvalid_1's l1: 0.444035\n",
      "[7000]\ttraining's l1: 0.0584011\tvalid_1's l1: 0.443991\n",
      "[7100]\ttraining's l1: 0.0573366\tvalid_1's l1: 0.443938\n",
      "[7200]\ttraining's l1: 0.0562959\tvalid_1's l1: 0.443848\n",
      "[7300]\ttraining's l1: 0.0552971\tvalid_1's l1: 0.443801\n",
      "[7400]\ttraining's l1: 0.0543856\tvalid_1's l1: 0.443719\n",
      "[7500]\ttraining's l1: 0.0533984\tvalid_1's l1: 0.443686\n",
      "[7600]\ttraining's l1: 0.0524034\tvalid_1's l1: 0.443655\n",
      "[7700]\ttraining's l1: 0.0515448\tvalid_1's l1: 0.443528\n",
      "[7800]\ttraining's l1: 0.0506103\tvalid_1's l1: 0.443519\n",
      "[7900]\ttraining's l1: 0.049783\tvalid_1's l1: 0.443569\n",
      "Early stopping, best iteration is:\n",
      "[7733]\ttraining's l1: 0.0512202\tvalid_1's l1: 0.443487\n",
      "1JHN Fold 2, logMAE: -0.813086572346629\n",
      "*** Training Model for 2JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.343616\tvalid_1's l1: 0.3581\n",
      "[200]\ttraining's l1: 0.293948\tvalid_1's l1: 0.314911\n",
      "[300]\ttraining's l1: 0.266232\tvalid_1's l1: 0.292006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's l1: 0.24812\tvalid_1's l1: 0.277787\n",
      "[500]\ttraining's l1: 0.233576\tvalid_1's l1: 0.26678\n",
      "[600]\ttraining's l1: 0.222078\tvalid_1's l1: 0.258518\n",
      "[700]\ttraining's l1: 0.212505\tvalid_1's l1: 0.251773\n",
      "[800]\ttraining's l1: 0.203715\tvalid_1's l1: 0.245815\n",
      "[900]\ttraining's l1: 0.196565\tvalid_1's l1: 0.241194\n",
      "[1000]\ttraining's l1: 0.189783\tvalid_1's l1: 0.237016\n",
      "[1100]\ttraining's l1: 0.183706\tvalid_1's l1: 0.233225\n",
      "[1200]\ttraining's l1: 0.178602\tvalid_1's l1: 0.23022\n",
      "[1300]\ttraining's l1: 0.173652\tvalid_1's l1: 0.22741\n",
      "[1400]\ttraining's l1: 0.169171\tvalid_1's l1: 0.224922\n",
      "[1500]\ttraining's l1: 0.164917\tvalid_1's l1: 0.222656\n",
      "[1600]\ttraining's l1: 0.160621\tvalid_1's l1: 0.220356\n",
      "[1700]\ttraining's l1: 0.156732\tvalid_1's l1: 0.218307\n",
      "[1800]\ttraining's l1: 0.15319\tvalid_1's l1: 0.21642\n",
      "[1900]\ttraining's l1: 0.149892\tvalid_1's l1: 0.214832\n",
      "[2000]\ttraining's l1: 0.146712\tvalid_1's l1: 0.213202\n",
      "[2100]\ttraining's l1: 0.143726\tvalid_1's l1: 0.211755\n",
      "[2200]\ttraining's l1: 0.140856\tvalid_1's l1: 0.210455\n",
      "[2300]\ttraining's l1: 0.138212\tvalid_1's l1: 0.209223\n",
      "[2400]\ttraining's l1: 0.135585\tvalid_1's l1: 0.208053\n",
      "[2500]\ttraining's l1: 0.133106\tvalid_1's l1: 0.206879\n",
      "[2600]\ttraining's l1: 0.130633\tvalid_1's l1: 0.20579\n",
      "[2700]\ttraining's l1: 0.128345\tvalid_1's l1: 0.204671\n",
      "[2800]\ttraining's l1: 0.126187\tvalid_1's l1: 0.203726\n",
      "[2900]\ttraining's l1: 0.124036\tvalid_1's l1: 0.202819\n",
      "[3000]\ttraining's l1: 0.122016\tvalid_1's l1: 0.202021\n",
      "[3100]\ttraining's l1: 0.120086\tvalid_1's l1: 0.201176\n",
      "[3200]\ttraining's l1: 0.118177\tvalid_1's l1: 0.200414\n",
      "[3300]\ttraining's l1: 0.116331\tvalid_1's l1: 0.199792\n",
      "[3400]\ttraining's l1: 0.114538\tvalid_1's l1: 0.199097\n",
      "[3500]\ttraining's l1: 0.112725\tvalid_1's l1: 0.198393\n",
      "[3600]\ttraining's l1: 0.111076\tvalid_1's l1: 0.197743\n",
      "[3700]\ttraining's l1: 0.109422\tvalid_1's l1: 0.197063\n",
      "[3800]\ttraining's l1: 0.107844\tvalid_1's l1: 0.196481\n",
      "[3900]\ttraining's l1: 0.106312\tvalid_1's l1: 0.195888\n",
      "[4000]\ttraining's l1: 0.104801\tvalid_1's l1: 0.195322\n",
      "[4100]\ttraining's l1: 0.103418\tvalid_1's l1: 0.194796\n",
      "[4200]\ttraining's l1: 0.101978\tvalid_1's l1: 0.194292\n",
      "[4300]\ttraining's l1: 0.100615\tvalid_1's l1: 0.193798\n",
      "[4400]\ttraining's l1: 0.0993044\tvalid_1's l1: 0.193402\n",
      "[4500]\ttraining's l1: 0.0980524\tvalid_1's l1: 0.192998\n",
      "[4600]\ttraining's l1: 0.0967352\tvalid_1's l1: 0.192527\n",
      "[4700]\ttraining's l1: 0.0954893\tvalid_1's l1: 0.192128\n",
      "[4800]\ttraining's l1: 0.0943249\tvalid_1's l1: 0.191752\n",
      "[4900]\ttraining's l1: 0.0931314\tvalid_1's l1: 0.191398\n",
      "[5000]\ttraining's l1: 0.0919287\tvalid_1's l1: 0.191058\n",
      "[5100]\ttraining's l1: 0.0908585\tvalid_1's l1: 0.19072\n",
      "[5200]\ttraining's l1: 0.0897251\tvalid_1's l1: 0.190341\n",
      "[5300]\ttraining's l1: 0.0885858\tvalid_1's l1: 0.189993\n",
      "[5400]\ttraining's l1: 0.0875757\tvalid_1's l1: 0.189666\n",
      "[5500]\ttraining's l1: 0.0865436\tvalid_1's l1: 0.189339\n",
      "[5600]\ttraining's l1: 0.0854633\tvalid_1's l1: 0.188989\n",
      "[5700]\ttraining's l1: 0.0845055\tvalid_1's l1: 0.188683\n",
      "[5800]\ttraining's l1: 0.083545\tvalid_1's l1: 0.188352\n",
      "[5900]\ttraining's l1: 0.0825527\tvalid_1's l1: 0.188091\n",
      "[6000]\ttraining's l1: 0.0815752\tvalid_1's l1: 0.1878\n",
      "[6100]\ttraining's l1: 0.0806714\tvalid_1's l1: 0.18751\n",
      "[6200]\ttraining's l1: 0.079751\tvalid_1's l1: 0.187214\n",
      "[6300]\ttraining's l1: 0.0788564\tvalid_1's l1: 0.186932\n",
      "[6400]\ttraining's l1: 0.0779959\tvalid_1's l1: 0.186646\n",
      "[6500]\ttraining's l1: 0.077131\tvalid_1's l1: 0.186341\n",
      "[6600]\ttraining's l1: 0.0762776\tvalid_1's l1: 0.186097\n",
      "[6700]\ttraining's l1: 0.0754658\tvalid_1's l1: 0.185841\n",
      "[6800]\ttraining's l1: 0.0746383\tvalid_1's l1: 0.185638\n",
      "[6900]\ttraining's l1: 0.0738236\tvalid_1's l1: 0.185413\n",
      "[7000]\ttraining's l1: 0.0730308\tvalid_1's l1: 0.185205\n",
      "[7100]\ttraining's l1: 0.07228\tvalid_1's l1: 0.185019\n",
      "[7200]\ttraining's l1: 0.0715427\tvalid_1's l1: 0.18484\n",
      "[7300]\ttraining's l1: 0.0707788\tvalid_1's l1: 0.184641\n",
      "[7400]\ttraining's l1: 0.0700562\tvalid_1's l1: 0.184463\n",
      "[7500]\ttraining's l1: 0.0693637\tvalid_1's l1: 0.184254\n",
      "[7600]\ttraining's l1: 0.0686416\tvalid_1's l1: 0.184035\n",
      "[7700]\ttraining's l1: 0.0679551\tvalid_1's l1: 0.183847\n",
      "[7800]\ttraining's l1: 0.0672788\tvalid_1's l1: 0.18365\n",
      "[7900]\ttraining's l1: 0.0666237\tvalid_1's l1: 0.183483\n",
      "[8000]\ttraining's l1: 0.0659518\tvalid_1's l1: 0.183317\n",
      "[8100]\ttraining's l1: 0.0653124\tvalid_1's l1: 0.183168\n",
      "[8200]\ttraining's l1: 0.0646722\tvalid_1's l1: 0.183007\n",
      "[8300]\ttraining's l1: 0.0640527\tvalid_1's l1: 0.182826\n",
      "[8400]\ttraining's l1: 0.0634467\tvalid_1's l1: 0.182711\n",
      "[8500]\ttraining's l1: 0.0628317\tvalid_1's l1: 0.182565\n",
      "[8600]\ttraining's l1: 0.0622156\tvalid_1's l1: 0.182464\n",
      "[8700]\ttraining's l1: 0.0616164\tvalid_1's l1: 0.18231\n",
      "[8800]\ttraining's l1: 0.0610366\tvalid_1's l1: 0.182174\n",
      "[8900]\ttraining's l1: 0.0604798\tvalid_1's l1: 0.182064\n",
      "[9000]\ttraining's l1: 0.059923\tvalid_1's l1: 0.181939\n",
      "[9100]\ttraining's l1: 0.0593619\tvalid_1's l1: 0.181829\n",
      "[9200]\ttraining's l1: 0.0587937\tvalid_1's l1: 0.18169\n",
      "[9300]\ttraining's l1: 0.0582386\tvalid_1's l1: 0.181573\n",
      "[9400]\ttraining's l1: 0.0576867\tvalid_1's l1: 0.181449\n",
      "[9500]\ttraining's l1: 0.05717\tvalid_1's l1: 0.181354\n",
      "[9600]\ttraining's l1: 0.0566285\tvalid_1's l1: 0.181227\n",
      "[9700]\ttraining's l1: 0.0561009\tvalid_1's l1: 0.181122\n",
      "[9800]\ttraining's l1: 0.0555914\tvalid_1's l1: 0.181007\n",
      "[9900]\ttraining's l1: 0.055102\tvalid_1's l1: 0.180911\n",
      "[10000]\ttraining's l1: 0.0546118\tvalid_1's l1: 0.180805\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0546118\tvalid_1's l1: 0.180805\n",
      "2JHH Fold 0, logMAE: -1.710335654622766\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.351302\tvalid_1's l1: 0.361015\n",
      "[200]\ttraining's l1: 0.298606\tvalid_1's l1: 0.31512\n",
      "[300]\ttraining's l1: 0.269622\tvalid_1's l1: 0.291101\n",
      "[400]\ttraining's l1: 0.249269\tvalid_1's l1: 0.275529\n",
      "[500]\ttraining's l1: 0.234931\tvalid_1's l1: 0.264937\n",
      "[600]\ttraining's l1: 0.223256\tvalid_1's l1: 0.256783\n",
      "[700]\ttraining's l1: 0.21316\tvalid_1's l1: 0.249783\n",
      "[800]\ttraining's l1: 0.204919\tvalid_1's l1: 0.24433\n",
      "[900]\ttraining's l1: 0.197677\tvalid_1's l1: 0.23984\n",
      "[1000]\ttraining's l1: 0.191252\tvalid_1's l1: 0.235962\n",
      "[1100]\ttraining's l1: 0.185394\tvalid_1's l1: 0.232477\n",
      "[1200]\ttraining's l1: 0.179759\tvalid_1's l1: 0.229089\n",
      "[1300]\ttraining's l1: 0.174924\tvalid_1's l1: 0.22628\n",
      "[1400]\ttraining's l1: 0.170565\tvalid_1's l1: 0.22395\n",
      "[1500]\ttraining's l1: 0.16611\tvalid_1's l1: 0.221501\n",
      "[1600]\ttraining's l1: 0.162165\tvalid_1's l1: 0.219311\n",
      "[1700]\ttraining's l1: 0.158428\tvalid_1's l1: 0.21739\n",
      "[1800]\ttraining's l1: 0.154882\tvalid_1's l1: 0.215533\n",
      "[1900]\ttraining's l1: 0.151693\tvalid_1's l1: 0.214059\n",
      "[2000]\ttraining's l1: 0.148615\tvalid_1's l1: 0.212534\n",
      "[2100]\ttraining's l1: 0.145418\tvalid_1's l1: 0.210812\n",
      "[2200]\ttraining's l1: 0.1427\tvalid_1's l1: 0.209473\n",
      "[2300]\ttraining's l1: 0.140091\tvalid_1's l1: 0.208312\n",
      "[2400]\ttraining's l1: 0.137448\tvalid_1's l1: 0.207184\n",
      "[2500]\ttraining's l1: 0.134864\tvalid_1's l1: 0.206087\n",
      "[2600]\ttraining's l1: 0.132375\tvalid_1's l1: 0.20505\n",
      "[2700]\ttraining's l1: 0.13007\tvalid_1's l1: 0.204037\n",
      "[2800]\ttraining's l1: 0.127702\tvalid_1's l1: 0.203019\n",
      "[2900]\ttraining's l1: 0.125645\tvalid_1's l1: 0.202091\n",
      "[3000]\ttraining's l1: 0.123492\tvalid_1's l1: 0.201186\n",
      "[3100]\ttraining's l1: 0.12146\tvalid_1's l1: 0.200423\n",
      "[3200]\ttraining's l1: 0.119414\tvalid_1's l1: 0.199565\n",
      "[3300]\ttraining's l1: 0.117495\tvalid_1's l1: 0.198777\n",
      "[3400]\ttraining's l1: 0.115708\tvalid_1's l1: 0.198116\n",
      "[3500]\ttraining's l1: 0.114044\tvalid_1's l1: 0.197494\n",
      "[3600]\ttraining's l1: 0.11242\tvalid_1's l1: 0.196926\n",
      "[3700]\ttraining's l1: 0.110769\tvalid_1's l1: 0.196318\n",
      "[3800]\ttraining's l1: 0.109169\tvalid_1's l1: 0.195735\n",
      "[3900]\ttraining's l1: 0.107611\tvalid_1's l1: 0.195147\n",
      "[4000]\ttraining's l1: 0.106157\tvalid_1's l1: 0.194619\n",
      "[4100]\ttraining's l1: 0.104724\tvalid_1's l1: 0.194075\n",
      "[4200]\ttraining's l1: 0.103299\tvalid_1's l1: 0.193628\n",
      "[4300]\ttraining's l1: 0.101867\tvalid_1's l1: 0.193163\n",
      "[4400]\ttraining's l1: 0.100429\tvalid_1's l1: 0.192687\n",
      "[4500]\ttraining's l1: 0.0990838\tvalid_1's l1: 0.192251\n",
      "[4600]\ttraining's l1: 0.0978722\tvalid_1's l1: 0.191874\n",
      "[4700]\ttraining's l1: 0.0966532\tvalid_1's l1: 0.191506\n",
      "[4800]\ttraining's l1: 0.0954246\tvalid_1's l1: 0.191162\n",
      "[4900]\ttraining's l1: 0.0941833\tvalid_1's l1: 0.190741\n",
      "[5000]\ttraining's l1: 0.0930312\tvalid_1's l1: 0.190342\n",
      "[5100]\ttraining's l1: 0.0918529\tvalid_1's l1: 0.189965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5200]\ttraining's l1: 0.0907414\tvalid_1's l1: 0.189632\n",
      "[5300]\ttraining's l1: 0.0896349\tvalid_1's l1: 0.189303\n",
      "[5400]\ttraining's l1: 0.0885715\tvalid_1's l1: 0.188948\n",
      "[5500]\ttraining's l1: 0.087547\tvalid_1's l1: 0.188582\n",
      "[5600]\ttraining's l1: 0.0864641\tvalid_1's l1: 0.18831\n",
      "[5700]\ttraining's l1: 0.0854678\tvalid_1's l1: 0.188033\n",
      "[5800]\ttraining's l1: 0.0844669\tvalid_1's l1: 0.18774\n",
      "[5900]\ttraining's l1: 0.0834996\tvalid_1's l1: 0.187426\n",
      "[6000]\ttraining's l1: 0.0825376\tvalid_1's l1: 0.187178\n",
      "[6100]\ttraining's l1: 0.0815874\tvalid_1's l1: 0.186939\n",
      "[6200]\ttraining's l1: 0.080617\tvalid_1's l1: 0.186675\n",
      "[6300]\ttraining's l1: 0.07969\tvalid_1's l1: 0.186391\n",
      "[6400]\ttraining's l1: 0.0787596\tvalid_1's l1: 0.18611\n",
      "[6500]\ttraining's l1: 0.0779306\tvalid_1's l1: 0.185847\n",
      "[6600]\ttraining's l1: 0.0770583\tvalid_1's l1: 0.185596\n",
      "[6700]\ttraining's l1: 0.0761937\tvalid_1's l1: 0.185362\n",
      "[6800]\ttraining's l1: 0.0753511\tvalid_1's l1: 0.185163\n",
      "[6900]\ttraining's l1: 0.0745423\tvalid_1's l1: 0.184985\n",
      "[7000]\ttraining's l1: 0.0737585\tvalid_1's l1: 0.18479\n",
      "[7100]\ttraining's l1: 0.0729573\tvalid_1's l1: 0.184583\n",
      "[7200]\ttraining's l1: 0.0722007\tvalid_1's l1: 0.18443\n",
      "[7300]\ttraining's l1: 0.0714293\tvalid_1's l1: 0.184217\n",
      "[7400]\ttraining's l1: 0.070689\tvalid_1's l1: 0.184014\n",
      "[7500]\ttraining's l1: 0.069949\tvalid_1's l1: 0.183829\n",
      "[7600]\ttraining's l1: 0.0692295\tvalid_1's l1: 0.18368\n",
      "[7700]\ttraining's l1: 0.0685285\tvalid_1's l1: 0.183514\n",
      "[7800]\ttraining's l1: 0.0678493\tvalid_1's l1: 0.183325\n",
      "[7900]\ttraining's l1: 0.0671371\tvalid_1's l1: 0.183135\n",
      "[8000]\ttraining's l1: 0.0664741\tvalid_1's l1: 0.182937\n",
      "[8100]\ttraining's l1: 0.0658321\tvalid_1's l1: 0.182771\n",
      "[8200]\ttraining's l1: 0.0651699\tvalid_1's l1: 0.182616\n",
      "[8300]\ttraining's l1: 0.0645417\tvalid_1's l1: 0.182487\n",
      "[8400]\ttraining's l1: 0.0639098\tvalid_1's l1: 0.182344\n",
      "[8500]\ttraining's l1: 0.0632905\tvalid_1's l1: 0.182189\n",
      "[8600]\ttraining's l1: 0.0626425\tvalid_1's l1: 0.182051\n",
      "[8700]\ttraining's l1: 0.0620066\tvalid_1's l1: 0.181896\n",
      "[8800]\ttraining's l1: 0.0614164\tvalid_1's l1: 0.181762\n",
      "[8900]\ttraining's l1: 0.0608278\tvalid_1's l1: 0.181616\n",
      "[9000]\ttraining's l1: 0.0602593\tvalid_1's l1: 0.181471\n",
      "[9100]\ttraining's l1: 0.0597003\tvalid_1's l1: 0.18132\n",
      "[9200]\ttraining's l1: 0.0591451\tvalid_1's l1: 0.181182\n",
      "[9300]\ttraining's l1: 0.0586167\tvalid_1's l1: 0.181071\n",
      "[9400]\ttraining's l1: 0.058067\tvalid_1's l1: 0.180953\n",
      "[9500]\ttraining's l1: 0.0575158\tvalid_1's l1: 0.180835\n",
      "[9600]\ttraining's l1: 0.0570016\tvalid_1's l1: 0.180709\n",
      "[9700]\ttraining's l1: 0.0564719\tvalid_1's l1: 0.180611\n",
      "[9800]\ttraining's l1: 0.0559372\tvalid_1's l1: 0.180482\n",
      "[9900]\ttraining's l1: 0.0554296\tvalid_1's l1: 0.180376\n",
      "[10000]\ttraining's l1: 0.0549222\tvalid_1's l1: 0.180275\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0549222\tvalid_1's l1: 0.180275\n",
      "2JHH Fold 1, logMAE: -1.7132708771499179\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.346581\tvalid_1's l1: 0.356872\n",
      "[200]\ttraining's l1: 0.296783\tvalid_1's l1: 0.314139\n",
      "[300]\ttraining's l1: 0.268724\tvalid_1's l1: 0.290743\n",
      "[400]\ttraining's l1: 0.249995\tvalid_1's l1: 0.276225\n",
      "[500]\ttraining's l1: 0.235388\tvalid_1's l1: 0.265162\n",
      "[600]\ttraining's l1: 0.223533\tvalid_1's l1: 0.256824\n",
      "[700]\ttraining's l1: 0.213312\tvalid_1's l1: 0.249783\n",
      "[800]\ttraining's l1: 0.205045\tvalid_1's l1: 0.244246\n",
      "[900]\ttraining's l1: 0.197543\tvalid_1's l1: 0.239321\n",
      "[1000]\ttraining's l1: 0.19106\tvalid_1's l1: 0.235252\n",
      "[1100]\ttraining's l1: 0.185333\tvalid_1's l1: 0.231602\n",
      "[1200]\ttraining's l1: 0.179814\tvalid_1's l1: 0.228374\n",
      "[1300]\ttraining's l1: 0.175048\tvalid_1's l1: 0.225663\n",
      "[1400]\ttraining's l1: 0.170212\tvalid_1's l1: 0.222952\n",
      "[1500]\ttraining's l1: 0.165993\tvalid_1's l1: 0.220603\n",
      "[1600]\ttraining's l1: 0.16201\tvalid_1's l1: 0.218411\n",
      "[1700]\ttraining's l1: 0.158452\tvalid_1's l1: 0.216726\n",
      "[1800]\ttraining's l1: 0.15513\tvalid_1's l1: 0.215017\n",
      "[1900]\ttraining's l1: 0.151665\tvalid_1's l1: 0.21336\n",
      "[2000]\ttraining's l1: 0.148351\tvalid_1's l1: 0.211797\n",
      "[2100]\ttraining's l1: 0.145419\tvalid_1's l1: 0.210544\n",
      "[2200]\ttraining's l1: 0.142472\tvalid_1's l1: 0.209107\n",
      "[2300]\ttraining's l1: 0.139762\tvalid_1's l1: 0.207834\n",
      "[2400]\ttraining's l1: 0.137144\tvalid_1's l1: 0.206577\n",
      "[2500]\ttraining's l1: 0.134686\tvalid_1's l1: 0.205549\n",
      "[2600]\ttraining's l1: 0.132268\tvalid_1's l1: 0.20449\n",
      "[2700]\ttraining's l1: 0.130022\tvalid_1's l1: 0.203466\n",
      "[2800]\ttraining's l1: 0.127918\tvalid_1's l1: 0.202652\n",
      "[2900]\ttraining's l1: 0.125805\tvalid_1's l1: 0.201797\n",
      "[3000]\ttraining's l1: 0.123805\tvalid_1's l1: 0.200948\n",
      "[3100]\ttraining's l1: 0.121839\tvalid_1's l1: 0.20015\n",
      "[3200]\ttraining's l1: 0.119949\tvalid_1's l1: 0.199401\n",
      "[3300]\ttraining's l1: 0.118061\tvalid_1's l1: 0.198659\n",
      "[3400]\ttraining's l1: 0.116156\tvalid_1's l1: 0.197857\n",
      "[3500]\ttraining's l1: 0.114454\tvalid_1's l1: 0.197236\n",
      "[3600]\ttraining's l1: 0.112763\tvalid_1's l1: 0.196639\n",
      "[3700]\ttraining's l1: 0.111096\tvalid_1's l1: 0.196015\n",
      "[3800]\ttraining's l1: 0.109475\tvalid_1's l1: 0.1954\n",
      "[3900]\ttraining's l1: 0.107905\tvalid_1's l1: 0.194793\n",
      "[4000]\ttraining's l1: 0.106455\tvalid_1's l1: 0.19432\n",
      "[4100]\ttraining's l1: 0.104995\tvalid_1's l1: 0.193771\n",
      "[4200]\ttraining's l1: 0.103671\tvalid_1's l1: 0.1933\n",
      "[4300]\ttraining's l1: 0.102345\tvalid_1's l1: 0.192874\n",
      "[4400]\ttraining's l1: 0.101\tvalid_1's l1: 0.192408\n",
      "[4500]\ttraining's l1: 0.0997076\tvalid_1's l1: 0.191994\n",
      "[4600]\ttraining's l1: 0.0983845\tvalid_1's l1: 0.1915\n",
      "[4700]\ttraining's l1: 0.0971045\tvalid_1's l1: 0.191127\n",
      "[4800]\ttraining's l1: 0.095904\tvalid_1's l1: 0.190769\n",
      "[4900]\ttraining's l1: 0.094666\tvalid_1's l1: 0.190373\n",
      "[5000]\ttraining's l1: 0.0934902\tvalid_1's l1: 0.190014\n",
      "[5100]\ttraining's l1: 0.0923099\tvalid_1's l1: 0.189631\n",
      "[5200]\ttraining's l1: 0.091155\tvalid_1's l1: 0.189276\n",
      "[5300]\ttraining's l1: 0.0900511\tvalid_1's l1: 0.188919\n",
      "[5400]\ttraining's l1: 0.0889866\tvalid_1's l1: 0.188575\n",
      "[5500]\ttraining's l1: 0.0879166\tvalid_1's l1: 0.188246\n",
      "[5600]\ttraining's l1: 0.086867\tvalid_1's l1: 0.187922\n",
      "[5700]\ttraining's l1: 0.0858794\tvalid_1's l1: 0.187592\n",
      "[5800]\ttraining's l1: 0.0848746\tvalid_1's l1: 0.187267\n",
      "[5900]\ttraining's l1: 0.0838898\tvalid_1's l1: 0.187022\n",
      "[6000]\ttraining's l1: 0.0829449\tvalid_1's l1: 0.186746\n",
      "[6100]\ttraining's l1: 0.0819952\tvalid_1's l1: 0.186423\n",
      "[6200]\ttraining's l1: 0.0810928\tvalid_1's l1: 0.186152\n",
      "[6300]\ttraining's l1: 0.0801999\tvalid_1's l1: 0.185931\n",
      "[6400]\ttraining's l1: 0.0792959\tvalid_1's l1: 0.185662\n",
      "[6500]\ttraining's l1: 0.0783833\tvalid_1's l1: 0.185381\n",
      "[6600]\ttraining's l1: 0.0775405\tvalid_1's l1: 0.185168\n",
      "[6700]\ttraining's l1: 0.0767246\tvalid_1's l1: 0.184964\n",
      "[6800]\ttraining's l1: 0.0759112\tvalid_1's l1: 0.184729\n",
      "[6900]\ttraining's l1: 0.0750761\tvalid_1's l1: 0.184451\n",
      "[7000]\ttraining's l1: 0.0742969\tvalid_1's l1: 0.184261\n",
      "[7100]\ttraining's l1: 0.073519\tvalid_1's l1: 0.183999\n",
      "[7200]\ttraining's l1: 0.0727405\tvalid_1's l1: 0.183814\n",
      "[7300]\ttraining's l1: 0.0719787\tvalid_1's l1: 0.183642\n",
      "[7400]\ttraining's l1: 0.0712354\tvalid_1's l1: 0.183475\n",
      "[7500]\ttraining's l1: 0.0705135\tvalid_1's l1: 0.183329\n",
      "[7600]\ttraining's l1: 0.0698121\tvalid_1's l1: 0.183157\n",
      "[7700]\ttraining's l1: 0.0690918\tvalid_1's l1: 0.182946\n",
      "[7800]\ttraining's l1: 0.0683914\tvalid_1's l1: 0.182766\n",
      "[7900]\ttraining's l1: 0.0677095\tvalid_1's l1: 0.182582\n",
      "[8000]\ttraining's l1: 0.067045\tvalid_1's l1: 0.182413\n",
      "[8100]\ttraining's l1: 0.0664132\tvalid_1's l1: 0.182263\n",
      "[8200]\ttraining's l1: 0.0657403\tvalid_1's l1: 0.182093\n",
      "[8300]\ttraining's l1: 0.0651066\tvalid_1's l1: 0.181942\n",
      "[8400]\ttraining's l1: 0.0644784\tvalid_1's l1: 0.181823\n",
      "[8500]\ttraining's l1: 0.0638557\tvalid_1's l1: 0.18166\n",
      "[8600]\ttraining's l1: 0.0632668\tvalid_1's l1: 0.181533\n",
      "[8700]\ttraining's l1: 0.0626642\tvalid_1's l1: 0.181393\n",
      "[8800]\ttraining's l1: 0.0620909\tvalid_1's l1: 0.18123\n",
      "[8900]\ttraining's l1: 0.0615025\tvalid_1's l1: 0.181079\n",
      "[9000]\ttraining's l1: 0.0609228\tvalid_1's l1: 0.180972\n",
      "[9100]\ttraining's l1: 0.0603404\tvalid_1's l1: 0.180847\n",
      "[9200]\ttraining's l1: 0.0597729\tvalid_1's l1: 0.180743\n",
      "[9300]\ttraining's l1: 0.0592243\tvalid_1's l1: 0.180619\n",
      "[9400]\ttraining's l1: 0.0586664\tvalid_1's l1: 0.18049\n",
      "[9500]\ttraining's l1: 0.0581392\tvalid_1's l1: 0.180352\n",
      "[9600]\ttraining's l1: 0.0576161\tvalid_1's l1: 0.180243\n",
      "[9700]\ttraining's l1: 0.0571163\tvalid_1's l1: 0.180138\n",
      "[9800]\ttraining's l1: 0.0565895\tvalid_1's l1: 0.180006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9900]\ttraining's l1: 0.0560778\tvalid_1's l1: 0.179883\n",
      "[10000]\ttraining's l1: 0.0555944\tvalid_1's l1: 0.179768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0555944\tvalid_1's l1: 0.179768\n",
      "2JHH Fold 2, logMAE: -1.7160901140294582\n",
      "*** Training Model for 2JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.262157\tvalid_1's l1: 0.285638\n",
      "[200]\ttraining's l1: 0.21312\tvalid_1's l1: 0.244132\n",
      "[300]\ttraining's l1: 0.187701\tvalid_1's l1: 0.223484\n",
      "[400]\ttraining's l1: 0.171354\tvalid_1's l1: 0.211549\n",
      "[500]\ttraining's l1: 0.159606\tvalid_1's l1: 0.203296\n",
      "[600]\ttraining's l1: 0.150154\tvalid_1's l1: 0.197433\n",
      "[700]\ttraining's l1: 0.142024\tvalid_1's l1: 0.192591\n",
      "[800]\ttraining's l1: 0.134886\tvalid_1's l1: 0.188281\n",
      "[900]\ttraining's l1: 0.128507\tvalid_1's l1: 0.18458\n",
      "[1000]\ttraining's l1: 0.123079\tvalid_1's l1: 0.18183\n",
      "[1100]\ttraining's l1: 0.118224\tvalid_1's l1: 0.17917\n",
      "[1200]\ttraining's l1: 0.113952\tvalid_1's l1: 0.177156\n",
      "[1300]\ttraining's l1: 0.109879\tvalid_1's l1: 0.175175\n",
      "[1400]\ttraining's l1: 0.106101\tvalid_1's l1: 0.173438\n",
      "[1500]\ttraining's l1: 0.102394\tvalid_1's l1: 0.171646\n",
      "[1600]\ttraining's l1: 0.0991919\tvalid_1's l1: 0.170302\n",
      "[1700]\ttraining's l1: 0.0961928\tvalid_1's l1: 0.169079\n",
      "[1800]\ttraining's l1: 0.0933377\tvalid_1's l1: 0.167863\n",
      "[1900]\ttraining's l1: 0.0906161\tvalid_1's l1: 0.166748\n",
      "[2000]\ttraining's l1: 0.0881273\tvalid_1's l1: 0.165777\n",
      "[2100]\ttraining's l1: 0.0858288\tvalid_1's l1: 0.164945\n",
      "[2200]\ttraining's l1: 0.083487\tvalid_1's l1: 0.164065\n",
      "[2300]\ttraining's l1: 0.0812702\tvalid_1's l1: 0.163184\n",
      "[2400]\ttraining's l1: 0.0792704\tvalid_1's l1: 0.162452\n",
      "[2500]\ttraining's l1: 0.0772556\tvalid_1's l1: 0.161518\n",
      "[2600]\ttraining's l1: 0.075417\tvalid_1's l1: 0.160979\n",
      "[2700]\ttraining's l1: 0.0736401\tvalid_1's l1: 0.160393\n",
      "[2800]\ttraining's l1: 0.07197\tvalid_1's l1: 0.159805\n",
      "[2900]\ttraining's l1: 0.0703415\tvalid_1's l1: 0.159255\n",
      "[3000]\ttraining's l1: 0.0688004\tvalid_1's l1: 0.158745\n",
      "[3100]\ttraining's l1: 0.0673087\tvalid_1's l1: 0.158372\n",
      "[3200]\ttraining's l1: 0.0658369\tvalid_1's l1: 0.157908\n",
      "[3300]\ttraining's l1: 0.0644392\tvalid_1's l1: 0.157453\n",
      "[3400]\ttraining's l1: 0.063097\tvalid_1's l1: 0.157066\n",
      "[3500]\ttraining's l1: 0.0618646\tvalid_1's l1: 0.15669\n",
      "[3600]\ttraining's l1: 0.0606698\tvalid_1's l1: 0.156375\n",
      "[3700]\ttraining's l1: 0.0595322\tvalid_1's l1: 0.156068\n",
      "[3800]\ttraining's l1: 0.0584034\tvalid_1's l1: 0.155812\n",
      "[3900]\ttraining's l1: 0.0572571\tvalid_1's l1: 0.155397\n",
      "[4000]\ttraining's l1: 0.0561863\tvalid_1's l1: 0.155103\n",
      "[4100]\ttraining's l1: 0.0551115\tvalid_1's l1: 0.154836\n",
      "[4200]\ttraining's l1: 0.0541007\tvalid_1's l1: 0.154585\n",
      "[4300]\ttraining's l1: 0.0531216\tvalid_1's l1: 0.154291\n",
      "[4400]\ttraining's l1: 0.0521554\tvalid_1's l1: 0.154022\n",
      "[4500]\ttraining's l1: 0.0512167\tvalid_1's l1: 0.153805\n",
      "[4600]\ttraining's l1: 0.0503\tvalid_1's l1: 0.153494\n",
      "[4700]\ttraining's l1: 0.04944\tvalid_1's l1: 0.153325\n",
      "[4800]\ttraining's l1: 0.0486006\tvalid_1's l1: 0.153091\n",
      "[4900]\ttraining's l1: 0.0477755\tvalid_1's l1: 0.152891\n",
      "[5000]\ttraining's l1: 0.0469932\tvalid_1's l1: 0.152731\n",
      "[5100]\ttraining's l1: 0.0462492\tvalid_1's l1: 0.152583\n",
      "[5200]\ttraining's l1: 0.0454465\tvalid_1's l1: 0.152329\n",
      "[5300]\ttraining's l1: 0.0446942\tvalid_1's l1: 0.152189\n",
      "[5400]\ttraining's l1: 0.0439903\tvalid_1's l1: 0.152048\n",
      "[5500]\ttraining's l1: 0.0432756\tvalid_1's l1: 0.151895\n",
      "[5600]\ttraining's l1: 0.0426167\tvalid_1's l1: 0.151705\n",
      "[5700]\ttraining's l1: 0.0419401\tvalid_1's l1: 0.151578\n",
      "[5800]\ttraining's l1: 0.0412813\tvalid_1's l1: 0.151416\n",
      "[5900]\ttraining's l1: 0.0406403\tvalid_1's l1: 0.151326\n",
      "[6000]\ttraining's l1: 0.0400407\tvalid_1's l1: 0.151185\n",
      "[6100]\ttraining's l1: 0.0394112\tvalid_1's l1: 0.151012\n",
      "[6200]\ttraining's l1: 0.0388086\tvalid_1's l1: 0.150898\n",
      "[6300]\ttraining's l1: 0.0381968\tvalid_1's l1: 0.150754\n",
      "[6400]\ttraining's l1: 0.0376543\tvalid_1's l1: 0.150628\n",
      "[6500]\ttraining's l1: 0.0370916\tvalid_1's l1: 0.150522\n",
      "[6600]\ttraining's l1: 0.0365363\tvalid_1's l1: 0.150386\n",
      "[6700]\ttraining's l1: 0.0360057\tvalid_1's l1: 0.150278\n",
      "[6800]\ttraining's l1: 0.035499\tvalid_1's l1: 0.150188\n",
      "[6900]\ttraining's l1: 0.0350106\tvalid_1's l1: 0.150056\n",
      "[7000]\ttraining's l1: 0.0345011\tvalid_1's l1: 0.149927\n",
      "[7100]\ttraining's l1: 0.0340262\tvalid_1's l1: 0.149826\n",
      "[7200]\ttraining's l1: 0.0335524\tvalid_1's l1: 0.149742\n",
      "[7300]\ttraining's l1: 0.0330896\tvalid_1's l1: 0.149645\n",
      "[7400]\ttraining's l1: 0.0326616\tvalid_1's l1: 0.149522\n",
      "[7500]\ttraining's l1: 0.0322252\tvalid_1's l1: 0.149461\n",
      "[7600]\ttraining's l1: 0.031787\tvalid_1's l1: 0.149404\n",
      "[7700]\ttraining's l1: 0.0313561\tvalid_1's l1: 0.149324\n",
      "[7800]\ttraining's l1: 0.0309466\tvalid_1's l1: 0.149246\n",
      "[7900]\ttraining's l1: 0.0305582\tvalid_1's l1: 0.149183\n",
      "[8000]\ttraining's l1: 0.0301676\tvalid_1's l1: 0.149118\n",
      "[8100]\ttraining's l1: 0.0297993\tvalid_1's l1: 0.149055\n",
      "[8200]\ttraining's l1: 0.0294242\tvalid_1's l1: 0.14899\n",
      "[8300]\ttraining's l1: 0.0290313\tvalid_1's l1: 0.148934\n",
      "[8400]\ttraining's l1: 0.0286876\tvalid_1's l1: 0.14888\n",
      "[8500]\ttraining's l1: 0.0283244\tvalid_1's l1: 0.148825\n",
      "[8600]\ttraining's l1: 0.0279564\tvalid_1's l1: 0.148767\n",
      "[8700]\ttraining's l1: 0.0275992\tvalid_1's l1: 0.14869\n",
      "[8800]\ttraining's l1: 0.0272503\tvalid_1's l1: 0.148619\n",
      "[8900]\ttraining's l1: 0.0269137\tvalid_1's l1: 0.148523\n",
      "[9000]\ttraining's l1: 0.0265949\tvalid_1's l1: 0.148471\n",
      "[9100]\ttraining's l1: 0.0262769\tvalid_1's l1: 0.148421\n",
      "[9200]\ttraining's l1: 0.0259545\tvalid_1's l1: 0.148371\n",
      "[9300]\ttraining's l1: 0.0256473\tvalid_1's l1: 0.148315\n",
      "[9400]\ttraining's l1: 0.0253489\tvalid_1's l1: 0.148276\n",
      "[9500]\ttraining's l1: 0.0250604\tvalid_1's l1: 0.148223\n",
      "[9600]\ttraining's l1: 0.0247786\tvalid_1's l1: 0.148175\n",
      "[9700]\ttraining's l1: 0.0244924\tvalid_1's l1: 0.148151\n",
      "[9800]\ttraining's l1: 0.0242175\tvalid_1's l1: 0.148096\n",
      "[9900]\ttraining's l1: 0.0239419\tvalid_1's l1: 0.148035\n",
      "[10000]\ttraining's l1: 0.0236624\tvalid_1's l1: 0.147984\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0236624\tvalid_1's l1: 0.147984\n",
      "2JHN Fold 0, logMAE: -1.910650469240052\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.267838\tvalid_1's l1: 0.283862\n",
      "[200]\ttraining's l1: 0.21737\tvalid_1's l1: 0.242328\n",
      "[300]\ttraining's l1: 0.190883\tvalid_1's l1: 0.221972\n",
      "[400]\ttraining's l1: 0.174135\tvalid_1's l1: 0.210612\n",
      "[500]\ttraining's l1: 0.160925\tvalid_1's l1: 0.201292\n",
      "[600]\ttraining's l1: 0.150975\tvalid_1's l1: 0.194911\n",
      "[700]\ttraining's l1: 0.143052\tvalid_1's l1: 0.190133\n",
      "[800]\ttraining's l1: 0.135749\tvalid_1's l1: 0.186254\n",
      "[900]\ttraining's l1: 0.129381\tvalid_1's l1: 0.182684\n",
      "[1000]\ttraining's l1: 0.123862\tvalid_1's l1: 0.179922\n",
      "[1100]\ttraining's l1: 0.118794\tvalid_1's l1: 0.177308\n",
      "[1200]\ttraining's l1: 0.114373\tvalid_1's l1: 0.175146\n",
      "[1300]\ttraining's l1: 0.110388\tvalid_1's l1: 0.17334\n",
      "[1400]\ttraining's l1: 0.106786\tvalid_1's l1: 0.171555\n",
      "[1500]\ttraining's l1: 0.10323\tvalid_1's l1: 0.170205\n",
      "[1600]\ttraining's l1: 0.0998691\tvalid_1's l1: 0.168771\n",
      "[1700]\ttraining's l1: 0.0968237\tvalid_1's l1: 0.167706\n",
      "[1800]\ttraining's l1: 0.0940398\tvalid_1's l1: 0.166684\n",
      "[1900]\ttraining's l1: 0.0914869\tvalid_1's l1: 0.165555\n",
      "[2000]\ttraining's l1: 0.0889691\tvalid_1's l1: 0.164594\n",
      "[2100]\ttraining's l1: 0.0864804\tvalid_1's l1: 0.163616\n",
      "[2200]\ttraining's l1: 0.0842289\tvalid_1's l1: 0.162755\n",
      "[2300]\ttraining's l1: 0.0821298\tvalid_1's l1: 0.161942\n",
      "[2400]\ttraining's l1: 0.0799684\tvalid_1's l1: 0.161238\n",
      "[2500]\ttraining's l1: 0.0780887\tvalid_1's l1: 0.160612\n",
      "[2600]\ttraining's l1: 0.076212\tvalid_1's l1: 0.159831\n",
      "[2700]\ttraining's l1: 0.074484\tvalid_1's l1: 0.159195\n",
      "[2800]\ttraining's l1: 0.0727711\tvalid_1's l1: 0.158582\n",
      "[2900]\ttraining's l1: 0.0711095\tvalid_1's l1: 0.15808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3000]\ttraining's l1: 0.0694869\tvalid_1's l1: 0.157668\n",
      "[3100]\ttraining's l1: 0.0679219\tvalid_1's l1: 0.157183\n",
      "[3200]\ttraining's l1: 0.0664775\tvalid_1's l1: 0.156791\n",
      "[3300]\ttraining's l1: 0.0650136\tvalid_1's l1: 0.156391\n",
      "[3400]\ttraining's l1: 0.0636995\tvalid_1's l1: 0.155981\n",
      "[3500]\ttraining's l1: 0.0624488\tvalid_1's l1: 0.155615\n",
      "[3600]\ttraining's l1: 0.0612499\tvalid_1's l1: 0.155219\n",
      "[3700]\ttraining's l1: 0.0600615\tvalid_1's l1: 0.15493\n",
      "[3800]\ttraining's l1: 0.0589006\tvalid_1's l1: 0.154603\n",
      "[3900]\ttraining's l1: 0.0576763\tvalid_1's l1: 0.154298\n",
      "[4000]\ttraining's l1: 0.0566364\tvalid_1's l1: 0.154062\n",
      "[4100]\ttraining's l1: 0.0555802\tvalid_1's l1: 0.153769\n",
      "[4200]\ttraining's l1: 0.0546248\tvalid_1's l1: 0.153567\n",
      "[4300]\ttraining's l1: 0.0535975\tvalid_1's l1: 0.153291\n",
      "[4400]\ttraining's l1: 0.0526293\tvalid_1's l1: 0.153029\n",
      "[4500]\ttraining's l1: 0.0517194\tvalid_1's l1: 0.152826\n",
      "[4600]\ttraining's l1: 0.0508113\tvalid_1's l1: 0.152603\n",
      "[4700]\ttraining's l1: 0.0499696\tvalid_1's l1: 0.152415\n",
      "[4800]\ttraining's l1: 0.0490895\tvalid_1's l1: 0.152192\n",
      "[4900]\ttraining's l1: 0.0482125\tvalid_1's l1: 0.151969\n",
      "[5000]\ttraining's l1: 0.0474191\tvalid_1's l1: 0.151821\n",
      "[5100]\ttraining's l1: 0.0466211\tvalid_1's l1: 0.151586\n",
      "[5200]\ttraining's l1: 0.0458516\tvalid_1's l1: 0.151439\n",
      "[5300]\ttraining's l1: 0.0451301\tvalid_1's l1: 0.151243\n",
      "[5400]\ttraining's l1: 0.0444047\tvalid_1's l1: 0.151083\n",
      "[5500]\ttraining's l1: 0.0436925\tvalid_1's l1: 0.150961\n",
      "[5600]\ttraining's l1: 0.042998\tvalid_1's l1: 0.150782\n",
      "[5700]\ttraining's l1: 0.0423341\tvalid_1's l1: 0.150628\n",
      "[5800]\ttraining's l1: 0.0416596\tvalid_1's l1: 0.15052\n",
      "[5900]\ttraining's l1: 0.0410375\tvalid_1's l1: 0.150385\n",
      "[6000]\ttraining's l1: 0.0404177\tvalid_1's l1: 0.150267\n",
      "[6100]\ttraining's l1: 0.0398211\tvalid_1's l1: 0.150157\n",
      "[6200]\ttraining's l1: 0.0392273\tvalid_1's l1: 0.150007\n",
      "[6300]\ttraining's l1: 0.0386528\tvalid_1's l1: 0.149883\n",
      "[6400]\ttraining's l1: 0.0380837\tvalid_1's l1: 0.149797\n",
      "[6500]\ttraining's l1: 0.0375569\tvalid_1's l1: 0.149686\n",
      "[6600]\ttraining's l1: 0.0370096\tvalid_1's l1: 0.149538\n",
      "[6700]\ttraining's l1: 0.0364999\tvalid_1's l1: 0.149432\n",
      "[6800]\ttraining's l1: 0.0359597\tvalid_1's l1: 0.149354\n",
      "[6900]\ttraining's l1: 0.0354637\tvalid_1's l1: 0.149257\n",
      "[7000]\ttraining's l1: 0.0349751\tvalid_1's l1: 0.149161\n",
      "[7100]\ttraining's l1: 0.0344982\tvalid_1's l1: 0.149051\n",
      "[7200]\ttraining's l1: 0.0340305\tvalid_1's l1: 0.148966\n",
      "[7300]\ttraining's l1: 0.033561\tvalid_1's l1: 0.148904\n",
      "[7400]\ttraining's l1: 0.0330957\tvalid_1's l1: 0.148813\n",
      "[7500]\ttraining's l1: 0.0326638\tvalid_1's l1: 0.148748\n",
      "[7600]\ttraining's l1: 0.0322405\tvalid_1's l1: 0.148668\n",
      "[7700]\ttraining's l1: 0.0318322\tvalid_1's l1: 0.14861\n",
      "[7800]\ttraining's l1: 0.0314347\tvalid_1's l1: 0.148532\n",
      "[7900]\ttraining's l1: 0.03103\tvalid_1's l1: 0.148444\n",
      "[8000]\ttraining's l1: 0.0306278\tvalid_1's l1: 0.148375\n",
      "[8100]\ttraining's l1: 0.0302565\tvalid_1's l1: 0.148348\n",
      "[8200]\ttraining's l1: 0.0298666\tvalid_1's l1: 0.148275\n",
      "[8300]\ttraining's l1: 0.0294916\tvalid_1's l1: 0.148188\n",
      "[8400]\ttraining's l1: 0.0291299\tvalid_1's l1: 0.148121\n",
      "[8500]\ttraining's l1: 0.0287864\tvalid_1's l1: 0.148039\n",
      "[8600]\ttraining's l1: 0.0284303\tvalid_1's l1: 0.148006\n",
      "[8700]\ttraining's l1: 0.0280746\tvalid_1's l1: 0.147943\n",
      "[8800]\ttraining's l1: 0.0277391\tvalid_1's l1: 0.147873\n",
      "[8900]\ttraining's l1: 0.0274017\tvalid_1's l1: 0.1478\n",
      "[9000]\ttraining's l1: 0.0270793\tvalid_1's l1: 0.147739\n",
      "[9100]\ttraining's l1: 0.026761\tvalid_1's l1: 0.147706\n",
      "[9200]\ttraining's l1: 0.0264473\tvalid_1's l1: 0.147666\n",
      "[9300]\ttraining's l1: 0.0261489\tvalid_1's l1: 0.147614\n",
      "[9400]\ttraining's l1: 0.0258426\tvalid_1's l1: 0.147543\n",
      "[9500]\ttraining's l1: 0.0255405\tvalid_1's l1: 0.147515\n",
      "[9600]\ttraining's l1: 0.0252489\tvalid_1's l1: 0.147472\n",
      "[9700]\ttraining's l1: 0.0249571\tvalid_1's l1: 0.147412\n",
      "[9800]\ttraining's l1: 0.0246677\tvalid_1's l1: 0.14736\n",
      "[9900]\ttraining's l1: 0.0244054\tvalid_1's l1: 0.147335\n",
      "[10000]\ttraining's l1: 0.0241195\tvalid_1's l1: 0.14728\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0241195\tvalid_1's l1: 0.14728\n",
      "2JHN Fold 1, logMAE: -1.9154216241040316\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.261306\tvalid_1's l1: 0.277007\n",
      "[200]\ttraining's l1: 0.21299\tvalid_1's l1: 0.237114\n",
      "[300]\ttraining's l1: 0.18818\tvalid_1's l1: 0.217752\n",
      "[400]\ttraining's l1: 0.172329\tvalid_1's l1: 0.206053\n",
      "[500]\ttraining's l1: 0.160085\tvalid_1's l1: 0.197942\n",
      "[600]\ttraining's l1: 0.150301\tvalid_1's l1: 0.191553\n",
      "[700]\ttraining's l1: 0.142489\tvalid_1's l1: 0.187008\n",
      "[800]\ttraining's l1: 0.135417\tvalid_1's l1: 0.182871\n",
      "[900]\ttraining's l1: 0.129205\tvalid_1's l1: 0.17931\n",
      "[1000]\ttraining's l1: 0.123791\tvalid_1's l1: 0.176736\n",
      "[1100]\ttraining's l1: 0.118596\tvalid_1's l1: 0.174271\n",
      "[1200]\ttraining's l1: 0.114103\tvalid_1's l1: 0.172004\n",
      "[1300]\ttraining's l1: 0.110017\tvalid_1's l1: 0.16986\n",
      "[1400]\ttraining's l1: 0.106151\tvalid_1's l1: 0.167942\n",
      "[1500]\ttraining's l1: 0.102637\tvalid_1's l1: 0.166423\n",
      "[1600]\ttraining's l1: 0.0994904\tvalid_1's l1: 0.164989\n",
      "[1700]\ttraining's l1: 0.0963989\tvalid_1's l1: 0.163723\n",
      "[1800]\ttraining's l1: 0.0933657\tvalid_1's l1: 0.162494\n",
      "[1900]\ttraining's l1: 0.0907963\tvalid_1's l1: 0.161337\n",
      "[2000]\ttraining's l1: 0.0883761\tvalid_1's l1: 0.160179\n",
      "[2100]\ttraining's l1: 0.086089\tvalid_1's l1: 0.15939\n",
      "[2200]\ttraining's l1: 0.083853\tvalid_1's l1: 0.158591\n",
      "[2300]\ttraining's l1: 0.0815902\tvalid_1's l1: 0.157714\n",
      "[2400]\ttraining's l1: 0.0795552\tvalid_1's l1: 0.156979\n",
      "[2500]\ttraining's l1: 0.0776521\tvalid_1's l1: 0.156312\n",
      "[2600]\ttraining's l1: 0.0757731\tvalid_1's l1: 0.155612\n",
      "[2700]\ttraining's l1: 0.0737499\tvalid_1's l1: 0.154815\n",
      "[2800]\ttraining's l1: 0.072107\tvalid_1's l1: 0.154273\n",
      "[2900]\ttraining's l1: 0.0705636\tvalid_1's l1: 0.153742\n",
      "[3000]\ttraining's l1: 0.0689413\tvalid_1's l1: 0.153357\n",
      "[3100]\ttraining's l1: 0.0674317\tvalid_1's l1: 0.152853\n",
      "[3200]\ttraining's l1: 0.0659988\tvalid_1's l1: 0.1524\n",
      "[3300]\ttraining's l1: 0.0646238\tvalid_1's l1: 0.152035\n",
      "[3400]\ttraining's l1: 0.0632635\tvalid_1's l1: 0.151655\n",
      "[3500]\ttraining's l1: 0.062008\tvalid_1's l1: 0.151301\n",
      "[3600]\ttraining's l1: 0.0607797\tvalid_1's l1: 0.150994\n",
      "[3700]\ttraining's l1: 0.0595449\tvalid_1's l1: 0.15068\n",
      "[3800]\ttraining's l1: 0.0584237\tvalid_1's l1: 0.150419\n",
      "[3900]\ttraining's l1: 0.0573081\tvalid_1's l1: 0.150149\n",
      "[4000]\ttraining's l1: 0.0561799\tvalid_1's l1: 0.149852\n",
      "[4100]\ttraining's l1: 0.055173\tvalid_1's l1: 0.149567\n",
      "[4200]\ttraining's l1: 0.054165\tvalid_1's l1: 0.149285\n",
      "[4300]\ttraining's l1: 0.0531895\tvalid_1's l1: 0.149017\n",
      "[4400]\ttraining's l1: 0.0522335\tvalid_1's l1: 0.148755\n",
      "[4500]\ttraining's l1: 0.0513116\tvalid_1's l1: 0.148495\n",
      "[4600]\ttraining's l1: 0.0503941\tvalid_1's l1: 0.148235\n",
      "[4700]\ttraining's l1: 0.0495499\tvalid_1's l1: 0.148045\n",
      "[4800]\ttraining's l1: 0.0486857\tvalid_1's l1: 0.147852\n",
      "[4900]\ttraining's l1: 0.0478639\tvalid_1's l1: 0.147649\n",
      "[5000]\ttraining's l1: 0.0470466\tvalid_1's l1: 0.147454\n",
      "[5100]\ttraining's l1: 0.0462317\tvalid_1's l1: 0.147241\n",
      "[5200]\ttraining's l1: 0.0454689\tvalid_1's l1: 0.147071\n",
      "[5300]\ttraining's l1: 0.0447414\tvalid_1's l1: 0.146914\n",
      "[5400]\ttraining's l1: 0.0440133\tvalid_1's l1: 0.146823\n",
      "[5500]\ttraining's l1: 0.0432936\tvalid_1's l1: 0.14667\n",
      "[5600]\ttraining's l1: 0.0426243\tvalid_1's l1: 0.146533\n",
      "[5700]\ttraining's l1: 0.0419571\tvalid_1's l1: 0.146396\n",
      "[5800]\ttraining's l1: 0.0412996\tvalid_1's l1: 0.146258\n",
      "[5900]\ttraining's l1: 0.0406617\tvalid_1's l1: 0.146129\n",
      "[6000]\ttraining's l1: 0.04003\tvalid_1's l1: 0.146018\n",
      "[6100]\ttraining's l1: 0.0394186\tvalid_1's l1: 0.145894\n",
      "[6200]\ttraining's l1: 0.0388457\tvalid_1's l1: 0.145795\n",
      "[6300]\ttraining's l1: 0.0382679\tvalid_1's l1: 0.145671\n",
      "[6400]\ttraining's l1: 0.0377044\tvalid_1's l1: 0.145556\n",
      "[6500]\ttraining's l1: 0.0371301\tvalid_1's l1: 0.145447\n",
      "[6600]\ttraining's l1: 0.036641\tvalid_1's l1: 0.145306\n",
      "[6700]\ttraining's l1: 0.036127\tvalid_1's l1: 0.145195\n",
      "[6800]\ttraining's l1: 0.0356049\tvalid_1's l1: 0.145106\n",
      "[6900]\ttraining's l1: 0.0351146\tvalid_1's l1: 0.145025\n",
      "[7000]\ttraining's l1: 0.0346249\tvalid_1's l1: 0.144931\n",
      "[7100]\ttraining's l1: 0.0341532\tvalid_1's l1: 0.14484\n",
      "[7200]\ttraining's l1: 0.0336569\tvalid_1's l1: 0.14475\n",
      "[7300]\ttraining's l1: 0.0331989\tvalid_1's l1: 0.144679\n",
      "[7400]\ttraining's l1: 0.0327386\tvalid_1's l1: 0.144624\n",
      "[7500]\ttraining's l1: 0.0323039\tvalid_1's l1: 0.144546\n",
      "[7600]\ttraining's l1: 0.0318882\tvalid_1's l1: 0.144461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7700]\ttraining's l1: 0.0314901\tvalid_1's l1: 0.144427\n",
      "[7800]\ttraining's l1: 0.0310778\tvalid_1's l1: 0.144373\n",
      "[7900]\ttraining's l1: 0.0306497\tvalid_1's l1: 0.144314\n",
      "[8000]\ttraining's l1: 0.0302739\tvalid_1's l1: 0.144272\n",
      "[8100]\ttraining's l1: 0.0298862\tvalid_1's l1: 0.144213\n",
      "[8200]\ttraining's l1: 0.0295107\tvalid_1's l1: 0.144132\n",
      "[8300]\ttraining's l1: 0.029135\tvalid_1's l1: 0.144075\n",
      "[8400]\ttraining's l1: 0.0287723\tvalid_1's l1: 0.144013\n",
      "[8500]\ttraining's l1: 0.0284197\tvalid_1's l1: 0.143953\n",
      "[8600]\ttraining's l1: 0.0280673\tvalid_1's l1: 0.143914\n",
      "[8700]\ttraining's l1: 0.0277369\tvalid_1's l1: 0.143877\n",
      "[8800]\ttraining's l1: 0.0273848\tvalid_1's l1: 0.143839\n",
      "[8900]\ttraining's l1: 0.0270437\tvalid_1's l1: 0.143802\n",
      "[9000]\ttraining's l1: 0.0267143\tvalid_1's l1: 0.143758\n",
      "[9100]\ttraining's l1: 0.026391\tvalid_1's l1: 0.143713\n",
      "[9200]\ttraining's l1: 0.0260905\tvalid_1's l1: 0.143696\n",
      "[9300]\ttraining's l1: 0.0257932\tvalid_1's l1: 0.143646\n",
      "[9400]\ttraining's l1: 0.0254983\tvalid_1's l1: 0.143597\n",
      "[9500]\ttraining's l1: 0.0251881\tvalid_1's l1: 0.143545\n",
      "[9600]\ttraining's l1: 0.0249072\tvalid_1's l1: 0.143494\n",
      "[9700]\ttraining's l1: 0.0246206\tvalid_1's l1: 0.143443\n",
      "[9800]\ttraining's l1: 0.0243519\tvalid_1's l1: 0.143402\n",
      "[9900]\ttraining's l1: 0.0240858\tvalid_1's l1: 0.14336\n",
      "[10000]\ttraining's l1: 0.0237911\tvalid_1's l1: 0.143325\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0237911\tvalid_1's l1: 0.143325\n",
      "2JHN Fold 2, logMAE: -1.9426418585645127\n",
      "*** Training Model for 2JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.647132\tvalid_1's l1: 0.652633\n",
      "[200]\ttraining's l1: 0.567186\tvalid_1's l1: 0.577478\n",
      "[300]\ttraining's l1: 0.522175\tvalid_1's l1: 0.536115\n",
      "[400]\ttraining's l1: 0.490249\tvalid_1's l1: 0.507537\n",
      "[500]\ttraining's l1: 0.46687\tvalid_1's l1: 0.487181\n",
      "[600]\ttraining's l1: 0.449747\tvalid_1's l1: 0.472454\n",
      "[700]\ttraining's l1: 0.434833\tvalid_1's l1: 0.460134\n",
      "[800]\ttraining's l1: 0.421836\tvalid_1's l1: 0.449386\n",
      "[900]\ttraining's l1: 0.411394\tvalid_1's l1: 0.441164\n",
      "[1000]\ttraining's l1: 0.402221\tvalid_1's l1: 0.433839\n",
      "[1100]\ttraining's l1: 0.393273\tvalid_1's l1: 0.426934\n",
      "[1200]\ttraining's l1: 0.385284\tvalid_1's l1: 0.420887\n",
      "[1300]\ttraining's l1: 0.378298\tvalid_1's l1: 0.415755\n",
      "[1400]\ttraining's l1: 0.371604\tvalid_1's l1: 0.410938\n",
      "[1500]\ttraining's l1: 0.365318\tvalid_1's l1: 0.406368\n",
      "[1600]\ttraining's l1: 0.359828\tvalid_1's l1: 0.402562\n",
      "[1700]\ttraining's l1: 0.354375\tvalid_1's l1: 0.398604\n",
      "[1800]\ttraining's l1: 0.349464\tvalid_1's l1: 0.395148\n",
      "[1900]\ttraining's l1: 0.344628\tvalid_1's l1: 0.391734\n",
      "[2000]\ttraining's l1: 0.339978\tvalid_1's l1: 0.388534\n",
      "[2100]\ttraining's l1: 0.33563\tvalid_1's l1: 0.385577\n",
      "[2200]\ttraining's l1: 0.33158\tvalid_1's l1: 0.38293\n",
      "[2300]\ttraining's l1: 0.327714\tvalid_1's l1: 0.380367\n",
      "[2400]\ttraining's l1: 0.323836\tvalid_1's l1: 0.377867\n",
      "[2500]\ttraining's l1: 0.320299\tvalid_1's l1: 0.375565\n",
      "[2600]\ttraining's l1: 0.316969\tvalid_1's l1: 0.373527\n",
      "[2700]\ttraining's l1: 0.313484\tvalid_1's l1: 0.371424\n",
      "[2800]\ttraining's l1: 0.310225\tvalid_1's l1: 0.369456\n",
      "[2900]\ttraining's l1: 0.307018\tvalid_1's l1: 0.367526\n",
      "[3000]\ttraining's l1: 0.304189\tvalid_1's l1: 0.365873\n",
      "[3100]\ttraining's l1: 0.301166\tvalid_1's l1: 0.364109\n",
      "[3200]\ttraining's l1: 0.298326\tvalid_1's l1: 0.362505\n",
      "[3300]\ttraining's l1: 0.295647\tvalid_1's l1: 0.360889\n",
      "[3400]\ttraining's l1: 0.292917\tvalid_1's l1: 0.359372\n",
      "[3500]\ttraining's l1: 0.290183\tvalid_1's l1: 0.357864\n",
      "[3600]\ttraining's l1: 0.287889\tvalid_1's l1: 0.35663\n",
      "[3700]\ttraining's l1: 0.285592\tvalid_1's l1: 0.355305\n",
      "[3800]\ttraining's l1: 0.283185\tvalid_1's l1: 0.354037\n",
      "[3900]\ttraining's l1: 0.280778\tvalid_1's l1: 0.352783\n",
      "[4000]\ttraining's l1: 0.278379\tvalid_1's l1: 0.351425\n",
      "[4100]\ttraining's l1: 0.27625\tvalid_1's l1: 0.35031\n",
      "[4200]\ttraining's l1: 0.274203\tvalid_1's l1: 0.349209\n",
      "[4300]\ttraining's l1: 0.272336\tvalid_1's l1: 0.348281\n",
      "[4400]\ttraining's l1: 0.270308\tvalid_1's l1: 0.347136\n",
      "[4500]\ttraining's l1: 0.268235\tvalid_1's l1: 0.346102\n",
      "[4600]\ttraining's l1: 0.266311\tvalid_1's l1: 0.345098\n",
      "[4700]\ttraining's l1: 0.264425\tvalid_1's l1: 0.344188\n",
      "[4800]\ttraining's l1: 0.262526\tvalid_1's l1: 0.343198\n",
      "[4900]\ttraining's l1: 0.260711\tvalid_1's l1: 0.342256\n",
      "[5000]\ttraining's l1: 0.2589\tvalid_1's l1: 0.341325\n",
      "[5100]\ttraining's l1: 0.257128\tvalid_1's l1: 0.340427\n",
      "[5200]\ttraining's l1: 0.255289\tvalid_1's l1: 0.339456\n",
      "[5300]\ttraining's l1: 0.253548\tvalid_1's l1: 0.338584\n",
      "[5400]\ttraining's l1: 0.251873\tvalid_1's l1: 0.337817\n",
      "[5500]\ttraining's l1: 0.250279\tvalid_1's l1: 0.337053\n",
      "[5600]\ttraining's l1: 0.248586\tvalid_1's l1: 0.336222\n",
      "[5700]\ttraining's l1: 0.247078\tvalid_1's l1: 0.335496\n",
      "[5800]\ttraining's l1: 0.245527\tvalid_1's l1: 0.334811\n",
      "[5900]\ttraining's l1: 0.244034\tvalid_1's l1: 0.334169\n",
      "[6000]\ttraining's l1: 0.242485\tvalid_1's l1: 0.333454\n",
      "[6100]\ttraining's l1: 0.241039\tvalid_1's l1: 0.332793\n",
      "[6200]\ttraining's l1: 0.239565\tvalid_1's l1: 0.332151\n",
      "[6300]\ttraining's l1: 0.238045\tvalid_1's l1: 0.331373\n",
      "[6400]\ttraining's l1: 0.236626\tvalid_1's l1: 0.330696\n",
      "[6500]\ttraining's l1: 0.235202\tvalid_1's l1: 0.330067\n",
      "[6600]\ttraining's l1: 0.233796\tvalid_1's l1: 0.329449\n",
      "[6700]\ttraining's l1: 0.23247\tvalid_1's l1: 0.328877\n",
      "[6800]\ttraining's l1: 0.231169\tvalid_1's l1: 0.328237\n",
      "[6900]\ttraining's l1: 0.22986\tvalid_1's l1: 0.327709\n",
      "[7000]\ttraining's l1: 0.228549\tvalid_1's l1: 0.327197\n",
      "[7100]\ttraining's l1: 0.227286\tvalid_1's l1: 0.326659\n",
      "[7200]\ttraining's l1: 0.22602\tvalid_1's l1: 0.326182\n",
      "[7300]\ttraining's l1: 0.224786\tvalid_1's l1: 0.32561\n",
      "[7400]\ttraining's l1: 0.223519\tvalid_1's l1: 0.325021\n",
      "[7500]\ttraining's l1: 0.222275\tvalid_1's l1: 0.32445\n",
      "[7600]\ttraining's l1: 0.221083\tvalid_1's l1: 0.323908\n",
      "[7700]\ttraining's l1: 0.219926\tvalid_1's l1: 0.323467\n",
      "[7800]\ttraining's l1: 0.218695\tvalid_1's l1: 0.322956\n",
      "[7900]\ttraining's l1: 0.217477\tvalid_1's l1: 0.322433\n",
      "[8000]\ttraining's l1: 0.21632\tvalid_1's l1: 0.32193\n",
      "[8100]\ttraining's l1: 0.215238\tvalid_1's l1: 0.321493\n",
      "[8200]\ttraining's l1: 0.214133\tvalid_1's l1: 0.321019\n",
      "[8300]\ttraining's l1: 0.21306\tvalid_1's l1: 0.320567\n",
      "[8400]\ttraining's l1: 0.211988\tvalid_1's l1: 0.320093\n",
      "[8500]\ttraining's l1: 0.210958\tvalid_1's l1: 0.319678\n",
      "[8600]\ttraining's l1: 0.209888\tvalid_1's l1: 0.319284\n",
      "[8700]\ttraining's l1: 0.20885\tvalid_1's l1: 0.318894\n",
      "[8800]\ttraining's l1: 0.207803\tvalid_1's l1: 0.318525\n",
      "[8900]\ttraining's l1: 0.206734\tvalid_1's l1: 0.318067\n",
      "[9000]\ttraining's l1: 0.205727\tvalid_1's l1: 0.317715\n",
      "[9100]\ttraining's l1: 0.204777\tvalid_1's l1: 0.317343\n",
      "[9200]\ttraining's l1: 0.203819\tvalid_1's l1: 0.31699\n",
      "[9300]\ttraining's l1: 0.202853\tvalid_1's l1: 0.316589\n",
      "[9400]\ttraining's l1: 0.201881\tvalid_1's l1: 0.316215\n",
      "[9500]\ttraining's l1: 0.200912\tvalid_1's l1: 0.315833\n",
      "[9600]\ttraining's l1: 0.199944\tvalid_1's l1: 0.315471\n",
      "[9700]\ttraining's l1: 0.199011\tvalid_1's l1: 0.315145\n",
      "[9800]\ttraining's l1: 0.19803\tvalid_1's l1: 0.314781\n",
      "[9900]\ttraining's l1: 0.197096\tvalid_1's l1: 0.314427\n",
      "[10000]\ttraining's l1: 0.196213\tvalid_1's l1: 0.314093\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.196213\tvalid_1's l1: 0.314093\n",
      "2JHC Fold 0, logMAE: -1.158067634685472\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.645381\tvalid_1's l1: 0.653975\n",
      "[200]\ttraining's l1: 0.563614\tvalid_1's l1: 0.575573\n",
      "[300]\ttraining's l1: 0.519916\tvalid_1's l1: 0.534991\n",
      "[400]\ttraining's l1: 0.489897\tvalid_1's l1: 0.507706\n",
      "[500]\ttraining's l1: 0.467999\tvalid_1's l1: 0.488633\n",
      "[600]\ttraining's l1: 0.45064\tvalid_1's l1: 0.473768\n",
      "[700]\ttraining's l1: 0.435804\tvalid_1's l1: 0.461292\n",
      "[800]\ttraining's l1: 0.423359\tvalid_1's l1: 0.451237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[900]\ttraining's l1: 0.412393\tvalid_1's l1: 0.442666\n",
      "[1000]\ttraining's l1: 0.402533\tvalid_1's l1: 0.434643\n",
      "[1100]\ttraining's l1: 0.394486\tvalid_1's l1: 0.428587\n",
      "[1200]\ttraining's l1: 0.38671\tvalid_1's l1: 0.422708\n",
      "[1300]\ttraining's l1: 0.379038\tvalid_1's l1: 0.4168\n",
      "[1400]\ttraining's l1: 0.372325\tvalid_1's l1: 0.411839\n",
      "[1500]\ttraining's l1: 0.366059\tvalid_1's l1: 0.407177\n",
      "[1600]\ttraining's l1: 0.360377\tvalid_1's l1: 0.403158\n",
      "[1700]\ttraining's l1: 0.354725\tvalid_1's l1: 0.399029\n",
      "[1800]\ttraining's l1: 0.349795\tvalid_1's l1: 0.395638\n",
      "[1900]\ttraining's l1: 0.345112\tvalid_1's l1: 0.392385\n",
      "[2000]\ttraining's l1: 0.34058\tvalid_1's l1: 0.389319\n",
      "[2100]\ttraining's l1: 0.336397\tvalid_1's l1: 0.386535\n",
      "[2200]\ttraining's l1: 0.332167\tvalid_1's l1: 0.383813\n",
      "[2300]\ttraining's l1: 0.32815\tvalid_1's l1: 0.381172\n",
      "[2400]\ttraining's l1: 0.324404\tvalid_1's l1: 0.378797\n",
      "[2500]\ttraining's l1: 0.320935\tvalid_1's l1: 0.376643\n",
      "[2600]\ttraining's l1: 0.317448\tvalid_1's l1: 0.374474\n",
      "[2700]\ttraining's l1: 0.31399\tvalid_1's l1: 0.372245\n",
      "[2800]\ttraining's l1: 0.31073\tvalid_1's l1: 0.370212\n",
      "[2900]\ttraining's l1: 0.307456\tvalid_1's l1: 0.368176\n",
      "[3000]\ttraining's l1: 0.304484\tvalid_1's l1: 0.366418\n",
      "[3100]\ttraining's l1: 0.301634\tvalid_1's l1: 0.3647\n",
      "[3200]\ttraining's l1: 0.298732\tvalid_1's l1: 0.363091\n",
      "[3300]\ttraining's l1: 0.295871\tvalid_1's l1: 0.361361\n",
      "[3400]\ttraining's l1: 0.29327\tvalid_1's l1: 0.359945\n",
      "[3500]\ttraining's l1: 0.29072\tvalid_1's l1: 0.358413\n",
      "[3600]\ttraining's l1: 0.288267\tvalid_1's l1: 0.356966\n",
      "[3700]\ttraining's l1: 0.285879\tvalid_1's l1: 0.355618\n",
      "[3800]\ttraining's l1: 0.283383\tvalid_1's l1: 0.354119\n",
      "[3900]\ttraining's l1: 0.281159\tvalid_1's l1: 0.352874\n",
      "[4000]\ttraining's l1: 0.279005\tvalid_1's l1: 0.351785\n",
      "[4100]\ttraining's l1: 0.276738\tvalid_1's l1: 0.350518\n",
      "[4200]\ttraining's l1: 0.274591\tvalid_1's l1: 0.349338\n",
      "[4300]\ttraining's l1: 0.272405\tvalid_1's l1: 0.348139\n",
      "[4400]\ttraining's l1: 0.270375\tvalid_1's l1: 0.347082\n",
      "[4500]\ttraining's l1: 0.268298\tvalid_1's l1: 0.34591\n",
      "[4600]\ttraining's l1: 0.266284\tvalid_1's l1: 0.344903\n",
      "[4700]\ttraining's l1: 0.264389\tvalid_1's l1: 0.343904\n",
      "[4800]\ttraining's l1: 0.262522\tvalid_1's l1: 0.342946\n",
      "[4900]\ttraining's l1: 0.260555\tvalid_1's l1: 0.341913\n",
      "[5000]\ttraining's l1: 0.258823\tvalid_1's l1: 0.34104\n",
      "[5100]\ttraining's l1: 0.257145\tvalid_1's l1: 0.340112\n",
      "[5200]\ttraining's l1: 0.2554\tvalid_1's l1: 0.339243\n",
      "[5300]\ttraining's l1: 0.253611\tvalid_1's l1: 0.338335\n",
      "[5400]\ttraining's l1: 0.251892\tvalid_1's l1: 0.337428\n",
      "[5500]\ttraining's l1: 0.250271\tvalid_1's l1: 0.336585\n",
      "[5600]\ttraining's l1: 0.248674\tvalid_1's l1: 0.335812\n",
      "[5700]\ttraining's l1: 0.247028\tvalid_1's l1: 0.335018\n",
      "[5800]\ttraining's l1: 0.245518\tvalid_1's l1: 0.334294\n",
      "[5900]\ttraining's l1: 0.244032\tvalid_1's l1: 0.333584\n",
      "[6000]\ttraining's l1: 0.242587\tvalid_1's l1: 0.332884\n",
      "[6100]\ttraining's l1: 0.241005\tvalid_1's l1: 0.332159\n",
      "[6200]\ttraining's l1: 0.239479\tvalid_1's l1: 0.33147\n",
      "[6300]\ttraining's l1: 0.238037\tvalid_1's l1: 0.330771\n",
      "[6400]\ttraining's l1: 0.236561\tvalid_1's l1: 0.330046\n",
      "[6500]\ttraining's l1: 0.235222\tvalid_1's l1: 0.329502\n",
      "[6600]\ttraining's l1: 0.233851\tvalid_1's l1: 0.328856\n",
      "[6700]\ttraining's l1: 0.23252\tvalid_1's l1: 0.328276\n",
      "[6800]\ttraining's l1: 0.231149\tvalid_1's l1: 0.327621\n",
      "[6900]\ttraining's l1: 0.229815\tvalid_1's l1: 0.326975\n",
      "[7000]\ttraining's l1: 0.228523\tvalid_1's l1: 0.326398\n",
      "[7100]\ttraining's l1: 0.227216\tvalid_1's l1: 0.325832\n",
      "[7200]\ttraining's l1: 0.225969\tvalid_1's l1: 0.325293\n",
      "[7300]\ttraining's l1: 0.224651\tvalid_1's l1: 0.324659\n",
      "[7400]\ttraining's l1: 0.223514\tvalid_1's l1: 0.324135\n",
      "[7500]\ttraining's l1: 0.222315\tvalid_1's l1: 0.323633\n",
      "[7600]\ttraining's l1: 0.221087\tvalid_1's l1: 0.323114\n",
      "[7700]\ttraining's l1: 0.219917\tvalid_1's l1: 0.322601\n",
      "[7800]\ttraining's l1: 0.218764\tvalid_1's l1: 0.322104\n",
      "[7900]\ttraining's l1: 0.217639\tvalid_1's l1: 0.321607\n",
      "[8000]\ttraining's l1: 0.21645\tvalid_1's l1: 0.321071\n",
      "[8100]\ttraining's l1: 0.215276\tvalid_1's l1: 0.320588\n",
      "[8200]\ttraining's l1: 0.214161\tvalid_1's l1: 0.320175\n",
      "[8300]\ttraining's l1: 0.213055\tvalid_1's l1: 0.319733\n",
      "[8400]\ttraining's l1: 0.212023\tvalid_1's l1: 0.319343\n",
      "[8500]\ttraining's l1: 0.210936\tvalid_1's l1: 0.318911\n",
      "[8600]\ttraining's l1: 0.209905\tvalid_1's l1: 0.318496\n",
      "[8700]\ttraining's l1: 0.20885\tvalid_1's l1: 0.318086\n",
      "[8800]\ttraining's l1: 0.207772\tvalid_1's l1: 0.317667\n",
      "[8900]\ttraining's l1: 0.206756\tvalid_1's l1: 0.31726\n",
      "[9000]\ttraining's l1: 0.205691\tvalid_1's l1: 0.316847\n",
      "[9100]\ttraining's l1: 0.204666\tvalid_1's l1: 0.316435\n",
      "[9200]\ttraining's l1: 0.203669\tvalid_1's l1: 0.316028\n",
      "[9300]\ttraining's l1: 0.202665\tvalid_1's l1: 0.315578\n",
      "[9400]\ttraining's l1: 0.201666\tvalid_1's l1: 0.315209\n",
      "[9500]\ttraining's l1: 0.200637\tvalid_1's l1: 0.314801\n",
      "[9600]\ttraining's l1: 0.199696\tvalid_1's l1: 0.314468\n",
      "[9700]\ttraining's l1: 0.198792\tvalid_1's l1: 0.314114\n",
      "[9800]\ttraining's l1: 0.197864\tvalid_1's l1: 0.313749\n",
      "[9900]\ttraining's l1: 0.196953\tvalid_1's l1: 0.31341\n",
      "[10000]\ttraining's l1: 0.196027\tvalid_1's l1: 0.313055\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.196027\tvalid_1's l1: 0.313055\n",
      "2JHC Fold 1, logMAE: -1.1613772815577241\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.647911\tvalid_1's l1: 0.65356\n",
      "[200]\ttraining's l1: 0.563245\tvalid_1's l1: 0.571626\n",
      "[300]\ttraining's l1: 0.520364\tvalid_1's l1: 0.531843\n",
      "[400]\ttraining's l1: 0.490506\tvalid_1's l1: 0.505049\n",
      "[500]\ttraining's l1: 0.468113\tvalid_1's l1: 0.485689\n",
      "[600]\ttraining's l1: 0.449389\tvalid_1's l1: 0.469861\n",
      "[700]\ttraining's l1: 0.434968\tvalid_1's l1: 0.457976\n",
      "[800]\ttraining's l1: 0.422461\tvalid_1's l1: 0.447791\n",
      "[900]\ttraining's l1: 0.411898\tvalid_1's l1: 0.439585\n",
      "[1000]\ttraining's l1: 0.402183\tvalid_1's l1: 0.43185\n",
      "[1100]\ttraining's l1: 0.393844\tvalid_1's l1: 0.425622\n",
      "[1200]\ttraining's l1: 0.385907\tvalid_1's l1: 0.419751\n",
      "[1300]\ttraining's l1: 0.378837\tvalid_1's l1: 0.414619\n",
      "[1400]\ttraining's l1: 0.371995\tvalid_1's l1: 0.409632\n",
      "[1500]\ttraining's l1: 0.365829\tvalid_1's l1: 0.405175\n",
      "[1600]\ttraining's l1: 0.360254\tvalid_1's l1: 0.401075\n",
      "[1700]\ttraining's l1: 0.35492\tvalid_1's l1: 0.397437\n",
      "[1800]\ttraining's l1: 0.349922\tvalid_1's l1: 0.394056\n",
      "[1900]\ttraining's l1: 0.345387\tvalid_1's l1: 0.390978\n",
      "[2000]\ttraining's l1: 0.340743\tvalid_1's l1: 0.387868\n",
      "[2100]\ttraining's l1: 0.336254\tvalid_1's l1: 0.38492\n",
      "[2200]\ttraining's l1: 0.332204\tvalid_1's l1: 0.38234\n",
      "[2300]\ttraining's l1: 0.328044\tvalid_1's l1: 0.379684\n",
      "[2400]\ttraining's l1: 0.324357\tvalid_1's l1: 0.37742\n",
      "[2500]\ttraining's l1: 0.321026\tvalid_1's l1: 0.375321\n",
      "[2600]\ttraining's l1: 0.317797\tvalid_1's l1: 0.373365\n",
      "[2700]\ttraining's l1: 0.314435\tvalid_1's l1: 0.371263\n",
      "[2800]\ttraining's l1: 0.311286\tvalid_1's l1: 0.369434\n",
      "[2900]\ttraining's l1: 0.30825\tvalid_1's l1: 0.367596\n",
      "[3000]\ttraining's l1: 0.305409\tvalid_1's l1: 0.366006\n",
      "[3100]\ttraining's l1: 0.302308\tvalid_1's l1: 0.364102\n",
      "[3200]\ttraining's l1: 0.299607\tvalid_1's l1: 0.36248\n",
      "[3300]\ttraining's l1: 0.296789\tvalid_1's l1: 0.360864\n",
      "[3400]\ttraining's l1: 0.29408\tvalid_1's l1: 0.35933\n",
      "[3500]\ttraining's l1: 0.291664\tvalid_1's l1: 0.35792\n",
      "[3600]\ttraining's l1: 0.289202\tvalid_1's l1: 0.356443\n",
      "[3700]\ttraining's l1: 0.286824\tvalid_1's l1: 0.35513\n",
      "[3800]\ttraining's l1: 0.284329\tvalid_1's l1: 0.353747\n",
      "[3900]\ttraining's l1: 0.282121\tvalid_1's l1: 0.352603\n",
      "[4000]\ttraining's l1: 0.279948\tvalid_1's l1: 0.351441\n",
      "[4100]\ttraining's l1: 0.277897\tvalid_1's l1: 0.350365\n",
      "[4200]\ttraining's l1: 0.275747\tvalid_1's l1: 0.349221\n",
      "[4300]\ttraining's l1: 0.273615\tvalid_1's l1: 0.348158\n",
      "[4400]\ttraining's l1: 0.27173\tvalid_1's l1: 0.347219\n",
      "[4500]\ttraining's l1: 0.269634\tvalid_1's l1: 0.346035\n",
      "[4600]\ttraining's l1: 0.267765\tvalid_1's l1: 0.345119\n",
      "[4700]\ttraining's l1: 0.265852\tvalid_1's l1: 0.344146\n",
      "[4800]\ttraining's l1: 0.264023\tvalid_1's l1: 0.343163\n",
      "[4900]\ttraining's l1: 0.262115\tvalid_1's l1: 0.342182\n",
      "[5000]\ttraining's l1: 0.260281\tvalid_1's l1: 0.34129\n",
      "[5100]\ttraining's l1: 0.258535\tvalid_1's l1: 0.340417\n",
      "[5200]\ttraining's l1: 0.25674\tvalid_1's l1: 0.339559\n",
      "[5300]\ttraining's l1: 0.25498\tvalid_1's l1: 0.338707\n",
      "[5400]\ttraining's l1: 0.253334\tvalid_1's l1: 0.337853\n",
      "[5500]\ttraining's l1: 0.251568\tvalid_1's l1: 0.337024\n",
      "[5600]\ttraining's l1: 0.249904\tvalid_1's l1: 0.336185\n",
      "[5700]\ttraining's l1: 0.248409\tvalid_1's l1: 0.33552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5800]\ttraining's l1: 0.246799\tvalid_1's l1: 0.334738\n",
      "[5900]\ttraining's l1: 0.245214\tvalid_1's l1: 0.333996\n",
      "[6000]\ttraining's l1: 0.243713\tvalid_1's l1: 0.333264\n",
      "[6100]\ttraining's l1: 0.242232\tvalid_1's l1: 0.33262\n",
      "[6200]\ttraining's l1: 0.240771\tvalid_1's l1: 0.331956\n",
      "[6300]\ttraining's l1: 0.239322\tvalid_1's l1: 0.33131\n",
      "[6400]\ttraining's l1: 0.237847\tvalid_1's l1: 0.330621\n",
      "[6500]\ttraining's l1: 0.236471\tvalid_1's l1: 0.330019\n",
      "[6600]\ttraining's l1: 0.235066\tvalid_1's l1: 0.329403\n",
      "[6700]\ttraining's l1: 0.233692\tvalid_1's l1: 0.32882\n",
      "[6800]\ttraining's l1: 0.232197\tvalid_1's l1: 0.328141\n",
      "[6900]\ttraining's l1: 0.230875\tvalid_1's l1: 0.327546\n",
      "[7000]\ttraining's l1: 0.229557\tvalid_1's l1: 0.326968\n",
      "[7100]\ttraining's l1: 0.228282\tvalid_1's l1: 0.326392\n",
      "[7200]\ttraining's l1: 0.227056\tvalid_1's l1: 0.325846\n",
      "[7300]\ttraining's l1: 0.225806\tvalid_1's l1: 0.32528\n",
      "[7400]\ttraining's l1: 0.224628\tvalid_1's l1: 0.324812\n",
      "[7500]\ttraining's l1: 0.22344\tvalid_1's l1: 0.324329\n",
      "[7600]\ttraining's l1: 0.222231\tvalid_1's l1: 0.323821\n",
      "[7700]\ttraining's l1: 0.221014\tvalid_1's l1: 0.323278\n",
      "[7800]\ttraining's l1: 0.219896\tvalid_1's l1: 0.322835\n",
      "[7900]\ttraining's l1: 0.218809\tvalid_1's l1: 0.322362\n",
      "[8000]\ttraining's l1: 0.217678\tvalid_1's l1: 0.321904\n",
      "[8100]\ttraining's l1: 0.216503\tvalid_1's l1: 0.321383\n",
      "[8200]\ttraining's l1: 0.215399\tvalid_1's l1: 0.32089\n",
      "[8300]\ttraining's l1: 0.214381\tvalid_1's l1: 0.320463\n",
      "[8400]\ttraining's l1: 0.213302\tvalid_1's l1: 0.320033\n",
      "[8500]\ttraining's l1: 0.212297\tvalid_1's l1: 0.319635\n",
      "[8600]\ttraining's l1: 0.211298\tvalid_1's l1: 0.319306\n",
      "[8700]\ttraining's l1: 0.210253\tvalid_1's l1: 0.318919\n",
      "[8800]\ttraining's l1: 0.209189\tvalid_1's l1: 0.318473\n",
      "[8900]\ttraining's l1: 0.208198\tvalid_1's l1: 0.318104\n",
      "[9000]\ttraining's l1: 0.20717\tvalid_1's l1: 0.317735\n",
      "[9100]\ttraining's l1: 0.206155\tvalid_1's l1: 0.317329\n",
      "[9200]\ttraining's l1: 0.205141\tvalid_1's l1: 0.316939\n",
      "[9300]\ttraining's l1: 0.204149\tvalid_1's l1: 0.316554\n",
      "[9400]\ttraining's l1: 0.20318\tvalid_1's l1: 0.316152\n",
      "[9500]\ttraining's l1: 0.202197\tvalid_1's l1: 0.315752\n",
      "[9600]\ttraining's l1: 0.201242\tvalid_1's l1: 0.315382\n",
      "[9700]\ttraining's l1: 0.200277\tvalid_1's l1: 0.315042\n",
      "[9800]\ttraining's l1: 0.199441\tvalid_1's l1: 0.314697\n",
      "[9900]\ttraining's l1: 0.198483\tvalid_1's l1: 0.314312\n",
      "[10000]\ttraining's l1: 0.197548\tvalid_1's l1: 0.313992\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.197548\tvalid_1's l1: 0.313992\n",
      "2JHC Fold 2, logMAE: -1.1583877956169295\n",
      "*** Training Model for 3JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.336462\tvalid_1's l1: 0.341386\n",
      "[200]\ttraining's l1: 0.288702\tvalid_1's l1: 0.297299\n",
      "[300]\ttraining's l1: 0.263631\tvalid_1's l1: 0.275505\n",
      "[400]\ttraining's l1: 0.247418\tvalid_1's l1: 0.26192\n",
      "[500]\ttraining's l1: 0.234816\tvalid_1's l1: 0.251602\n",
      "[600]\ttraining's l1: 0.224618\tvalid_1's l1: 0.243777\n",
      "[700]\ttraining's l1: 0.21623\tvalid_1's l1: 0.237549\n",
      "[800]\ttraining's l1: 0.209185\tvalid_1's l1: 0.232372\n",
      "[900]\ttraining's l1: 0.203184\tvalid_1's l1: 0.228044\n",
      "[1000]\ttraining's l1: 0.197466\tvalid_1's l1: 0.224111\n",
      "[1100]\ttraining's l1: 0.192569\tvalid_1's l1: 0.220727\n",
      "[1200]\ttraining's l1: 0.188013\tvalid_1's l1: 0.217656\n",
      "[1300]\ttraining's l1: 0.183951\tvalid_1's l1: 0.214937\n",
      "[1400]\ttraining's l1: 0.180096\tvalid_1's l1: 0.212533\n",
      "[1500]\ttraining's l1: 0.176604\tvalid_1's l1: 0.210322\n",
      "[1600]\ttraining's l1: 0.173279\tvalid_1's l1: 0.208267\n",
      "[1700]\ttraining's l1: 0.170178\tvalid_1's l1: 0.206397\n",
      "[1800]\ttraining's l1: 0.167326\tvalid_1's l1: 0.204736\n",
      "[1900]\ttraining's l1: 0.164589\tvalid_1's l1: 0.20311\n",
      "[2000]\ttraining's l1: 0.161993\tvalid_1's l1: 0.201651\n",
      "[2100]\ttraining's l1: 0.159564\tvalid_1's l1: 0.20018\n",
      "[2200]\ttraining's l1: 0.157142\tvalid_1's l1: 0.198825\n",
      "[2300]\ttraining's l1: 0.154838\tvalid_1's l1: 0.197577\n",
      "[2400]\ttraining's l1: 0.152611\tvalid_1's l1: 0.196365\n",
      "[2500]\ttraining's l1: 0.150594\tvalid_1's l1: 0.195364\n",
      "[2600]\ttraining's l1: 0.148641\tvalid_1's l1: 0.194251\n",
      "[2700]\ttraining's l1: 0.146678\tvalid_1's l1: 0.193206\n",
      "[2800]\ttraining's l1: 0.144812\tvalid_1's l1: 0.192233\n",
      "[2900]\ttraining's l1: 0.142985\tvalid_1's l1: 0.19122\n",
      "[3000]\ttraining's l1: 0.141229\tvalid_1's l1: 0.190328\n",
      "[3100]\ttraining's l1: 0.139523\tvalid_1's l1: 0.189432\n",
      "[3200]\ttraining's l1: 0.137849\tvalid_1's l1: 0.18866\n",
      "[3300]\ttraining's l1: 0.136273\tvalid_1's l1: 0.187889\n",
      "[3400]\ttraining's l1: 0.134769\tvalid_1's l1: 0.18718\n",
      "[3500]\ttraining's l1: 0.133271\tvalid_1's l1: 0.186464\n",
      "[3600]\ttraining's l1: 0.131927\tvalid_1's l1: 0.185834\n",
      "[3700]\ttraining's l1: 0.130553\tvalid_1's l1: 0.185202\n",
      "[3800]\ttraining's l1: 0.12916\tvalid_1's l1: 0.184559\n",
      "[3900]\ttraining's l1: 0.127833\tvalid_1's l1: 0.184001\n",
      "[4000]\ttraining's l1: 0.126557\tvalid_1's l1: 0.183415\n",
      "[4100]\ttraining's l1: 0.125257\tvalid_1's l1: 0.182788\n",
      "[4200]\ttraining's l1: 0.124066\tvalid_1's l1: 0.182295\n",
      "[4300]\ttraining's l1: 0.122846\tvalid_1's l1: 0.181754\n",
      "[4400]\ttraining's l1: 0.121661\tvalid_1's l1: 0.181194\n",
      "[4500]\ttraining's l1: 0.120583\tvalid_1's l1: 0.180695\n",
      "[4600]\ttraining's l1: 0.119494\tvalid_1's l1: 0.180278\n",
      "[4700]\ttraining's l1: 0.118396\tvalid_1's l1: 0.17977\n",
      "[4800]\ttraining's l1: 0.117307\tvalid_1's l1: 0.179287\n",
      "[4900]\ttraining's l1: 0.116294\tvalid_1's l1: 0.178856\n",
      "[5000]\ttraining's l1: 0.11529\tvalid_1's l1: 0.17845\n",
      "[5100]\ttraining's l1: 0.114324\tvalid_1's l1: 0.178092\n",
      "[5200]\ttraining's l1: 0.113329\tvalid_1's l1: 0.177692\n",
      "[5300]\ttraining's l1: 0.112358\tvalid_1's l1: 0.177276\n",
      "[5400]\ttraining's l1: 0.111444\tvalid_1's l1: 0.17693\n",
      "[5500]\ttraining's l1: 0.110489\tvalid_1's l1: 0.176582\n",
      "[5600]\ttraining's l1: 0.109624\tvalid_1's l1: 0.176264\n",
      "[5700]\ttraining's l1: 0.108747\tvalid_1's l1: 0.175936\n",
      "[5800]\ttraining's l1: 0.107823\tvalid_1's l1: 0.175588\n",
      "[5900]\ttraining's l1: 0.10701\tvalid_1's l1: 0.175312\n",
      "[6000]\ttraining's l1: 0.10616\tvalid_1's l1: 0.174976\n",
      "[6100]\ttraining's l1: 0.105347\tvalid_1's l1: 0.174705\n",
      "[6200]\ttraining's l1: 0.104514\tvalid_1's l1: 0.174407\n",
      "[6300]\ttraining's l1: 0.103754\tvalid_1's l1: 0.174112\n",
      "[6400]\ttraining's l1: 0.102935\tvalid_1's l1: 0.173791\n",
      "[6500]\ttraining's l1: 0.102157\tvalid_1's l1: 0.173498\n",
      "[6600]\ttraining's l1: 0.101397\tvalid_1's l1: 0.17321\n",
      "[6700]\ttraining's l1: 0.100626\tvalid_1's l1: 0.172966\n",
      "[6800]\ttraining's l1: 0.0998824\tvalid_1's l1: 0.172723\n",
      "[6900]\ttraining's l1: 0.0991692\tvalid_1's l1: 0.172474\n",
      "[7000]\ttraining's l1: 0.0984401\tvalid_1's l1: 0.172228\n",
      "[7100]\ttraining's l1: 0.0977377\tvalid_1's l1: 0.171967\n",
      "[7200]\ttraining's l1: 0.0970497\tvalid_1's l1: 0.171734\n",
      "[7300]\ttraining's l1: 0.0963557\tvalid_1's l1: 0.171503\n",
      "[7400]\ttraining's l1: 0.0956501\tvalid_1's l1: 0.171252\n",
      "[7500]\ttraining's l1: 0.0950062\tvalid_1's l1: 0.170987\n",
      "[7600]\ttraining's l1: 0.0943512\tvalid_1's l1: 0.17076\n",
      "[7700]\ttraining's l1: 0.0937144\tvalid_1's l1: 0.170555\n",
      "[7800]\ttraining's l1: 0.0930825\tvalid_1's l1: 0.170358\n",
      "[7900]\ttraining's l1: 0.0924645\tvalid_1's l1: 0.170149\n",
      "[8000]\ttraining's l1: 0.0918448\tvalid_1's l1: 0.169932\n",
      "[8100]\ttraining's l1: 0.0912389\tvalid_1's l1: 0.169724\n",
      "[8200]\ttraining's l1: 0.0906337\tvalid_1's l1: 0.169534\n",
      "[8300]\ttraining's l1: 0.0900511\tvalid_1's l1: 0.16933\n",
      "[8400]\ttraining's l1: 0.0894532\tvalid_1's l1: 0.169122\n",
      "[8500]\ttraining's l1: 0.088867\tvalid_1's l1: 0.168941\n",
      "[8600]\ttraining's l1: 0.0882852\tvalid_1's l1: 0.168732\n",
      "[8700]\ttraining's l1: 0.0877093\tvalid_1's l1: 0.168544\n",
      "[8800]\ttraining's l1: 0.0871461\tvalid_1's l1: 0.168357\n",
      "[8900]\ttraining's l1: 0.0866077\tvalid_1's l1: 0.168173\n",
      "[9000]\ttraining's l1: 0.0860642\tvalid_1's l1: 0.168007\n",
      "[9100]\ttraining's l1: 0.0855046\tvalid_1's l1: 0.167828\n",
      "[9200]\ttraining's l1: 0.0849669\tvalid_1's l1: 0.16766\n",
      "[9300]\ttraining's l1: 0.0844797\tvalid_1's l1: 0.167487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9400]\ttraining's l1: 0.0839556\tvalid_1's l1: 0.167312\n",
      "[9500]\ttraining's l1: 0.083435\tvalid_1's l1: 0.167149\n",
      "[9600]\ttraining's l1: 0.0829281\tvalid_1's l1: 0.166991\n",
      "[9700]\ttraining's l1: 0.082426\tvalid_1's l1: 0.166809\n",
      "[9800]\ttraining's l1: 0.0819485\tvalid_1's l1: 0.166677\n",
      "[9900]\ttraining's l1: 0.0814624\tvalid_1's l1: 0.16653\n",
      "[10000]\ttraining's l1: 0.0809787\tvalid_1's l1: 0.166386\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0809787\tvalid_1's l1: 0.166386\n",
      "3JHH Fold 0, logMAE: -1.7934435288143422\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.337322\tvalid_1's l1: 0.343486\n",
      "[200]\ttraining's l1: 0.289222\tvalid_1's l1: 0.298822\n",
      "[300]\ttraining's l1: 0.263837\tvalid_1's l1: 0.276564\n",
      "[400]\ttraining's l1: 0.247139\tvalid_1's l1: 0.262594\n",
      "[500]\ttraining's l1: 0.234329\tvalid_1's l1: 0.251984\n",
      "[600]\ttraining's l1: 0.224212\tvalid_1's l1: 0.244113\n",
      "[700]\ttraining's l1: 0.216016\tvalid_1's l1: 0.238087\n",
      "[800]\ttraining's l1: 0.20917\tvalid_1's l1: 0.233048\n",
      "[900]\ttraining's l1: 0.203215\tvalid_1's l1: 0.228541\n",
      "[1000]\ttraining's l1: 0.197645\tvalid_1's l1: 0.224671\n",
      "[1100]\ttraining's l1: 0.192917\tvalid_1's l1: 0.221504\n",
      "[1200]\ttraining's l1: 0.188475\tvalid_1's l1: 0.21855\n",
      "[1300]\ttraining's l1: 0.184276\tvalid_1's l1: 0.215837\n",
      "[1400]\ttraining's l1: 0.180169\tvalid_1's l1: 0.213204\n",
      "[1500]\ttraining's l1: 0.176558\tvalid_1's l1: 0.210835\n",
      "[1600]\ttraining's l1: 0.173187\tvalid_1's l1: 0.208717\n",
      "[1700]\ttraining's l1: 0.169913\tvalid_1's l1: 0.206726\n",
      "[1800]\ttraining's l1: 0.167068\tvalid_1's l1: 0.205057\n",
      "[1900]\ttraining's l1: 0.164367\tvalid_1's l1: 0.203463\n",
      "[2000]\ttraining's l1: 0.161715\tvalid_1's l1: 0.201965\n",
      "[2100]\ttraining's l1: 0.159146\tvalid_1's l1: 0.200394\n",
      "[2200]\ttraining's l1: 0.156687\tvalid_1's l1: 0.198919\n",
      "[2300]\ttraining's l1: 0.154315\tvalid_1's l1: 0.197518\n",
      "[2400]\ttraining's l1: 0.152235\tvalid_1's l1: 0.196412\n",
      "[2500]\ttraining's l1: 0.150182\tvalid_1's l1: 0.195351\n",
      "[2600]\ttraining's l1: 0.148225\tvalid_1's l1: 0.194353\n",
      "[2700]\ttraining's l1: 0.146271\tvalid_1's l1: 0.19326\n",
      "[2800]\ttraining's l1: 0.144423\tvalid_1's l1: 0.192361\n",
      "[2900]\ttraining's l1: 0.142607\tvalid_1's l1: 0.191437\n",
      "[3000]\ttraining's l1: 0.140989\tvalid_1's l1: 0.190594\n",
      "[3100]\ttraining's l1: 0.139378\tvalid_1's l1: 0.189803\n",
      "[3200]\ttraining's l1: 0.137692\tvalid_1's l1: 0.188985\n",
      "[3300]\ttraining's l1: 0.136136\tvalid_1's l1: 0.188168\n",
      "[3400]\ttraining's l1: 0.134585\tvalid_1's l1: 0.187402\n",
      "[3500]\ttraining's l1: 0.133116\tvalid_1's l1: 0.186772\n",
      "[3600]\ttraining's l1: 0.131647\tvalid_1's l1: 0.186093\n",
      "[3700]\ttraining's l1: 0.130308\tvalid_1's l1: 0.185446\n",
      "[3800]\ttraining's l1: 0.128895\tvalid_1's l1: 0.184756\n",
      "[3900]\ttraining's l1: 0.127512\tvalid_1's l1: 0.184099\n",
      "[4000]\ttraining's l1: 0.126215\tvalid_1's l1: 0.183496\n",
      "[4100]\ttraining's l1: 0.124988\tvalid_1's l1: 0.182949\n",
      "[4200]\ttraining's l1: 0.123787\tvalid_1's l1: 0.182403\n",
      "[4300]\ttraining's l1: 0.12265\tvalid_1's l1: 0.181986\n",
      "[4400]\ttraining's l1: 0.121476\tvalid_1's l1: 0.181412\n",
      "[4500]\ttraining's l1: 0.120355\tvalid_1's l1: 0.180963\n",
      "[4600]\ttraining's l1: 0.119264\tvalid_1's l1: 0.1805\n",
      "[4700]\ttraining's l1: 0.118164\tvalid_1's l1: 0.180003\n",
      "[4800]\ttraining's l1: 0.117146\tvalid_1's l1: 0.179588\n",
      "[4900]\ttraining's l1: 0.116091\tvalid_1's l1: 0.17917\n",
      "[5000]\ttraining's l1: 0.115063\tvalid_1's l1: 0.178758\n",
      "[5100]\ttraining's l1: 0.114069\tvalid_1's l1: 0.178312\n",
      "[5200]\ttraining's l1: 0.11311\tvalid_1's l1: 0.177916\n",
      "[5300]\ttraining's l1: 0.112201\tvalid_1's l1: 0.177549\n",
      "[5400]\ttraining's l1: 0.111273\tvalid_1's l1: 0.177218\n",
      "[5500]\ttraining's l1: 0.110328\tvalid_1's l1: 0.176867\n",
      "[5600]\ttraining's l1: 0.109461\tvalid_1's l1: 0.176531\n",
      "[5700]\ttraining's l1: 0.108551\tvalid_1's l1: 0.176142\n",
      "[5800]\ttraining's l1: 0.107651\tvalid_1's l1: 0.175753\n",
      "[5900]\ttraining's l1: 0.106763\tvalid_1's l1: 0.175409\n",
      "[6000]\ttraining's l1: 0.105954\tvalid_1's l1: 0.17509\n",
      "[6100]\ttraining's l1: 0.105131\tvalid_1's l1: 0.174795\n",
      "[6200]\ttraining's l1: 0.104325\tvalid_1's l1: 0.174482\n",
      "[6300]\ttraining's l1: 0.10353\tvalid_1's l1: 0.174216\n",
      "[6400]\ttraining's l1: 0.102743\tvalid_1's l1: 0.173923\n",
      "[6500]\ttraining's l1: 0.101979\tvalid_1's l1: 0.173626\n",
      "[6600]\ttraining's l1: 0.10124\tvalid_1's l1: 0.173374\n",
      "[6700]\ttraining's l1: 0.100496\tvalid_1's l1: 0.173079\n",
      "[6800]\ttraining's l1: 0.0997586\tvalid_1's l1: 0.172812\n",
      "[6900]\ttraining's l1: 0.0990415\tvalid_1's l1: 0.17254\n",
      "[7000]\ttraining's l1: 0.0983307\tvalid_1's l1: 0.172312\n",
      "[7100]\ttraining's l1: 0.0976218\tvalid_1's l1: 0.17205\n",
      "[7200]\ttraining's l1: 0.0969442\tvalid_1's l1: 0.171828\n",
      "[7300]\ttraining's l1: 0.096258\tvalid_1's l1: 0.171591\n",
      "[7400]\ttraining's l1: 0.0955816\tvalid_1's l1: 0.171354\n",
      "[7500]\ttraining's l1: 0.0949205\tvalid_1's l1: 0.171095\n",
      "[7600]\ttraining's l1: 0.0942522\tvalid_1's l1: 0.170869\n",
      "[7700]\ttraining's l1: 0.0936525\tvalid_1's l1: 0.170662\n",
      "[7800]\ttraining's l1: 0.0929873\tvalid_1's l1: 0.170445\n",
      "[7900]\ttraining's l1: 0.0923644\tvalid_1's l1: 0.170201\n",
      "[8000]\ttraining's l1: 0.0917416\tvalid_1's l1: 0.169997\n",
      "[8100]\ttraining's l1: 0.091129\tvalid_1's l1: 0.169801\n",
      "[8200]\ttraining's l1: 0.090509\tvalid_1's l1: 0.169592\n",
      "[8300]\ttraining's l1: 0.0898977\tvalid_1's l1: 0.169383\n",
      "[8400]\ttraining's l1: 0.08934\tvalid_1's l1: 0.169193\n",
      "[8500]\ttraining's l1: 0.0887554\tvalid_1's l1: 0.168988\n",
      "[8600]\ttraining's l1: 0.088197\tvalid_1's l1: 0.168815\n",
      "[8700]\ttraining's l1: 0.0876397\tvalid_1's l1: 0.16864\n",
      "[8800]\ttraining's l1: 0.0870706\tvalid_1's l1: 0.168468\n",
      "[8900]\ttraining's l1: 0.0865239\tvalid_1's l1: 0.168287\n",
      "[9000]\ttraining's l1: 0.0859933\tvalid_1's l1: 0.168114\n",
      "[9100]\ttraining's l1: 0.0854614\tvalid_1's l1: 0.167921\n",
      "[9200]\ttraining's l1: 0.0849199\tvalid_1's l1: 0.167732\n",
      "[9300]\ttraining's l1: 0.0844137\tvalid_1's l1: 0.167549\n",
      "[9400]\ttraining's l1: 0.0839087\tvalid_1's l1: 0.167402\n",
      "[9500]\ttraining's l1: 0.0833849\tvalid_1's l1: 0.167268\n",
      "[9600]\ttraining's l1: 0.0828832\tvalid_1's l1: 0.167109\n",
      "[9700]\ttraining's l1: 0.0823694\tvalid_1's l1: 0.166961\n",
      "[9800]\ttraining's l1: 0.0818823\tvalid_1's l1: 0.166798\n",
      "[9900]\ttraining's l1: 0.0813929\tvalid_1's l1: 0.166637\n",
      "[10000]\ttraining's l1: 0.0808988\tvalid_1's l1: 0.166469\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0808988\tvalid_1's l1: 0.166469\n",
      "3JHH Fold 1, logMAE: -1.7929470967194392\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.339858\tvalid_1's l1: 0.346156\n",
      "[200]\ttraining's l1: 0.291962\tvalid_1's l1: 0.301674\n",
      "[300]\ttraining's l1: 0.266108\tvalid_1's l1: 0.278776\n",
      "[400]\ttraining's l1: 0.248615\tvalid_1's l1: 0.263845\n",
      "[500]\ttraining's l1: 0.236114\tvalid_1's l1: 0.253677\n",
      "[600]\ttraining's l1: 0.226006\tvalid_1's l1: 0.245865\n",
      "[700]\ttraining's l1: 0.217496\tvalid_1's l1: 0.239301\n",
      "[800]\ttraining's l1: 0.210015\tvalid_1's l1: 0.233658\n",
      "[900]\ttraining's l1: 0.203739\tvalid_1's l1: 0.229154\n",
      "[1000]\ttraining's l1: 0.198415\tvalid_1's l1: 0.225431\n",
      "[1100]\ttraining's l1: 0.193272\tvalid_1's l1: 0.221664\n",
      "[1200]\ttraining's l1: 0.18873\tvalid_1's l1: 0.218587\n",
      "[1300]\ttraining's l1: 0.184545\tvalid_1's l1: 0.215729\n",
      "[1400]\ttraining's l1: 0.180783\tvalid_1's l1: 0.21326\n",
      "[1500]\ttraining's l1: 0.177263\tvalid_1's l1: 0.210955\n",
      "[1600]\ttraining's l1: 0.173979\tvalid_1's l1: 0.20893\n",
      "[1700]\ttraining's l1: 0.1709\tvalid_1's l1: 0.207007\n",
      "[1800]\ttraining's l1: 0.167885\tvalid_1's l1: 0.205111\n",
      "[1900]\ttraining's l1: 0.165112\tvalid_1's l1: 0.203365\n",
      "[2000]\ttraining's l1: 0.162428\tvalid_1's l1: 0.201677\n",
      "[2100]\ttraining's l1: 0.159912\tvalid_1's l1: 0.200297\n",
      "[2200]\ttraining's l1: 0.157603\tvalid_1's l1: 0.198933\n",
      "[2300]\ttraining's l1: 0.15542\tvalid_1's l1: 0.197756\n",
      "[2400]\ttraining's l1: 0.153163\tvalid_1's l1: 0.196498\n",
      "[2500]\ttraining's l1: 0.151093\tvalid_1's l1: 0.19531\n",
      "[2600]\ttraining's l1: 0.149034\tvalid_1's l1: 0.194245\n",
      "[2700]\ttraining's l1: 0.147006\tvalid_1's l1: 0.193133\n",
      "[2800]\ttraining's l1: 0.14509\tvalid_1's l1: 0.192055\n",
      "[2900]\ttraining's l1: 0.143316\tvalid_1's l1: 0.191201\n",
      "[3000]\ttraining's l1: 0.141585\tvalid_1's l1: 0.190302\n",
      "[3100]\ttraining's l1: 0.139933\tvalid_1's l1: 0.189413\n",
      "[3200]\ttraining's l1: 0.138331\tvalid_1's l1: 0.188669\n",
      "[3300]\ttraining's l1: 0.136801\tvalid_1's l1: 0.187895\n",
      "[3400]\ttraining's l1: 0.13532\tvalid_1's l1: 0.187266\n",
      "[3500]\ttraining's l1: 0.133861\tvalid_1's l1: 0.18652\n",
      "[3600]\ttraining's l1: 0.132364\tvalid_1's l1: 0.185797\n",
      "[3700]\ttraining's l1: 0.13108\tvalid_1's l1: 0.185193\n",
      "[3800]\ttraining's l1: 0.129683\tvalid_1's l1: 0.184529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3900]\ttraining's l1: 0.128276\tvalid_1's l1: 0.183864\n",
      "[4000]\ttraining's l1: 0.12692\tvalid_1's l1: 0.183247\n",
      "[4100]\ttraining's l1: 0.125659\tvalid_1's l1: 0.182667\n",
      "[4200]\ttraining's l1: 0.12443\tvalid_1's l1: 0.182097\n",
      "[4300]\ttraining's l1: 0.123209\tvalid_1's l1: 0.181555\n",
      "[4400]\ttraining's l1: 0.122058\tvalid_1's l1: 0.181006\n",
      "[4500]\ttraining's l1: 0.120914\tvalid_1's l1: 0.180539\n",
      "[4600]\ttraining's l1: 0.11977\tvalid_1's l1: 0.18005\n",
      "[4700]\ttraining's l1: 0.118684\tvalid_1's l1: 0.179564\n",
      "[4800]\ttraining's l1: 0.117636\tvalid_1's l1: 0.179117\n",
      "[4900]\ttraining's l1: 0.116593\tvalid_1's l1: 0.17869\n",
      "[5000]\ttraining's l1: 0.115576\tvalid_1's l1: 0.178265\n",
      "[5100]\ttraining's l1: 0.114555\tvalid_1's l1: 0.177848\n",
      "[5200]\ttraining's l1: 0.113565\tvalid_1's l1: 0.177424\n",
      "[5300]\ttraining's l1: 0.112622\tvalid_1's l1: 0.177034\n",
      "[5400]\ttraining's l1: 0.111619\tvalid_1's l1: 0.176666\n",
      "[5500]\ttraining's l1: 0.110634\tvalid_1's l1: 0.176293\n",
      "[5600]\ttraining's l1: 0.10973\tvalid_1's l1: 0.175927\n",
      "[5700]\ttraining's l1: 0.108846\tvalid_1's l1: 0.175611\n",
      "[5800]\ttraining's l1: 0.107962\tvalid_1's l1: 0.175265\n",
      "[5900]\ttraining's l1: 0.107097\tvalid_1's l1: 0.174899\n",
      "[6000]\ttraining's l1: 0.106248\tvalid_1's l1: 0.174563\n",
      "[6100]\ttraining's l1: 0.105441\tvalid_1's l1: 0.174255\n",
      "[6200]\ttraining's l1: 0.104615\tvalid_1's l1: 0.173953\n",
      "[6300]\ttraining's l1: 0.103825\tvalid_1's l1: 0.173636\n",
      "[6400]\ttraining's l1: 0.103027\tvalid_1's l1: 0.173306\n",
      "[6500]\ttraining's l1: 0.102307\tvalid_1's l1: 0.173051\n",
      "[6600]\ttraining's l1: 0.101561\tvalid_1's l1: 0.17274\n",
      "[6700]\ttraining's l1: 0.100828\tvalid_1's l1: 0.172467\n",
      "[6800]\ttraining's l1: 0.10009\tvalid_1's l1: 0.172165\n",
      "[6900]\ttraining's l1: 0.0993597\tvalid_1's l1: 0.171903\n",
      "[7000]\ttraining's l1: 0.0986572\tvalid_1's l1: 0.171645\n",
      "[7100]\ttraining's l1: 0.0979436\tvalid_1's l1: 0.1713\n",
      "[7200]\ttraining's l1: 0.0972181\tvalid_1's l1: 0.171067\n",
      "[7300]\ttraining's l1: 0.096522\tvalid_1's l1: 0.170807\n",
      "[7400]\ttraining's l1: 0.0958492\tvalid_1's l1: 0.170568\n",
      "[7500]\ttraining's l1: 0.0951703\tvalid_1's l1: 0.170279\n",
      "[7600]\ttraining's l1: 0.094475\tvalid_1's l1: 0.170041\n",
      "[7700]\ttraining's l1: 0.0938111\tvalid_1's l1: 0.169842\n",
      "[7800]\ttraining's l1: 0.0931769\tvalid_1's l1: 0.169613\n",
      "[7900]\ttraining's l1: 0.0925073\tvalid_1's l1: 0.169399\n",
      "[8000]\ttraining's l1: 0.0919016\tvalid_1's l1: 0.169201\n",
      "[8100]\ttraining's l1: 0.0913022\tvalid_1's l1: 0.169007\n",
      "[8200]\ttraining's l1: 0.0907093\tvalid_1's l1: 0.168819\n",
      "[8300]\ttraining's l1: 0.0901259\tvalid_1's l1: 0.168584\n",
      "[8400]\ttraining's l1: 0.0895415\tvalid_1's l1: 0.168422\n",
      "[8500]\ttraining's l1: 0.0889337\tvalid_1's l1: 0.168207\n",
      "[8600]\ttraining's l1: 0.0883531\tvalid_1's l1: 0.168035\n",
      "[8700]\ttraining's l1: 0.0878002\tvalid_1's l1: 0.167888\n",
      "[8800]\ttraining's l1: 0.0872409\tvalid_1's l1: 0.167729\n",
      "[8900]\ttraining's l1: 0.0866729\tvalid_1's l1: 0.16756\n",
      "[9000]\ttraining's l1: 0.0861544\tvalid_1's l1: 0.167371\n",
      "[9100]\ttraining's l1: 0.0856238\tvalid_1's l1: 0.167199\n",
      "[9200]\ttraining's l1: 0.0850679\tvalid_1's l1: 0.167033\n",
      "[9300]\ttraining's l1: 0.0845174\tvalid_1's l1: 0.166866\n",
      "[9400]\ttraining's l1: 0.0839975\tvalid_1's l1: 0.166705\n",
      "[9500]\ttraining's l1: 0.0834756\tvalid_1's l1: 0.166562\n",
      "[9600]\ttraining's l1: 0.082952\tvalid_1's l1: 0.16641\n",
      "[9700]\ttraining's l1: 0.0824607\tvalid_1's l1: 0.166241\n",
      "[9800]\ttraining's l1: 0.0819812\tvalid_1's l1: 0.166125\n",
      "[9900]\ttraining's l1: 0.0814906\tvalid_1's l1: 0.165965\n",
      "[10000]\ttraining's l1: 0.081014\tvalid_1's l1: 0.165805\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.081014\tvalid_1's l1: 0.165805\n",
      "3JHH Fold 2, logMAE: -1.7969410214807653\n",
      "*** Training Model for 3JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.683675\tvalid_1's l1: 0.688233\n",
      "[200]\ttraining's l1: 0.59934\tvalid_1's l1: 0.60746\n",
      "[300]\ttraining's l1: 0.553402\tvalid_1's l1: 0.56459\n",
      "[400]\ttraining's l1: 0.523478\tvalid_1's l1: 0.537243\n",
      "[500]\ttraining's l1: 0.501923\tvalid_1's l1: 0.518168\n",
      "[600]\ttraining's l1: 0.485304\tvalid_1's l1: 0.503772\n",
      "[700]\ttraining's l1: 0.470668\tvalid_1's l1: 0.491334\n",
      "[800]\ttraining's l1: 0.457903\tvalid_1's l1: 0.480602\n",
      "[900]\ttraining's l1: 0.446803\tvalid_1's l1: 0.47144\n",
      "[1000]\ttraining's l1: 0.437412\tvalid_1's l1: 0.463987\n",
      "[1100]\ttraining's l1: 0.428728\tvalid_1's l1: 0.45691\n",
      "[1200]\ttraining's l1: 0.420843\tvalid_1's l1: 0.450685\n",
      "[1300]\ttraining's l1: 0.413603\tvalid_1's l1: 0.44524\n",
      "[1400]\ttraining's l1: 0.407364\tvalid_1's l1: 0.440667\n",
      "[1500]\ttraining's l1: 0.40138\tvalid_1's l1: 0.436078\n",
      "[1600]\ttraining's l1: 0.395604\tvalid_1's l1: 0.431628\n",
      "[1700]\ttraining's l1: 0.390454\tvalid_1's l1: 0.427962\n",
      "[1800]\ttraining's l1: 0.385683\tvalid_1's l1: 0.424762\n",
      "[1900]\ttraining's l1: 0.380838\tvalid_1's l1: 0.421307\n",
      "[2000]\ttraining's l1: 0.376489\tvalid_1's l1: 0.418171\n",
      "[2100]\ttraining's l1: 0.37213\tvalid_1's l1: 0.415259\n",
      "[2200]\ttraining's l1: 0.368126\tvalid_1's l1: 0.412474\n",
      "[2300]\ttraining's l1: 0.364169\tvalid_1's l1: 0.409853\n",
      "[2400]\ttraining's l1: 0.360668\tvalid_1's l1: 0.407574\n",
      "[2500]\ttraining's l1: 0.357161\tvalid_1's l1: 0.405272\n",
      "[2600]\ttraining's l1: 0.353763\tvalid_1's l1: 0.402993\n",
      "[2700]\ttraining's l1: 0.350567\tvalid_1's l1: 0.400969\n",
      "[2800]\ttraining's l1: 0.347385\tvalid_1's l1: 0.399097\n",
      "[2900]\ttraining's l1: 0.344292\tvalid_1's l1: 0.397194\n",
      "[3000]\ttraining's l1: 0.341356\tvalid_1's l1: 0.395336\n",
      "[3100]\ttraining's l1: 0.338328\tvalid_1's l1: 0.39356\n",
      "[3200]\ttraining's l1: 0.335642\tvalid_1's l1: 0.391892\n",
      "[3300]\ttraining's l1: 0.332885\tvalid_1's l1: 0.390337\n",
      "[3400]\ttraining's l1: 0.330323\tvalid_1's l1: 0.388843\n",
      "[3500]\ttraining's l1: 0.327868\tvalid_1's l1: 0.387478\n",
      "[3600]\ttraining's l1: 0.325316\tvalid_1's l1: 0.385904\n",
      "[3700]\ttraining's l1: 0.322912\tvalid_1's l1: 0.384523\n",
      "[3800]\ttraining's l1: 0.320485\tvalid_1's l1: 0.383102\n",
      "[3900]\ttraining's l1: 0.318144\tvalid_1's l1: 0.381819\n",
      "[4000]\ttraining's l1: 0.315838\tvalid_1's l1: 0.380526\n",
      "[4100]\ttraining's l1: 0.313643\tvalid_1's l1: 0.379345\n",
      "[4200]\ttraining's l1: 0.311531\tvalid_1's l1: 0.378207\n",
      "[4300]\ttraining's l1: 0.309425\tvalid_1's l1: 0.377098\n",
      "[4400]\ttraining's l1: 0.307386\tvalid_1's l1: 0.375988\n",
      "[4500]\ttraining's l1: 0.305349\tvalid_1's l1: 0.374996\n",
      "[4600]\ttraining's l1: 0.303299\tvalid_1's l1: 0.373916\n",
      "[4700]\ttraining's l1: 0.301394\tvalid_1's l1: 0.372917\n",
      "[4800]\ttraining's l1: 0.299507\tvalid_1's l1: 0.371991\n",
      "[4900]\ttraining's l1: 0.297634\tvalid_1's l1: 0.370992\n",
      "[5000]\ttraining's l1: 0.295806\tvalid_1's l1: 0.37008\n",
      "[5100]\ttraining's l1: 0.293959\tvalid_1's l1: 0.369152\n",
      "[5200]\ttraining's l1: 0.292196\tvalid_1's l1: 0.368316\n",
      "[5300]\ttraining's l1: 0.290525\tvalid_1's l1: 0.367528\n",
      "[5400]\ttraining's l1: 0.288791\tvalid_1's l1: 0.366643\n",
      "[5500]\ttraining's l1: 0.287137\tvalid_1's l1: 0.365817\n",
      "[5600]\ttraining's l1: 0.285484\tvalid_1's l1: 0.365054\n",
      "[5700]\ttraining's l1: 0.283904\tvalid_1's l1: 0.364297\n",
      "[5800]\ttraining's l1: 0.282248\tvalid_1's l1: 0.363518\n",
      "[5900]\ttraining's l1: 0.280615\tvalid_1's l1: 0.362752\n",
      "[6000]\ttraining's l1: 0.279034\tvalid_1's l1: 0.362011\n",
      "[6100]\ttraining's l1: 0.277443\tvalid_1's l1: 0.361265\n",
      "[6200]\ttraining's l1: 0.27593\tvalid_1's l1: 0.36052\n",
      "[6300]\ttraining's l1: 0.27448\tvalid_1's l1: 0.359833\n",
      "[6400]\ttraining's l1: 0.27297\tvalid_1's l1: 0.359127\n",
      "[6500]\ttraining's l1: 0.271518\tvalid_1's l1: 0.358488\n",
      "[6600]\ttraining's l1: 0.270137\tvalid_1's l1: 0.357918\n",
      "[6700]\ttraining's l1: 0.268758\tvalid_1's l1: 0.357288\n",
      "[6800]\ttraining's l1: 0.267378\tvalid_1's l1: 0.356643\n",
      "[6900]\ttraining's l1: 0.265947\tvalid_1's l1: 0.356028\n",
      "[7000]\ttraining's l1: 0.264618\tvalid_1's l1: 0.355444\n",
      "[7100]\ttraining's l1: 0.263365\tvalid_1's l1: 0.354907\n",
      "[7200]\ttraining's l1: 0.262049\tvalid_1's l1: 0.354289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7300]\ttraining's l1: 0.260766\tvalid_1's l1: 0.353741\n",
      "[7400]\ttraining's l1: 0.2595\tvalid_1's l1: 0.353187\n",
      "[7500]\ttraining's l1: 0.25824\tvalid_1's l1: 0.35267\n",
      "[7600]\ttraining's l1: 0.257038\tvalid_1's l1: 0.35216\n",
      "[7700]\ttraining's l1: 0.255846\tvalid_1's l1: 0.351643\n",
      "[7800]\ttraining's l1: 0.254618\tvalid_1's l1: 0.351082\n",
      "[7900]\ttraining's l1: 0.253382\tvalid_1's l1: 0.350564\n",
      "[8000]\ttraining's l1: 0.252229\tvalid_1's l1: 0.350067\n",
      "[8100]\ttraining's l1: 0.251039\tvalid_1's l1: 0.349551\n",
      "[8200]\ttraining's l1: 0.249888\tvalid_1's l1: 0.349035\n",
      "[8300]\ttraining's l1: 0.248706\tvalid_1's l1: 0.348537\n",
      "[8400]\ttraining's l1: 0.247564\tvalid_1's l1: 0.348058\n",
      "[8500]\ttraining's l1: 0.246409\tvalid_1's l1: 0.347605\n",
      "[8600]\ttraining's l1: 0.245303\tvalid_1's l1: 0.347173\n",
      "[8700]\ttraining's l1: 0.244202\tvalid_1's l1: 0.346754\n",
      "[8800]\ttraining's l1: 0.243102\tvalid_1's l1: 0.34631\n",
      "[8900]\ttraining's l1: 0.242037\tvalid_1's l1: 0.345894\n",
      "[9000]\ttraining's l1: 0.240953\tvalid_1's l1: 0.345492\n",
      "[9100]\ttraining's l1: 0.23987\tvalid_1's l1: 0.34505\n",
      "[9200]\ttraining's l1: 0.238824\tvalid_1's l1: 0.34469\n",
      "[9300]\ttraining's l1: 0.237828\tvalid_1's l1: 0.344303\n",
      "[9400]\ttraining's l1: 0.236775\tvalid_1's l1: 0.343911\n",
      "[9500]\ttraining's l1: 0.235785\tvalid_1's l1: 0.343522\n",
      "[9600]\ttraining's l1: 0.234803\tvalid_1's l1: 0.343157\n",
      "[9700]\ttraining's l1: 0.233812\tvalid_1's l1: 0.342805\n",
      "[9800]\ttraining's l1: 0.232851\tvalid_1's l1: 0.342463\n",
      "[9900]\ttraining's l1: 0.231876\tvalid_1's l1: 0.342068\n",
      "[10000]\ttraining's l1: 0.230947\tvalid_1's l1: 0.341762\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.230947\tvalid_1's l1: 0.341762\n",
      "3JHC Fold 0, logMAE: -1.073639589398193\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.684418\tvalid_1's l1: 0.690593\n",
      "[200]\ttraining's l1: 0.596002\tvalid_1's l1: 0.605759\n",
      "[300]\ttraining's l1: 0.55269\tvalid_1's l1: 0.565103\n",
      "[400]\ttraining's l1: 0.524122\tvalid_1's l1: 0.539104\n",
      "[500]\ttraining's l1: 0.501067\tvalid_1's l1: 0.518537\n",
      "[600]\ttraining's l1: 0.483758\tvalid_1's l1: 0.503432\n",
      "[700]\ttraining's l1: 0.469\tvalid_1's l1: 0.490474\n",
      "[800]\ttraining's l1: 0.457399\tvalid_1's l1: 0.480712\n",
      "[900]\ttraining's l1: 0.447129\tvalid_1's l1: 0.472274\n",
      "[1000]\ttraining's l1: 0.437789\tvalid_1's l1: 0.464577\n",
      "[1100]\ttraining's l1: 0.428927\tvalid_1's l1: 0.457464\n",
      "[1200]\ttraining's l1: 0.421348\tvalid_1's l1: 0.451648\n",
      "[1300]\ttraining's l1: 0.414022\tvalid_1's l1: 0.445901\n",
      "[1400]\ttraining's l1: 0.407352\tvalid_1's l1: 0.440863\n",
      "[1500]\ttraining's l1: 0.401358\tvalid_1's l1: 0.43631\n",
      "[1600]\ttraining's l1: 0.395821\tvalid_1's l1: 0.432179\n",
      "[1700]\ttraining's l1: 0.390977\tvalid_1's l1: 0.428642\n",
      "[1800]\ttraining's l1: 0.386138\tvalid_1's l1: 0.425093\n",
      "[1900]\ttraining's l1: 0.381511\tvalid_1's l1: 0.421761\n",
      "[2000]\ttraining's l1: 0.37701\tvalid_1's l1: 0.418576\n",
      "[2100]\ttraining's l1: 0.372602\tvalid_1's l1: 0.41557\n",
      "[2200]\ttraining's l1: 0.368402\tvalid_1's l1: 0.412702\n",
      "[2300]\ttraining's l1: 0.364444\tvalid_1's l1: 0.409972\n",
      "[2400]\ttraining's l1: 0.360726\tvalid_1's l1: 0.407429\n",
      "[2500]\ttraining's l1: 0.357138\tvalid_1's l1: 0.405158\n",
      "[2600]\ttraining's l1: 0.353824\tvalid_1's l1: 0.403083\n",
      "[2700]\ttraining's l1: 0.35066\tvalid_1's l1: 0.401136\n",
      "[2800]\ttraining's l1: 0.347523\tvalid_1's l1: 0.399204\n",
      "[2900]\ttraining's l1: 0.344413\tvalid_1's l1: 0.397272\n",
      "[3000]\ttraining's l1: 0.341354\tvalid_1's l1: 0.395339\n",
      "[3100]\ttraining's l1: 0.338549\tvalid_1's l1: 0.393613\n",
      "[3200]\ttraining's l1: 0.335696\tvalid_1's l1: 0.391905\n",
      "[3300]\ttraining's l1: 0.332997\tvalid_1's l1: 0.390346\n",
      "[3400]\ttraining's l1: 0.33035\tvalid_1's l1: 0.388872\n",
      "[3500]\ttraining's l1: 0.327664\tvalid_1's l1: 0.38718\n",
      "[3600]\ttraining's l1: 0.325174\tvalid_1's l1: 0.385734\n",
      "[3700]\ttraining's l1: 0.322727\tvalid_1's l1: 0.38431\n",
      "[3800]\ttraining's l1: 0.320327\tvalid_1's l1: 0.382858\n",
      "[3900]\ttraining's l1: 0.317984\tvalid_1's l1: 0.381516\n",
      "[4000]\ttraining's l1: 0.315806\tvalid_1's l1: 0.380288\n",
      "[4100]\ttraining's l1: 0.313525\tvalid_1's l1: 0.378998\n",
      "[4200]\ttraining's l1: 0.311303\tvalid_1's l1: 0.377829\n",
      "[4300]\ttraining's l1: 0.309133\tvalid_1's l1: 0.376667\n",
      "[4400]\ttraining's l1: 0.307105\tvalid_1's l1: 0.375536\n",
      "[4500]\ttraining's l1: 0.305106\tvalid_1's l1: 0.374436\n",
      "[4600]\ttraining's l1: 0.303123\tvalid_1's l1: 0.373356\n",
      "[4700]\ttraining's l1: 0.301175\tvalid_1's l1: 0.372392\n",
      "[4800]\ttraining's l1: 0.299325\tvalid_1's l1: 0.371349\n",
      "[4900]\ttraining's l1: 0.297536\tvalid_1's l1: 0.370437\n",
      "[5000]\ttraining's l1: 0.295681\tvalid_1's l1: 0.369484\n",
      "[5100]\ttraining's l1: 0.293972\tvalid_1's l1: 0.368628\n",
      "[5200]\ttraining's l1: 0.292167\tvalid_1's l1: 0.367673\n",
      "[5300]\ttraining's l1: 0.290393\tvalid_1's l1: 0.366793\n",
      "[5400]\ttraining's l1: 0.288753\tvalid_1's l1: 0.365974\n",
      "[5500]\ttraining's l1: 0.287021\tvalid_1's l1: 0.365062\n",
      "[5600]\ttraining's l1: 0.285424\tvalid_1's l1: 0.36427\n",
      "[5700]\ttraining's l1: 0.283772\tvalid_1's l1: 0.363407\n",
      "[5800]\ttraining's l1: 0.282177\tvalid_1's l1: 0.362665\n",
      "[5900]\ttraining's l1: 0.280601\tvalid_1's l1: 0.361887\n",
      "[6000]\ttraining's l1: 0.279095\tvalid_1's l1: 0.361193\n",
      "[6100]\ttraining's l1: 0.277574\tvalid_1's l1: 0.360492\n",
      "[6200]\ttraining's l1: 0.276061\tvalid_1's l1: 0.359756\n",
      "[6300]\ttraining's l1: 0.274606\tvalid_1's l1: 0.359111\n",
      "[6400]\ttraining's l1: 0.273117\tvalid_1's l1: 0.35841\n",
      "[6500]\ttraining's l1: 0.271652\tvalid_1's l1: 0.357721\n",
      "[6600]\ttraining's l1: 0.270234\tvalid_1's l1: 0.357074\n",
      "[6700]\ttraining's l1: 0.268853\tvalid_1's l1: 0.356452\n",
      "[6800]\ttraining's l1: 0.267424\tvalid_1's l1: 0.355792\n",
      "[6900]\ttraining's l1: 0.266051\tvalid_1's l1: 0.355207\n",
      "[7000]\ttraining's l1: 0.264735\tvalid_1's l1: 0.354633\n",
      "[7100]\ttraining's l1: 0.263426\tvalid_1's l1: 0.354042\n",
      "[7200]\ttraining's l1: 0.262148\tvalid_1's l1: 0.35348\n",
      "[7300]\ttraining's l1: 0.260808\tvalid_1's l1: 0.352887\n",
      "[7400]\ttraining's l1: 0.259586\tvalid_1's l1: 0.352393\n",
      "[7500]\ttraining's l1: 0.258404\tvalid_1's l1: 0.351907\n",
      "[7600]\ttraining's l1: 0.257146\tvalid_1's l1: 0.351362\n",
      "[7700]\ttraining's l1: 0.255937\tvalid_1's l1: 0.350821\n",
      "[7800]\ttraining's l1: 0.254721\tvalid_1's l1: 0.350271\n",
      "[7900]\ttraining's l1: 0.253521\tvalid_1's l1: 0.349745\n",
      "[8000]\ttraining's l1: 0.252368\tvalid_1's l1: 0.349273\n",
      "[8100]\ttraining's l1: 0.251237\tvalid_1's l1: 0.348805\n",
      "[8200]\ttraining's l1: 0.250041\tvalid_1's l1: 0.348322\n",
      "[8300]\ttraining's l1: 0.248894\tvalid_1's l1: 0.347835\n",
      "[8400]\ttraining's l1: 0.247748\tvalid_1's l1: 0.347343\n",
      "[8500]\ttraining's l1: 0.246643\tvalid_1's l1: 0.346892\n",
      "[8600]\ttraining's l1: 0.245505\tvalid_1's l1: 0.346391\n",
      "[8700]\ttraining's l1: 0.24442\tvalid_1's l1: 0.345913\n",
      "[8800]\ttraining's l1: 0.243295\tvalid_1's l1: 0.345478\n",
      "[8900]\ttraining's l1: 0.242215\tvalid_1's l1: 0.345036\n",
      "[9000]\ttraining's l1: 0.241176\tvalid_1's l1: 0.34463\n",
      "[9100]\ttraining's l1: 0.240104\tvalid_1's l1: 0.344218\n",
      "[9200]\ttraining's l1: 0.239078\tvalid_1's l1: 0.343833\n",
      "[9300]\ttraining's l1: 0.238059\tvalid_1's l1: 0.343439\n",
      "[9400]\ttraining's l1: 0.237041\tvalid_1's l1: 0.343063\n",
      "[9500]\ttraining's l1: 0.23603\tvalid_1's l1: 0.342669\n",
      "[9600]\ttraining's l1: 0.23502\tvalid_1's l1: 0.342309\n",
      "[9700]\ttraining's l1: 0.23404\tvalid_1's l1: 0.341942\n",
      "[9800]\ttraining's l1: 0.233052\tvalid_1's l1: 0.341557\n",
      "[9900]\ttraining's l1: 0.2321\tvalid_1's l1: 0.341212\n",
      "[10000]\ttraining's l1: 0.23111\tvalid_1's l1: 0.340833\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.23111\tvalid_1's l1: 0.340833\n",
      "3JHC Fold 1, logMAE: -1.0763625883573134\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.6821\tvalid_1's l1: 0.68614\n",
      "[200]\ttraining's l1: 0.599676\tvalid_1's l1: 0.606808\n",
      "[300]\ttraining's l1: 0.55597\tvalid_1's l1: 0.566098\n",
      "[400]\ttraining's l1: 0.526838\tvalid_1's l1: 0.539839\n",
      "[500]\ttraining's l1: 0.505071\tvalid_1's l1: 0.520361\n",
      "[600]\ttraining's l1: 0.487102\tvalid_1's l1: 0.504618\n",
      "[700]\ttraining's l1: 0.472622\tvalid_1's l1: 0.492229\n",
      "[800]\ttraining's l1: 0.460541\tvalid_1's l1: 0.482175\n",
      "[900]\ttraining's l1: 0.450083\tvalid_1's l1: 0.473623\n",
      "[1000]\ttraining's l1: 0.440314\tvalid_1's l1: 0.465565\n",
      "[1100]\ttraining's l1: 0.431978\tvalid_1's l1: 0.458898\n",
      "[1200]\ttraining's l1: 0.424018\tvalid_1's l1: 0.45255\n",
      "[1300]\ttraining's l1: 0.416939\tvalid_1's l1: 0.447059\n",
      "[1400]\ttraining's l1: 0.41058\tvalid_1's l1: 0.442317\n",
      "[1500]\ttraining's l1: 0.40443\tvalid_1's l1: 0.437705\n",
      "[1600]\ttraining's l1: 0.398725\tvalid_1's l1: 0.433453\n",
      "[1700]\ttraining's l1: 0.393137\tvalid_1's l1: 0.429327\n",
      "[1800]\ttraining's l1: 0.388079\tvalid_1's l1: 0.425864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1900]\ttraining's l1: 0.383217\tvalid_1's l1: 0.422396\n",
      "[2000]\ttraining's l1: 0.378528\tvalid_1's l1: 0.419015\n",
      "[2100]\ttraining's l1: 0.374281\tvalid_1's l1: 0.416036\n",
      "[2200]\ttraining's l1: 0.370043\tvalid_1's l1: 0.413189\n",
      "[2300]\ttraining's l1: 0.366158\tvalid_1's l1: 0.410594\n",
      "[2400]\ttraining's l1: 0.362263\tvalid_1's l1: 0.408007\n",
      "[2500]\ttraining's l1: 0.358698\tvalid_1's l1: 0.405698\n",
      "[2600]\ttraining's l1: 0.355287\tvalid_1's l1: 0.403544\n",
      "[2700]\ttraining's l1: 0.351858\tvalid_1's l1: 0.401373\n",
      "[2800]\ttraining's l1: 0.348617\tvalid_1's l1: 0.399385\n",
      "[2900]\ttraining's l1: 0.34549\tvalid_1's l1: 0.39743\n",
      "[3000]\ttraining's l1: 0.342482\tvalid_1's l1: 0.395575\n",
      "[3100]\ttraining's l1: 0.339653\tvalid_1's l1: 0.393914\n",
      "[3200]\ttraining's l1: 0.336773\tvalid_1's l1: 0.392179\n",
      "[3300]\ttraining's l1: 0.333986\tvalid_1's l1: 0.390567\n",
      "[3400]\ttraining's l1: 0.331349\tvalid_1's l1: 0.388982\n",
      "[3500]\ttraining's l1: 0.328742\tvalid_1's l1: 0.387428\n",
      "[3600]\ttraining's l1: 0.326107\tvalid_1's l1: 0.385898\n",
      "[3700]\ttraining's l1: 0.323629\tvalid_1's l1: 0.384462\n",
      "[3800]\ttraining's l1: 0.321173\tvalid_1's l1: 0.383051\n",
      "[3900]\ttraining's l1: 0.318841\tvalid_1's l1: 0.381707\n",
      "[4000]\ttraining's l1: 0.316555\tvalid_1's l1: 0.380434\n",
      "[4100]\ttraining's l1: 0.314392\tvalid_1's l1: 0.379272\n",
      "[4200]\ttraining's l1: 0.312179\tvalid_1's l1: 0.37801\n",
      "[4300]\ttraining's l1: 0.310065\tvalid_1's l1: 0.376943\n",
      "[4400]\ttraining's l1: 0.307974\tvalid_1's l1: 0.375785\n",
      "[4500]\ttraining's l1: 0.305967\tvalid_1's l1: 0.374745\n",
      "[4600]\ttraining's l1: 0.303904\tvalid_1's l1: 0.373698\n",
      "[4700]\ttraining's l1: 0.301945\tvalid_1's l1: 0.372705\n",
      "[4800]\ttraining's l1: 0.300107\tvalid_1's l1: 0.371708\n",
      "[4900]\ttraining's l1: 0.298155\tvalid_1's l1: 0.370691\n",
      "[5000]\ttraining's l1: 0.296338\tvalid_1's l1: 0.369818\n",
      "[5100]\ttraining's l1: 0.294571\tvalid_1's l1: 0.368995\n",
      "[5200]\ttraining's l1: 0.292807\tvalid_1's l1: 0.368123\n",
      "[5300]\ttraining's l1: 0.291003\tvalid_1's l1: 0.367223\n",
      "[5400]\ttraining's l1: 0.289248\tvalid_1's l1: 0.366434\n",
      "[5500]\ttraining's l1: 0.287666\tvalid_1's l1: 0.365682\n",
      "[5600]\ttraining's l1: 0.285986\tvalid_1's l1: 0.364858\n",
      "[5700]\ttraining's l1: 0.284342\tvalid_1's l1: 0.364044\n",
      "[5800]\ttraining's l1: 0.282703\tvalid_1's l1: 0.363286\n",
      "[5900]\ttraining's l1: 0.281178\tvalid_1's l1: 0.362624\n",
      "[6000]\ttraining's l1: 0.279607\tvalid_1's l1: 0.361886\n",
      "[6100]\ttraining's l1: 0.27801\tvalid_1's l1: 0.361152\n",
      "[6200]\ttraining's l1: 0.276516\tvalid_1's l1: 0.360454\n",
      "[6300]\ttraining's l1: 0.275039\tvalid_1's l1: 0.359776\n",
      "[6400]\ttraining's l1: 0.273584\tvalid_1's l1: 0.359109\n",
      "[6500]\ttraining's l1: 0.272169\tvalid_1's l1: 0.358495\n",
      "[6600]\ttraining's l1: 0.270674\tvalid_1's l1: 0.357861\n",
      "[6700]\ttraining's l1: 0.269257\tvalid_1's l1: 0.357217\n",
      "[6800]\ttraining's l1: 0.2679\tvalid_1's l1: 0.35658\n",
      "[6900]\ttraining's l1: 0.266549\tvalid_1's l1: 0.356027\n",
      "[7000]\ttraining's l1: 0.265221\tvalid_1's l1: 0.355503\n",
      "[7100]\ttraining's l1: 0.263953\tvalid_1's l1: 0.354956\n",
      "[7200]\ttraining's l1: 0.262622\tvalid_1's l1: 0.354374\n",
      "[7300]\ttraining's l1: 0.261343\tvalid_1's l1: 0.353805\n",
      "[7400]\ttraining's l1: 0.260061\tvalid_1's l1: 0.353271\n",
      "[7500]\ttraining's l1: 0.258806\tvalid_1's l1: 0.352731\n",
      "[7600]\ttraining's l1: 0.25755\tvalid_1's l1: 0.352194\n",
      "[7700]\ttraining's l1: 0.256341\tvalid_1's l1: 0.351683\n",
      "[7800]\ttraining's l1: 0.255111\tvalid_1's l1: 0.351098\n",
      "[7900]\ttraining's l1: 0.253851\tvalid_1's l1: 0.350514\n",
      "[8000]\ttraining's l1: 0.252644\tvalid_1's l1: 0.350045\n",
      "[8100]\ttraining's l1: 0.251488\tvalid_1's l1: 0.349581\n",
      "[8200]\ttraining's l1: 0.250318\tvalid_1's l1: 0.349088\n",
      "[8300]\ttraining's l1: 0.249127\tvalid_1's l1: 0.348632\n",
      "[8400]\ttraining's l1: 0.247979\tvalid_1's l1: 0.348141\n",
      "[8500]\ttraining's l1: 0.246922\tvalid_1's l1: 0.347704\n",
      "[8600]\ttraining's l1: 0.245792\tvalid_1's l1: 0.347213\n",
      "[8700]\ttraining's l1: 0.244662\tvalid_1's l1: 0.346773\n",
      "[8800]\ttraining's l1: 0.243593\tvalid_1's l1: 0.346342\n",
      "[8900]\ttraining's l1: 0.242491\tvalid_1's l1: 0.345877\n",
      "[9000]\ttraining's l1: 0.241415\tvalid_1's l1: 0.345452\n",
      "[9100]\ttraining's l1: 0.240363\tvalid_1's l1: 0.345098\n",
      "[9200]\ttraining's l1: 0.239314\tvalid_1's l1: 0.344676\n",
      "[9300]\ttraining's l1: 0.238345\tvalid_1's l1: 0.344364\n",
      "[9400]\ttraining's l1: 0.237313\tvalid_1's l1: 0.343987\n",
      "[9500]\ttraining's l1: 0.236275\tvalid_1's l1: 0.343543\n",
      "[9600]\ttraining's l1: 0.235291\tvalid_1's l1: 0.343152\n",
      "[9700]\ttraining's l1: 0.234304\tvalid_1's l1: 0.342759\n",
      "[9800]\ttraining's l1: 0.233311\tvalid_1's l1: 0.34238\n",
      "[9900]\ttraining's l1: 0.232343\tvalid_1's l1: 0.342026\n",
      "[10000]\ttraining's l1: 0.231388\tvalid_1's l1: 0.341646\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.231388\tvalid_1's l1: 0.341646\n",
      "3JHC Fold 2, logMAE: -1.073980197951673\n",
      "*** Training Model for 3JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.223366\tvalid_1's l1: 0.236311\n",
      "[200]\ttraining's l1: 0.184928\tvalid_1's l1: 0.204044\n",
      "[300]\ttraining's l1: 0.164339\tvalid_1's l1: 0.188026\n",
      "[400]\ttraining's l1: 0.150306\tvalid_1's l1: 0.178494\n",
      "[500]\ttraining's l1: 0.139458\tvalid_1's l1: 0.171406\n",
      "[600]\ttraining's l1: 0.131042\tvalid_1's l1: 0.166342\n",
      "[700]\ttraining's l1: 0.123909\tvalid_1's l1: 0.162275\n",
      "[800]\ttraining's l1: 0.117969\tvalid_1's l1: 0.159059\n",
      "[900]\ttraining's l1: 0.112834\tvalid_1's l1: 0.156601\n",
      "[1000]\ttraining's l1: 0.108482\tvalid_1's l1: 0.154302\n",
      "[1100]\ttraining's l1: 0.104303\tvalid_1's l1: 0.152298\n",
      "[1200]\ttraining's l1: 0.100396\tvalid_1's l1: 0.150538\n",
      "[1300]\ttraining's l1: 0.0970948\tvalid_1's l1: 0.149114\n",
      "[1400]\ttraining's l1: 0.0937259\tvalid_1's l1: 0.14761\n",
      "[1500]\ttraining's l1: 0.0905809\tvalid_1's l1: 0.146145\n",
      "[1600]\ttraining's l1: 0.0875851\tvalid_1's l1: 0.144897\n",
      "[1700]\ttraining's l1: 0.0849436\tvalid_1's l1: 0.143874\n",
      "[1800]\ttraining's l1: 0.0824856\tvalid_1's l1: 0.142977\n",
      "[1900]\ttraining's l1: 0.0801547\tvalid_1's l1: 0.142118\n",
      "[2000]\ttraining's l1: 0.0779528\tvalid_1's l1: 0.141363\n",
      "[2100]\ttraining's l1: 0.0758712\tvalid_1's l1: 0.140661\n",
      "[2200]\ttraining's l1: 0.0739228\tvalid_1's l1: 0.139944\n",
      "[2300]\ttraining's l1: 0.0720245\tvalid_1's l1: 0.139208\n",
      "[2400]\ttraining's l1: 0.0701524\tvalid_1's l1: 0.138597\n",
      "[2500]\ttraining's l1: 0.0684046\tvalid_1's l1: 0.138139\n",
      "[2600]\ttraining's l1: 0.0666515\tvalid_1's l1: 0.13751\n",
      "[2700]\ttraining's l1: 0.0650612\tvalid_1's l1: 0.136964\n",
      "[2800]\ttraining's l1: 0.0635499\tvalid_1's l1: 0.13646\n",
      "[2900]\ttraining's l1: 0.0620593\tvalid_1's l1: 0.135989\n",
      "[3000]\ttraining's l1: 0.0607091\tvalid_1's l1: 0.135562\n",
      "[3100]\ttraining's l1: 0.0593231\tvalid_1's l1: 0.135102\n",
      "[3200]\ttraining's l1: 0.0580583\tvalid_1's l1: 0.134745\n",
      "[3300]\ttraining's l1: 0.05685\tvalid_1's l1: 0.134385\n",
      "[3400]\ttraining's l1: 0.0556908\tvalid_1's l1: 0.134091\n",
      "[3500]\ttraining's l1: 0.0545694\tvalid_1's l1: 0.133817\n",
      "[3600]\ttraining's l1: 0.0534227\tvalid_1's l1: 0.133484\n",
      "[3700]\ttraining's l1: 0.0523366\tvalid_1's l1: 0.133214\n",
      "[3800]\ttraining's l1: 0.051309\tvalid_1's l1: 0.132928\n",
      "[3900]\ttraining's l1: 0.0502936\tvalid_1's l1: 0.132635\n",
      "[4000]\ttraining's l1: 0.0492781\tvalid_1's l1: 0.132346\n",
      "[4100]\ttraining's l1: 0.0483484\tvalid_1's l1: 0.132123\n",
      "[4200]\ttraining's l1: 0.0475002\tvalid_1's l1: 0.131923\n",
      "[4300]\ttraining's l1: 0.0466252\tvalid_1's l1: 0.131723\n",
      "[4400]\ttraining's l1: 0.0457492\tvalid_1's l1: 0.131525\n",
      "[4500]\ttraining's l1: 0.04492\tvalid_1's l1: 0.131304\n",
      "[4600]\ttraining's l1: 0.0441357\tvalid_1's l1: 0.131112\n",
      "[4700]\ttraining's l1: 0.0433428\tvalid_1's l1: 0.130896\n",
      "[4800]\ttraining's l1: 0.0425812\tvalid_1's l1: 0.130724\n",
      "[4900]\ttraining's l1: 0.0418624\tvalid_1's l1: 0.130582\n",
      "[5000]\ttraining's l1: 0.0411518\tvalid_1's l1: 0.130451\n",
      "[5100]\ttraining's l1: 0.04046\tvalid_1's l1: 0.130311\n",
      "[5200]\ttraining's l1: 0.0397791\tvalid_1's l1: 0.130177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5300]\ttraining's l1: 0.0390959\tvalid_1's l1: 0.130026\n",
      "[5400]\ttraining's l1: 0.0384625\tvalid_1's l1: 0.129884\n",
      "[5500]\ttraining's l1: 0.0378543\tvalid_1's l1: 0.129765\n",
      "[5600]\ttraining's l1: 0.0372355\tvalid_1's l1: 0.129646\n",
      "[5700]\ttraining's l1: 0.0366228\tvalid_1's l1: 0.12949\n",
      "[5800]\ttraining's l1: 0.0360568\tvalid_1's l1: 0.129369\n",
      "[5900]\ttraining's l1: 0.0355141\tvalid_1's l1: 0.129268\n",
      "[6000]\ttraining's l1: 0.034964\tvalid_1's l1: 0.12921\n",
      "[6100]\ttraining's l1: 0.034426\tvalid_1's l1: 0.129113\n",
      "[6200]\ttraining's l1: 0.0339095\tvalid_1's l1: 0.128996\n",
      "[6300]\ttraining's l1: 0.0333751\tvalid_1's l1: 0.128904\n",
      "[6400]\ttraining's l1: 0.0328964\tvalid_1's l1: 0.128799\n",
      "[6500]\ttraining's l1: 0.0324037\tvalid_1's l1: 0.128725\n",
      "[6600]\ttraining's l1: 0.0319253\tvalid_1's l1: 0.128654\n",
      "[6700]\ttraining's l1: 0.0314433\tvalid_1's l1: 0.128558\n",
      "[6800]\ttraining's l1: 0.0309954\tvalid_1's l1: 0.12848\n",
      "[6900]\ttraining's l1: 0.0305435\tvalid_1's l1: 0.128403\n",
      "[7000]\ttraining's l1: 0.0301205\tvalid_1's l1: 0.128321\n",
      "[7100]\ttraining's l1: 0.0296916\tvalid_1's l1: 0.128277\n",
      "[7200]\ttraining's l1: 0.0292633\tvalid_1's l1: 0.128183\n",
      "[7300]\ttraining's l1: 0.0288605\tvalid_1's l1: 0.12813\n",
      "[7400]\ttraining's l1: 0.0284715\tvalid_1's l1: 0.128088\n",
      "[7500]\ttraining's l1: 0.0280899\tvalid_1's l1: 0.128007\n",
      "[7600]\ttraining's l1: 0.0277163\tvalid_1's l1: 0.127924\n",
      "[7700]\ttraining's l1: 0.0273459\tvalid_1's l1: 0.127864\n",
      "[7800]\ttraining's l1: 0.0269804\tvalid_1's l1: 0.127802\n",
      "[7900]\ttraining's l1: 0.0266176\tvalid_1's l1: 0.127718\n",
      "[8000]\ttraining's l1: 0.0262742\tvalid_1's l1: 0.127653\n",
      "[8100]\ttraining's l1: 0.0259416\tvalid_1's l1: 0.127621\n",
      "[8200]\ttraining's l1: 0.0256123\tvalid_1's l1: 0.127571\n",
      "[8300]\ttraining's l1: 0.0252745\tvalid_1's l1: 0.127526\n",
      "[8400]\ttraining's l1: 0.0249556\tvalid_1's l1: 0.127477\n",
      "[8500]\ttraining's l1: 0.0246397\tvalid_1's l1: 0.127422\n",
      "[8600]\ttraining's l1: 0.0243349\tvalid_1's l1: 0.127366\n",
      "[8700]\ttraining's l1: 0.0240403\tvalid_1's l1: 0.127325\n",
      "[8800]\ttraining's l1: 0.0237612\tvalid_1's l1: 0.127259\n",
      "[8900]\ttraining's l1: 0.0234737\tvalid_1's l1: 0.127211\n",
      "[9000]\ttraining's l1: 0.0231895\tvalid_1's l1: 0.127182\n",
      "[9100]\ttraining's l1: 0.0229161\tvalid_1's l1: 0.127131\n",
      "[9200]\ttraining's l1: 0.0226403\tvalid_1's l1: 0.12709\n",
      "[9300]\ttraining's l1: 0.0223587\tvalid_1's l1: 0.127041\n",
      "[9400]\ttraining's l1: 0.0221028\tvalid_1's l1: 0.12701\n",
      "[9500]\ttraining's l1: 0.0218495\tvalid_1's l1: 0.126965\n",
      "[9600]\ttraining's l1: 0.0215968\tvalid_1's l1: 0.12692\n",
      "[9700]\ttraining's l1: 0.0213377\tvalid_1's l1: 0.126895\n",
      "[9800]\ttraining's l1: 0.0210983\tvalid_1's l1: 0.12686\n",
      "[9900]\ttraining's l1: 0.0208594\tvalid_1's l1: 0.126808\n",
      "[10000]\ttraining's l1: 0.0206208\tvalid_1's l1: 0.126768\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0206208\tvalid_1's l1: 0.126768\n",
      "3JHN Fold 0, logMAE: -2.065392754865507\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.224039\tvalid_1's l1: 0.233521\n",
      "[200]\ttraining's l1: 0.185026\tvalid_1's l1: 0.201283\n",
      "[300]\ttraining's l1: 0.164095\tvalid_1's l1: 0.185629\n",
      "[400]\ttraining's l1: 0.150456\tvalid_1's l1: 0.176101\n",
      "[500]\ttraining's l1: 0.140048\tvalid_1's l1: 0.169658\n",
      "[600]\ttraining's l1: 0.131785\tvalid_1's l1: 0.16457\n",
      "[700]\ttraining's l1: 0.124729\tvalid_1's l1: 0.160364\n",
      "[800]\ttraining's l1: 0.118729\tvalid_1's l1: 0.15721\n",
      "[900]\ttraining's l1: 0.113301\tvalid_1's l1: 0.154389\n",
      "[1000]\ttraining's l1: 0.108746\tvalid_1's l1: 0.152055\n",
      "[1100]\ttraining's l1: 0.104477\tvalid_1's l1: 0.150072\n",
      "[1200]\ttraining's l1: 0.100633\tvalid_1's l1: 0.148365\n",
      "[1300]\ttraining's l1: 0.0972793\tvalid_1's l1: 0.146819\n",
      "[1400]\ttraining's l1: 0.094045\tvalid_1's l1: 0.145499\n",
      "[1500]\ttraining's l1: 0.0910607\tvalid_1's l1: 0.144391\n",
      "[1600]\ttraining's l1: 0.0883111\tvalid_1's l1: 0.143253\n",
      "[1700]\ttraining's l1: 0.0855501\tvalid_1's l1: 0.142108\n",
      "[1800]\ttraining's l1: 0.0829987\tvalid_1's l1: 0.141218\n",
      "[1900]\ttraining's l1: 0.0806367\tvalid_1's l1: 0.140396\n",
      "[2000]\ttraining's l1: 0.0783092\tvalid_1's l1: 0.139557\n",
      "[2100]\ttraining's l1: 0.0761841\tvalid_1's l1: 0.138844\n",
      "[2200]\ttraining's l1: 0.0740413\tvalid_1's l1: 0.138098\n",
      "[2300]\ttraining's l1: 0.0720937\tvalid_1's l1: 0.137456\n",
      "[2400]\ttraining's l1: 0.0703408\tvalid_1's l1: 0.136913\n",
      "[2500]\ttraining's l1: 0.0685697\tvalid_1's l1: 0.136289\n",
      "[2600]\ttraining's l1: 0.0668686\tvalid_1's l1: 0.135804\n",
      "[2700]\ttraining's l1: 0.0652523\tvalid_1's l1: 0.135221\n",
      "[2800]\ttraining's l1: 0.0637455\tvalid_1's l1: 0.134713\n",
      "[2900]\ttraining's l1: 0.0622904\tvalid_1's l1: 0.134282\n",
      "[3000]\ttraining's l1: 0.0608649\tvalid_1's l1: 0.133902\n",
      "[3100]\ttraining's l1: 0.0595189\tvalid_1's l1: 0.133499\n",
      "[3200]\ttraining's l1: 0.0582068\tvalid_1's l1: 0.133092\n",
      "[3300]\ttraining's l1: 0.0569481\tvalid_1's l1: 0.132727\n",
      "[3400]\ttraining's l1: 0.0557671\tvalid_1's l1: 0.132423\n",
      "[3500]\ttraining's l1: 0.0546532\tvalid_1's l1: 0.132104\n",
      "[3600]\ttraining's l1: 0.0535433\tvalid_1's l1: 0.13183\n",
      "[3700]\ttraining's l1: 0.05242\tvalid_1's l1: 0.131514\n",
      "[3800]\ttraining's l1: 0.0513439\tvalid_1's l1: 0.131277\n",
      "[3900]\ttraining's l1: 0.0503127\tvalid_1's l1: 0.131029\n",
      "[4000]\ttraining's l1: 0.0493404\tvalid_1's l1: 0.130708\n",
      "[4100]\ttraining's l1: 0.0483797\tvalid_1's l1: 0.130489\n",
      "[4200]\ttraining's l1: 0.047451\tvalid_1's l1: 0.130295\n",
      "[4300]\ttraining's l1: 0.0465913\tvalid_1's l1: 0.130096\n",
      "[4400]\ttraining's l1: 0.0457257\tvalid_1's l1: 0.129859\n",
      "[4500]\ttraining's l1: 0.0448877\tvalid_1's l1: 0.12967\n",
      "[4600]\ttraining's l1: 0.0440987\tvalid_1's l1: 0.1295\n",
      "[4700]\ttraining's l1: 0.0433088\tvalid_1's l1: 0.129334\n",
      "[4800]\ttraining's l1: 0.0425627\tvalid_1's l1: 0.129186\n",
      "[4900]\ttraining's l1: 0.0418547\tvalid_1's l1: 0.129002\n",
      "[5000]\ttraining's l1: 0.0411659\tvalid_1's l1: 0.128826\n",
      "[5100]\ttraining's l1: 0.0404714\tvalid_1's l1: 0.128639\n",
      "[5200]\ttraining's l1: 0.0398185\tvalid_1's l1: 0.128475\n",
      "[5300]\ttraining's l1: 0.0391662\tvalid_1's l1: 0.128336\n",
      "[5400]\ttraining's l1: 0.0385169\tvalid_1's l1: 0.1282\n",
      "[5500]\ttraining's l1: 0.0379122\tvalid_1's l1: 0.128063\n",
      "[5600]\ttraining's l1: 0.0373291\tvalid_1's l1: 0.12793\n",
      "[5700]\ttraining's l1: 0.0367428\tvalid_1's l1: 0.127811\n",
      "[5800]\ttraining's l1: 0.0361456\tvalid_1's l1: 0.127673\n",
      "[5900]\ttraining's l1: 0.0355985\tvalid_1's l1: 0.127547\n",
      "[6000]\ttraining's l1: 0.0350552\tvalid_1's l1: 0.127431\n",
      "[6100]\ttraining's l1: 0.0345024\tvalid_1's l1: 0.127316\n",
      "[6200]\ttraining's l1: 0.0339711\tvalid_1's l1: 0.127236\n",
      "[6300]\ttraining's l1: 0.0334553\tvalid_1's l1: 0.127125\n",
      "[6400]\ttraining's l1: 0.0329463\tvalid_1's l1: 0.127023\n",
      "[6500]\ttraining's l1: 0.0324585\tvalid_1's l1: 0.12692\n",
      "[6600]\ttraining's l1: 0.0319774\tvalid_1's l1: 0.126822\n",
      "[6700]\ttraining's l1: 0.0315001\tvalid_1's l1: 0.126746\n",
      "[6800]\ttraining's l1: 0.0310365\tvalid_1's l1: 0.126662\n",
      "[6900]\ttraining's l1: 0.0305877\tvalid_1's l1: 0.126544\n",
      "[7000]\ttraining's l1: 0.0301551\tvalid_1's l1: 0.126479\n",
      "[7100]\ttraining's l1: 0.0297274\tvalid_1's l1: 0.126397\n",
      "[7200]\ttraining's l1: 0.0293167\tvalid_1's l1: 0.126323\n",
      "[7300]\ttraining's l1: 0.0289105\tvalid_1's l1: 0.126253\n",
      "[7400]\ttraining's l1: 0.0285093\tvalid_1's l1: 0.126183\n",
      "[7500]\ttraining's l1: 0.0281131\tvalid_1's l1: 0.126117\n",
      "[7600]\ttraining's l1: 0.0277358\tvalid_1's l1: 0.126033\n",
      "[7700]\ttraining's l1: 0.0273755\tvalid_1's l1: 0.125968\n",
      "[7800]\ttraining's l1: 0.0270094\tvalid_1's l1: 0.125902\n",
      "[7900]\ttraining's l1: 0.0266597\tvalid_1's l1: 0.125853\n",
      "[8000]\ttraining's l1: 0.0263091\tvalid_1's l1: 0.125772\n",
      "[8100]\ttraining's l1: 0.0259805\tvalid_1's l1: 0.125711\n",
      "[8200]\ttraining's l1: 0.0256635\tvalid_1's l1: 0.125681\n",
      "[8300]\ttraining's l1: 0.0253455\tvalid_1's l1: 0.12562\n",
      "[8400]\ttraining's l1: 0.0250227\tvalid_1's l1: 0.125558\n",
      "[8500]\ttraining's l1: 0.0247175\tvalid_1's l1: 0.125511\n",
      "[8600]\ttraining's l1: 0.0244183\tvalid_1's l1: 0.125452\n",
      "[8700]\ttraining's l1: 0.0241168\tvalid_1's l1: 0.125408\n",
      "[8800]\ttraining's l1: 0.0238186\tvalid_1's l1: 0.125365\n",
      "[8900]\ttraining's l1: 0.0235263\tvalid_1's l1: 0.125315\n",
      "[9000]\ttraining's l1: 0.0232479\tvalid_1's l1: 0.125279\n",
      "[9100]\ttraining's l1: 0.0229785\tvalid_1's l1: 0.125233\n",
      "[9200]\ttraining's l1: 0.0227059\tvalid_1's l1: 0.125183\n",
      "[9300]\ttraining's l1: 0.0224433\tvalid_1's l1: 0.125134\n",
      "[9400]\ttraining's l1: 0.0221762\tvalid_1's l1: 0.125091\n",
      "[9500]\ttraining's l1: 0.0219117\tvalid_1's l1: 0.125044\n",
      "[9600]\ttraining's l1: 0.0216667\tvalid_1's l1: 0.125022\n",
      "[9700]\ttraining's l1: 0.02142\tvalid_1's l1: 0.124974\n",
      "[9800]\ttraining's l1: 0.0211801\tvalid_1's l1: 0.124938\n",
      "[9900]\ttraining's l1: 0.020936\tvalid_1's l1: 0.124897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10000]\ttraining's l1: 0.0207058\tvalid_1's l1: 0.124846\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0207058\tvalid_1's l1: 0.124846\n",
      "3JHN Fold 1, logMAE: -2.080676915515261\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's l1: 0.223899\tvalid_1's l1: 0.236414\n",
      "[200]\ttraining's l1: 0.184792\tvalid_1's l1: 0.203594\n",
      "[300]\ttraining's l1: 0.163124\tvalid_1's l1: 0.186668\n",
      "[400]\ttraining's l1: 0.149387\tvalid_1's l1: 0.17743\n",
      "[500]\ttraining's l1: 0.139571\tvalid_1's l1: 0.171146\n",
      "[600]\ttraining's l1: 0.13103\tvalid_1's l1: 0.166151\n",
      "[700]\ttraining's l1: 0.123843\tvalid_1's l1: 0.16221\n",
      "[800]\ttraining's l1: 0.11822\tvalid_1's l1: 0.159141\n",
      "[900]\ttraining's l1: 0.113255\tvalid_1's l1: 0.156642\n",
      "[1000]\ttraining's l1: 0.10857\tvalid_1's l1: 0.154286\n",
      "[1100]\ttraining's l1: 0.104318\tvalid_1's l1: 0.15226\n",
      "[1200]\ttraining's l1: 0.100442\tvalid_1's l1: 0.150549\n",
      "[1300]\ttraining's l1: 0.0969442\tvalid_1's l1: 0.149071\n",
      "[1400]\ttraining's l1: 0.0937544\tvalid_1's l1: 0.147726\n",
      "[1500]\ttraining's l1: 0.0906562\tvalid_1's l1: 0.146369\n",
      "[1600]\ttraining's l1: 0.0878902\tvalid_1's l1: 0.145279\n",
      "[1700]\ttraining's l1: 0.0851724\tvalid_1's l1: 0.144254\n",
      "[1800]\ttraining's l1: 0.0826739\tvalid_1's l1: 0.143288\n",
      "[1900]\ttraining's l1: 0.0803371\tvalid_1's l1: 0.142441\n",
      "[2000]\ttraining's l1: 0.0780976\tvalid_1's l1: 0.141616\n",
      "[2100]\ttraining's l1: 0.0761001\tvalid_1's l1: 0.140947\n",
      "[2200]\ttraining's l1: 0.0740624\tvalid_1's l1: 0.140213\n",
      "[2300]\ttraining's l1: 0.072242\tvalid_1's l1: 0.139586\n",
      "[2400]\ttraining's l1: 0.0703567\tvalid_1's l1: 0.138945\n",
      "[2500]\ttraining's l1: 0.0686692\tvalid_1's l1: 0.138316\n",
      "[2600]\ttraining's l1: 0.067011\tvalid_1's l1: 0.137798\n",
      "[2700]\ttraining's l1: 0.0654448\tvalid_1's l1: 0.137287\n",
      "[2800]\ttraining's l1: 0.0638926\tvalid_1's l1: 0.136744\n",
      "[2900]\ttraining's l1: 0.0624002\tvalid_1's l1: 0.136282\n",
      "[3000]\ttraining's l1: 0.0609721\tvalid_1's l1: 0.135864\n",
      "[3100]\ttraining's l1: 0.059577\tvalid_1's l1: 0.135485\n",
      "[3200]\ttraining's l1: 0.0582982\tvalid_1's l1: 0.135103\n",
      "[3300]\ttraining's l1: 0.0570303\tvalid_1's l1: 0.134702\n",
      "[3400]\ttraining's l1: 0.0558312\tvalid_1's l1: 0.134362\n",
      "[3500]\ttraining's l1: 0.0547216\tvalid_1's l1: 0.133979\n",
      "[3600]\ttraining's l1: 0.0536469\tvalid_1's l1: 0.133691\n",
      "[3700]\ttraining's l1: 0.0525186\tvalid_1's l1: 0.133373\n",
      "[3800]\ttraining's l1: 0.0514879\tvalid_1's l1: 0.133146\n",
      "[3900]\ttraining's l1: 0.0504997\tvalid_1's l1: 0.132884\n",
      "[4000]\ttraining's l1: 0.049544\tvalid_1's l1: 0.132619\n",
      "[4100]\ttraining's l1: 0.048582\tvalid_1's l1: 0.132348\n",
      "[4200]\ttraining's l1: 0.047669\tvalid_1's l1: 0.13213\n",
      "[4300]\ttraining's l1: 0.0467475\tvalid_1's l1: 0.131905\n",
      "[4400]\ttraining's l1: 0.0458832\tvalid_1's l1: 0.131733\n",
      "[4500]\ttraining's l1: 0.0450638\tvalid_1's l1: 0.131511\n",
      "[4600]\ttraining's l1: 0.0442414\tvalid_1's l1: 0.131254\n",
      "[4700]\ttraining's l1: 0.0434715\tvalid_1's l1: 0.131027\n",
      "[4800]\ttraining's l1: 0.0427178\tvalid_1's l1: 0.130872\n",
      "[4900]\ttraining's l1: 0.0419914\tvalid_1's l1: 0.130734\n",
      "[5000]\ttraining's l1: 0.0412535\tvalid_1's l1: 0.130544\n",
      "[5100]\ttraining's l1: 0.0405682\tvalid_1's l1: 0.130378\n",
      "[5200]\ttraining's l1: 0.0398932\tvalid_1's l1: 0.130234\n",
      "[5300]\ttraining's l1: 0.0392478\tvalid_1's l1: 0.130097\n",
      "[5400]\ttraining's l1: 0.0386207\tvalid_1's l1: 0.129964\n",
      "[5500]\ttraining's l1: 0.037998\tvalid_1's l1: 0.129808\n",
      "[5600]\ttraining's l1: 0.0373744\tvalid_1's l1: 0.129687\n",
      "[5700]\ttraining's l1: 0.0367479\tvalid_1's l1: 0.129576\n",
      "[5800]\ttraining's l1: 0.0361593\tvalid_1's l1: 0.129448\n",
      "[5900]\ttraining's l1: 0.035569\tvalid_1's l1: 0.129297\n",
      "[6000]\ttraining's l1: 0.0350243\tvalid_1's l1: 0.129162\n",
      "[6100]\ttraining's l1: 0.0344696\tvalid_1's l1: 0.129037\n",
      "[6200]\ttraining's l1: 0.0339472\tvalid_1's l1: 0.128916\n",
      "[6300]\ttraining's l1: 0.0334455\tvalid_1's l1: 0.128825\n",
      "[6400]\ttraining's l1: 0.032935\tvalid_1's l1: 0.12873\n",
      "[6500]\ttraining's l1: 0.0324493\tvalid_1's l1: 0.128646\n",
      "[6600]\ttraining's l1: 0.0319731\tvalid_1's l1: 0.128534\n",
      "[6700]\ttraining's l1: 0.031512\tvalid_1's l1: 0.128462\n",
      "[6800]\ttraining's l1: 0.0310572\tvalid_1's l1: 0.12839\n",
      "[6900]\ttraining's l1: 0.0306033\tvalid_1's l1: 0.128296\n",
      "[7000]\ttraining's l1: 0.0301622\tvalid_1's l1: 0.128207\n",
      "[7100]\ttraining's l1: 0.0297201\tvalid_1's l1: 0.128125\n",
      "[7200]\ttraining's l1: 0.0293135\tvalid_1's l1: 0.128043\n",
      "[7300]\ttraining's l1: 0.0289046\tvalid_1's l1: 0.127984\n",
      "[7400]\ttraining's l1: 0.0284974\tvalid_1's l1: 0.127911\n",
      "[7500]\ttraining's l1: 0.028102\tvalid_1's l1: 0.127822\n",
      "[7600]\ttraining's l1: 0.0277411\tvalid_1's l1: 0.127763\n",
      "[7700]\ttraining's l1: 0.0273642\tvalid_1's l1: 0.12771\n",
      "[7800]\ttraining's l1: 0.0270149\tvalid_1's l1: 0.12764\n",
      "[7900]\ttraining's l1: 0.0266521\tvalid_1's l1: 0.127566\n",
      "[8000]\ttraining's l1: 0.0263007\tvalid_1's l1: 0.127504\n",
      "[8100]\ttraining's l1: 0.0259724\tvalid_1's l1: 0.127443\n",
      "[8200]\ttraining's l1: 0.0256353\tvalid_1's l1: 0.127382\n",
      "[8300]\ttraining's l1: 0.0253178\tvalid_1's l1: 0.127317\n",
      "[8400]\ttraining's l1: 0.0249971\tvalid_1's l1: 0.127252\n",
      "[8500]\ttraining's l1: 0.0246836\tvalid_1's l1: 0.127199\n",
      "[8600]\ttraining's l1: 0.0243811\tvalid_1's l1: 0.127146\n",
      "[8700]\ttraining's l1: 0.0240714\tvalid_1's l1: 0.127116\n",
      "[8800]\ttraining's l1: 0.0237755\tvalid_1's l1: 0.127069\n",
      "[8900]\ttraining's l1: 0.0234884\tvalid_1's l1: 0.12701\n",
      "[9000]\ttraining's l1: 0.0231989\tvalid_1's l1: 0.126958\n",
      "[9100]\ttraining's l1: 0.0229145\tvalid_1's l1: 0.126916\n",
      "[9200]\ttraining's l1: 0.0226397\tvalid_1's l1: 0.126876\n",
      "[9300]\ttraining's l1: 0.0223803\tvalid_1's l1: 0.126847\n",
      "[9400]\ttraining's l1: 0.0221213\tvalid_1's l1: 0.126802\n",
      "[9500]\ttraining's l1: 0.0218727\tvalid_1's l1: 0.126753\n",
      "[9600]\ttraining's l1: 0.0216203\tvalid_1's l1: 0.126708\n",
      "[9700]\ttraining's l1: 0.0213707\tvalid_1's l1: 0.126652\n",
      "[9800]\ttraining's l1: 0.0211259\tvalid_1's l1: 0.126624\n",
      "[9900]\ttraining's l1: 0.0208954\tvalid_1's l1: 0.126579\n",
      "[10000]\ttraining's l1: 0.020665\tvalid_1's l1: 0.126535\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.020665\tvalid_1's l1: 0.126535\n",
      "3JHN Fold 2, logMAE: -2.0672384739445304\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 3\n",
    "submission = submission_csv.copy()\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission, n_atoms=model_params[coupling_type], n_folds=N_FOLDS)\n",
    "    cv_scores[coupling_type] = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1JHC</td>\n",
       "      <td>-0.221759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1JHN</td>\n",
       "      <td>-0.811195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2JHH</td>\n",
       "      <td>-1.713232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2JHN</td>\n",
       "      <td>-1.922905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2JHC</td>\n",
       "      <td>-1.159278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3JHH</td>\n",
       "      <td>-1.794444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3JHC</td>\n",
       "      <td>-1.074661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3JHN</td>\n",
       "      <td>-2.071103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  cv_score\n",
       "0  1JHC -0.221759\n",
       "1  1JHN -0.811195\n",
       "2  2JHH -1.713232\n",
       "3  2JHN -1.922905\n",
       "4  2JHC -1.159278\n",
       "5  3JHH -1.794444\n",
       "6  3JHC -1.074661\n",
       "7  3JHN -2.071103"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And cv mean score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3460719540360282"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check for all cells to be filled with predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['scalar_coupling_constant'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>17.640482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>194.249176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>2.118107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>194.249176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>17.640482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>90.360893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>2.405610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>-7.489653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>-9.619507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>90.827225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scalar_coupling_constant\n",
       "id                               \n",
       "4658147  17.640482               \n",
       "4658148  194.249176              \n",
       "4658149  2.118107                \n",
       "4658150  194.249176              \n",
       "4658151  17.640482               \n",
       "4658152  90.360893               \n",
       "4658153  2.405610                \n",
       "4658154 -7.489653                \n",
       "4658155 -9.619507                \n",
       "4658156  90.827225               "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'{SUBMISSIONS_PATH}/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 630,
   "position": {
    "height": "40px",
    "left": "1388px",
    "right": "20px",
    "top": "8px",
    "width": "516px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
