{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Core Idea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Despite a lot of creeping Physics and Chemistry knowledge introduced in the description, this competition is more about Geometry and pattern matching.\n",
    "\n",
    "The hypothesis of this kernel is next:\n",
    "1. If we have two similar sets of atoms with the same distances between them and the same types - the scalar coupling constant should be very close.\n",
    "2. More closest atoms to the pair of atoms under prediction have higher influence on scalar coupling constant then those with higher distance\n",
    "\n",
    "So, basically, this problem could be dealt with some kind of K-Nearest Neighbor algorithm or any tree-based - e.g. LightGBM, in case we can find some representation which would describe similar configurations with similar feature sets.\n",
    "\n",
    "Each atom is described with 3 cartesian coordinates. This representation is not stable. Each coupling pair is located in a different point in space and two similar coupling sets would have very different X,Y,Z.\n",
    "\n",
    "So, instead of using coordinates let's consider next system:\n",
    "1. Take each pair of atoms as two first core atoms\n",
    "2. Calculate the center between the pair\n",
    "3. Find all n-nearest atoms to the center (excluding first two atoms)\n",
    "4. Take two closest atoms from step 3 - they will be 3rd and 4th core atoms\n",
    "5. Calculate the distances from 4 core atoms to the rest of the atoms and to the core atoms as well\n",
    "\n",
    "Using this representation each atom position can be described by 4 distances from the core atoms. This representation is stable to rotation and translation. And it's suitable for pattern-matching. So, we can take a sequence of atoms, describe each by 4 distances + atom type(H,O,etc) and looking up for the same pattern we can find similar configurations and detect scalar coupling constant.\n",
    "\n",
    "Here I used LightGBM, because sklearn KNN can't deal with the amount of data. My blind guess is that hand-crafted KNN can outperform LightGBM.\n",
    "\n",
    "Let's code the solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import modules, set options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "import gc\n",
    "import copy\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import os\n",
    "# os.listdir('../input/imputed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = '..\\\\input'\n",
    "SUBMISSIONS_PATH = '..\\\\output'\n",
    "INPUT_ADDED = '..\\\\input_added'\n",
    "# use atomic numbers to recode atomic names\n",
    "ATOMIC_NUMBERS = {\n",
    "    'H': 1,\n",
    "    'C': 6,\n",
    "    'N': 7,\n",
    "    'O': 8,\n",
    "    'F': 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 120)\n",
    "pd.set_option('display.max_columns', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all data is read as `float64` and `int64`. We can trade this uneeded precision for memory and higher prediction speed. So, let's read with Pandas all the data in the minimal representation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.257000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.807404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "      <td>-11.254300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "      <td>84.809502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    molecule_index  atom_index_0  atom_index_1  type  scalar_coupling_constant\n",
       "id                                                                            \n",
       "0   1               1             0             1JHC  84.807602               \n",
       "1   1               1             2             2JHH -11.257000               \n",
       "2   1               1             3             2JHH -11.254800               \n",
       "3   1               1             4             2JHH -11.254300               \n",
       "4   1               2             0             1JHC  84.807404               \n",
       "5   1               2             3             2JHH -11.254100               \n",
       "6   1               2             4             2JHH -11.254800               \n",
       "7   1               3             0             1JHC  84.809303               \n",
       "8   1               3             4             2JHH -11.254300               \n",
       "9   1               4             0             1JHC  84.809502               "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index_0': 'int8',\n",
    "    'atom_index_1': 'int8',\n",
    "    'type': 'category',\n",
    "    'scalar_coupling_constant': 'float32'\n",
    "}\n",
    "train_csv = pd.read_csv(f'{DATA_PATH}\\\\train.csv', index_col='id', dtype=train_dtypes)\n",
    "train_csv['molecule_index'] = train_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "train_csv = train_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type', 'scalar_coupling_constant']]\n",
    "train_csv.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv, _ = train_test_split(train_csv, test_size=0.9, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train_CSV Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>465814.000000</td>\n",
       "      <td>465814.000000</td>\n",
       "      <td>465814.000000</td>\n",
       "      <td>465814.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>69268.130563</td>\n",
       "      <td>13.358577</td>\n",
       "      <td>5.889037</td>\n",
       "      <td>15.912537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36611.492817</td>\n",
       "      <td>3.262254</td>\n",
       "      <td>4.998477</td>\n",
       "      <td>34.920429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.582699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39073.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.262648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>71760.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.278085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>100919.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.378878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>133884.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>203.188995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       molecule_index   atom_index_0   atom_index_1  scalar_coupling_constant\n",
       "count  465814.000000   465814.000000  465814.000000  465814.000000           \n",
       "mean   69268.130563    13.358577      5.889037       15.912537               \n",
       "std    36611.492817    3.262254       4.998477       34.920429               \n",
       "min    1.000000        1.000000       0.000000      -33.582699               \n",
       "25%    39073.000000    11.000000      2.000000      -0.262648                \n",
       "50%    71760.000000    13.000000      5.000000       2.278085                \n",
       "75%    100919.000000   16.000000      8.000000       7.378878                \n",
       "max    133884.000000   28.000000      28.000000      203.188995              "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (465814, 5)\n",
      "Total:  8850850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index                       3726512\n",
       "molecule_index              1863256\n",
       "atom_index_0                465814 \n",
       "atom_index_1                465814 \n",
       "type                        466198 \n",
       "scalar_coupling_constant    1863256\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', train_csv.shape)\n",
    "print('Total: ', train_csv.memory_usage().sum())\n",
    "train_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\numpy\\lib\\arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "submission_csv = pd.read_csv(f'{DATA_PATH}\\\\sample_submission.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3JHC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2JHH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1JHC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         molecule_index  atom_index_0  atom_index_1  type\n",
       "id                                                       \n",
       "4658147  4               2             0             2JHC\n",
       "4658148  4               2             1             1JHC\n",
       "4658149  4               2             3             3JHH\n",
       "4658150  4               3             0             1JHC\n",
       "4658151  4               3             1             2JHC\n",
       "4658152  15              3             0             1JHC\n",
       "4658153  15              3             2             3JHC\n",
       "4658154  15              3             4             2JHH\n",
       "4658155  15              3             5             2JHH\n",
       "4658156  15              4             0             1JHC"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(f'{DATA_PATH}\\\\test.csv', index_col='id', dtype=train_dtypes)\n",
    "test_csv['molecule_index'] = test_csv['molecule_name'].str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "test_csv = test_csv[['molecule_index', 'atom_index_0', 'atom_index_1', 'type']]\n",
    "test_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index</th>\n",
       "      <th>atom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>-0.876644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>0.906397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.040426</td>\n",
       "      <td>1.024108</td>\n",
       "      <td>0.062564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017257</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.027377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>1.358745</td>\n",
       "      <td>-0.028758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.520278</td>\n",
       "      <td>1.343532</td>\n",
       "      <td>-0.775543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.034360</td>\n",
       "      <td>0.977540</td>\n",
       "      <td>0.007602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   molecule_index  atom_index  atom         x         y         z\n",
       "0  1               0           6    -0.012698  1.085804  0.008001\n",
       "1  1               1           1     0.002150 -0.006031  0.001976\n",
       "2  1               2           1     1.011731  1.463751  0.000277\n",
       "3  1               3           1    -0.540815  1.447527 -0.876644\n",
       "4  1               4           1    -0.523814  1.437933  0.906397\n",
       "5  2               0           7    -0.040426  1.024108  0.062564\n",
       "6  2               1           1     0.017257  0.012545 -0.027377\n",
       "7  2               2           1     0.915789  1.358745 -0.028758\n",
       "8  2               3           1    -0.520278  1.343532 -0.775543\n",
       "9  3               0           8    -0.034360  0.977540  0.007602"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_dtypes = {\n",
    "    'molecule_name': 'category',\n",
    "    'atom_index': 'int8',\n",
    "    'atom': 'category',\n",
    "    'x': 'float32',\n",
    "    'y': 'float32',\n",
    "    'z': 'float32'\n",
    "}\n",
    "structures_csv = pd.read_csv(f'{DATA_PATH}\\\\structures.csv', dtype=structures_dtypes)\n",
    "structures_csv['molecule_index'] = structures_csv.molecule_name.str.replace('dsgdb9nsd_', '').astype('int32')\n",
    "structures_csv = structures_csv[['molecule_index', 'atom_index', 'atom', 'x', 'y', 'z']]\n",
    "structures_csv['atom'] = structures_csv['atom'].replace(ATOMIC_NUMBERS).astype('int8')\n",
    "structures_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (2358657, 6)\n",
      "Total:  42455906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index             80     \n",
       "molecule_index    9434628\n",
       "atom_index        2358657\n",
       "atom              2358657\n",
       "x                 9434628\n",
       "y                 9434628\n",
       "z                 9434628\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Shape: ', structures_csv.shape)\n",
    "print('Total: ', structures_csv.memory_usage().sum())\n",
    "structures_csv.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Distance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_type_dataframes(base, structures, coupling_type):\n",
    "    base = base[base['type'] == coupling_type].drop('type', axis=1).copy()\n",
    "    base = base.reset_index()\n",
    "    base['id'] = base['id'].astype('int32')\n",
    "    structures = structures[structures['molecule_index'].isin(base['molecule_index'])]\n",
    "    return base, structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_coordinates(base, structures, index):\n",
    "    df = pd.merge(base, structures, how='inner',\n",
    "                  left_on=['molecule_index', f'atom_index_{index}'],\n",
    "                  right_on=['molecule_index', 'atom_index']).drop(['atom_index'], axis=1)\n",
    "    df = df.rename(columns={\n",
    "        'atom': f'atom_{index}',\n",
    "        'x': f'x_{index}',\n",
    "        'y': f'y_{index}',\n",
    "        'z': f'z_{index}'\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_all_atoms(base, structures):\n",
    "    df = pd.merge(base, structures, how='left',\n",
    "                  left_on=['molecule_index'],\n",
    "                  right_on=['molecule_index'])\n",
    "    df = df[(df.atom_index_0 != df.atom_index) & (df.atom_index_1 != df.atom_index)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_center(df):\n",
    "    df['x_c'] = ((df['x_1'] + df['x_0']) * np.float32(0.5))\n",
    "    df['y_c'] = ((df['y_1'] + df['y_0']) * np.float32(0.5))\n",
    "    df['z_c'] = ((df['z_1'] + df['z_0']) * np.float32(0.5))\n",
    "\n",
    "\n",
    "\n",
    "def add_distance_between(df, suffix1, suffix2):\n",
    "    df[f'd_{suffix1}_{suffix2}'] = ((\n",
    "        (df[f'x_{suffix1}'] - df[f'x_{suffix2}'])**np.float32(2) +\n",
    "        (df[f'y_{suffix1}'] - df[f'y_{suffix2}'])**np.float32(2) + \n",
    "        (df[f'z_{suffix1}'] - df[f'z_{suffix2}'])**np.float32(2)\n",
    "    )**np.float32(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distances(df):\n",
    "    n_atoms = 1 + max([int(c.split('_')[1]) for c in df.columns if c.startswith('x_')])\n",
    "    \n",
    "    for i in range(1, n_atoms):\n",
    "        for vi in range(min(4, i)):\n",
    "            add_distance_between(df, i, vi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_n_atoms(base, structures):\n",
    "    dfs = structures['molecule_index'].value_counts().rename('n_atoms').to_frame()\n",
    "    return pd.merge(base, dfs, left_on='molecule_index', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_couple_dataframeOld(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    \n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in some_csv:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "        \n",
    "    add_center(atoms)\n",
    "    \n",
    "    \n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "    \n",
    "    add_distance_to_center(atoms)\n",
    "    \n",
    "    atoms = atoms.drop(['x_c', 'y_c', 'z_c', 'atom_index'], axis=1)\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "\n",
    "    atoms = atoms.set_index(['molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "    \n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    full = add_atoms(base, atoms)\n",
    "    add_distances(full)\n",
    "    \n",
    "    full.sort_values('id', inplace=True)\n",
    "    \n",
    "    return full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(n_atoms):\n",
    "        num = min(i, 4) if i < four_start else 4\n",
    "        for j in range(num):\n",
    "            labels.append(f'd_{i}_{j}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    output = df[labels]\n",
    "    atoms_names = list([col for col in output if col.startswith('atom_')])[2:]\n",
    "    output = output.drop(atoms_names, axis=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_atom_info(df, atom_idx):\n",
    "    structures = structures_csv[['molecule_index', 'atom_index', 'atom']]\n",
    "    structures = structures_csv\n",
    "    df = pd.merge(df, structures, how = 'left',\n",
    "                  left_on  = ['molecule_index', f'atom_index_{atom_idx}'],\n",
    "                  right_on = ['molecule_index',  'atom_index'])\n",
    "    df = df.rename(columns={'atom': f'atom_{atom_idx}'});\n",
    "    #df = df.drop('atom_index', axis=1)    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Проверяем, что для каждого типа молекулы только  atom_1 принимает только одно значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1JHC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1JHN</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2JHC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2JHH</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2JHN</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3JHC</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3JHH</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3JHN</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      atom_1\n",
       "type        \n",
       "1JHC  6     \n",
       "1JHN  7     \n",
       "2JHC  6     \n",
       "2JHH  1     \n",
       "2JHN  7     \n",
       "3JHC  6     \n",
       "3JHH  1     \n",
       "3JHN  7     "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invest0 = map_atom_info(train_csv, 1)\n",
    "invest0 = invest0[['type','atom_1']]\n",
    "invest0.groupby(['type']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Regressions for a simple type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_atoms(base, atoms):\n",
    "    df = pd.merge(base, atoms, how='inner',\n",
    "                  on=['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    return df\n",
    "\n",
    "\n",
    "def build_atoms(base_from, structures_from, n_atoms):\n",
    "    base = base_from\n",
    "    structures = structures_from\n",
    "\n",
    "    atoms = base.drop('id', axis=1).copy()\n",
    "    if 'scalar_coupling_constant' in atoms:\n",
    "        atoms = atoms.drop(['scalar_coupling_constant'], axis=1)\n",
    "\n",
    "    add_center(atoms)\n",
    "\n",
    "    atoms = merge_all_atoms(atoms, structures)\n",
    "        \n",
    "    add_distance_to_center(atoms)\n",
    "\n",
    "    atoms.sort_values(['molecule_index', 'atom_index_0', 'atom_index_1', 'd_c'], inplace=True)\n",
    "    atom_groups = atoms.groupby(['molecule_index', 'atom_index_0', 'atom_index_1'])\n",
    "    atoms['num'] = atom_groups.cumcount() + 2\n",
    "    atoms = atoms.drop(['d_c'], axis=1)\n",
    "    atoms = atoms[atoms['num'] < n_atoms]\n",
    "    \n",
    "    atoms = atoms.drop(['x_0', 'y_0', 'z_0', 'x_1', 'y_1', 'z_1'], axis=1)\n",
    "    atoms = atoms.drop(['atom_index'], axis=1)\n",
    "    atoms = atoms.set_index(['x_c', 'y_c', 'z_c', \n",
    "        'molecule_index', 'atom_index_0', 'atom_index_1', 'num']).unstack()\n",
    "    atoms.columns = [f'{col[0]}_{col[1]}' for col in atoms.columns]\n",
    "    atoms = atoms.reset_index()\n",
    "\n",
    "    # downcast back to int8\n",
    "    for col in atoms.columns:\n",
    "        if col.startswith('atom_'):\n",
    "            atoms[col] = atoms[col].fillna(0).astype('int8')\n",
    "            \n",
    "    atoms['molecule_index'] = atoms['molecule_index'].astype('int32')\n",
    "    \n",
    "    return atoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_to_center(df):\n",
    "    df['d_c'] = ((\n",
    "        ( df['x'] -  df['x_c'])**np.float32(2) +\n",
    "        ( df['y'] -  df['y_c'])**np.float32(2) + \n",
    "        ( df['z'] -  df['z_c'])**np.float32(2)\n",
    "    )**np.float32(0.5))\n",
    "    \n",
    "\n",
    "def cross_prod(v1, v2):\n",
    "    outp0 = v1[1] * v2[2] - v1[2] * v2[1]\n",
    "    outp1 = v1[2] * v2[0] - v1[0] * v2[2]\n",
    "    outp2 = v1[0] * v2[1] - v1[1] * v2[0]\n",
    "    outp = pd.concat([outp0, outp1,outp2], axis=1)\n",
    "    return outp\n",
    "\n",
    "\n",
    "def add_axis_x(df):\n",
    "    n_x = df.x_0 - df.x_c\n",
    "    n_y = df.y_0 - df.y_c\n",
    "    n_z = df.z_0 - df.z_c\n",
    "    axisFrame = pd.concat([n_x, n_y, n_z], axis=1)\n",
    "    axisNorm = np.sqrt(np.square(axisFrame).sum(axis=1))\n",
    "    df['ax_x'] = axisFrame[0] / axisNorm\n",
    "    df['ax_y'] = axisFrame[1] / axisNorm\n",
    "    df['ax_z'] = axisFrame[2] / axisNorm\n",
    "\n",
    "\n",
    "def add_axis_y(df):\n",
    "    r_vec = pd.concat([df.x_2 - df.x_c, \n",
    "                 df.y_2 - df.y_c,\n",
    "                 df.z_2 - df.z_c], axis=1)\n",
    "    axis_vec = pd.concat([df['ax_x'], \n",
    "                          df['ax_y'], \n",
    "                          df['ax_z']], axis=1)\n",
    "    axis_vec.columns = [0, 1, 2]\n",
    "    dist =  axis_vec[0] * r_vec[0] + axis_vec[1] * r_vec[1] + axis_vec[2] * r_vec[2]\n",
    "    yDir = r_vec - axis_vec.multiply(dist, axis=\"index\")\n",
    "    yDirNorm = np.sqrt(np.square(yDir).sum(axis=1))\n",
    "    df['ay_x'] = yDir[0] / yDirNorm\n",
    "    df['ay_y'] = yDir[1] / yDirNorm\n",
    "    df['ay_z'] = yDir[2] / yDirNorm    \n",
    "\n",
    "def add_axis_z(df):    \n",
    "    r_vec = pd.concat([df.x_2 - df.x_c, \n",
    "         df.y_2 - df.y_c,\n",
    "         df.z_2 - df.z_c], axis=1)\n",
    "    axis_x_vec = pd.concat([df['ax_x'], \n",
    "                      df['ax_y'], \n",
    "                      df['ax_z']], axis=1)\n",
    "    axis_x_vec.columns = [0, 1, 2]\n",
    "    axis_y_vec = pd.concat([df['ay_x'], \n",
    "                      df['ay_y'], \n",
    "                      df['ay_z']], axis=1)\n",
    "    axis_y_vec.columns = [0, 1, 2]\n",
    "    axis_z_vec = cross_prod(axis_x_vec, axis_y_vec)\n",
    "    df['az_x'] = axis_z_vec[0] \n",
    "    df['az_y'] = axis_z_vec[1] \n",
    "    df['az_z'] = axis_z_vec[2] \n",
    "\n",
    "\n",
    "    \n",
    "#add coordinates in frame ax,ay,az\n",
    "def add_r_per_atom(df, suffix):\n",
    "    x_loc = df[f'x_{suffix}'] - df.x_c\n",
    "    y_loc = df[f'y_{suffix}'] - df.y_c\n",
    "    z_loc = df[f'z_{suffix}'] - df.z_c\n",
    "    r_x =  df['ax_x'] * x_loc + df['ax_y'] * y_loc + df['ax_z'] * z_loc\n",
    "    r_y =  df['ay_x'] * x_loc + df['ay_y'] * y_loc + df['ay_z'] * z_loc\n",
    "    r_z =  df['az_x'] * x_loc + df['az_y'] * y_loc + df['az_z'] * z_loc\n",
    "    df[f'r_x_{suffix}'] = r_x\n",
    "    df[f'r_y_{suffix}'] = r_y\n",
    "    df[f'r_z_{suffix}'] = r_z\n",
    "            \n",
    "def add_r(df):    \n",
    "    n_atoms = len([col for col in df if col.startswith('x_')]) - 1\n",
    "    for i in range(1, n_atoms):\n",
    "            add_r_per_atom(df, i)\n",
    "            \n",
    "def build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=10):\n",
    "    base, structures = build_type_dataframes(some_csv, structures_csv, coupling_type)\n",
    "    base = add_coordinates(base, structures, 0)\n",
    "    base = add_coordinates(base, structures, 1)\n",
    "    base = base.drop(['atom_0', 'atom_1'], axis=1)\n",
    "    \n",
    "    atoms = build_atoms(base, structures, n_atoms)\n",
    "    df = add_atoms(base, atoms)\n",
    "    \n",
    "    add_axis_x(df)\n",
    "    add_axis_y(df)\n",
    "    add_axis_z(df)\n",
    "    add_r(df)\n",
    "\n",
    "    df.sort_values('id', inplace=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 116 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>z_c</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>z_8</th>\n",
       "      <th>z_9</th>\n",
       "      <th>ax_x</th>\n",
       "      <th>ax_y</th>\n",
       "      <th>ax_z</th>\n",
       "      <th>ay_x</th>\n",
       "      <th>ay_y</th>\n",
       "      <th>ay_z</th>\n",
       "      <th>az_x</th>\n",
       "      <th>az_y</th>\n",
       "      <th>az_z</th>\n",
       "      <th>r_x_1</th>\n",
       "      <th>r_y_1</th>\n",
       "      <th>r_z_1</th>\n",
       "      <th>r_x_2</th>\n",
       "      <th>r_y_2</th>\n",
       "      <th>r_z_2</th>\n",
       "      <th>r_x_3</th>\n",
       "      <th>r_y_3</th>\n",
       "      <th>r_z_3</th>\n",
       "      <th>r_x_4</th>\n",
       "      <th>r_y_4</th>\n",
       "      <th>r_z_4</th>\n",
       "      <th>r_x_5</th>\n",
       "      <th>r_y_5</th>\n",
       "      <th>r_z_5</th>\n",
       "      <th>r_x_6</th>\n",
       "      <th>r_y_6</th>\n",
       "      <th>r_z_6</th>\n",
       "      <th>r_x_7</th>\n",
       "      <th>r_y_7</th>\n",
       "      <th>r_z_7</th>\n",
       "      <th>r_x_8</th>\n",
       "      <th>r_y_8</th>\n",
       "      <th>r_z_8</th>\n",
       "      <th>r_x_9</th>\n",
       "      <th>r_y_9</th>\n",
       "      <th>r_z_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1567330</td>\n",
       "      <td>50893</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>140.645004</td>\n",
       "      <td>0.634779</td>\n",
       "      <td>-0.462826</td>\n",
       "      <td>-0.739286</td>\n",
       "      <td>-0.13381</td>\n",
       "      <td>0.038041</td>\n",
       "      <td>-0.150691</td>\n",
       "      <td>0.250485</td>\n",
       "      <td>-0.212392</td>\n",
       "      <td>-0.444989</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.256479</td>\n",
       "      <td>-1.090539</td>\n",
       "      <td>0.509465</td>\n",
       "      <td>-0.941471</td>\n",
       "      <td>-0.039216</td>\n",
       "      <td>-1.970939</td>\n",
       "      <td>-2.699512</td>\n",
       "      <td>-1.220216</td>\n",
       "      <td>1.252988</td>\n",
       "      <td>-0.831051</td>\n",
       "      <td>1.787187</td>\n",
       "      <td>-2.158229</td>\n",
       "      <td>-2.629475</td>\n",
       "      <td>-2.850358</td>\n",
       "      <td>-2.328591</td>\n",
       "      <td>-4.609975</td>\n",
       "      <td>0.143031</td>\n",
       "      <td>0.318055</td>\n",
       "      <td>-0.264027</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>-0.643397</td>\n",
       "      <td>0.563172</td>\n",
       "      <td>1.023855</td>\n",
       "      <td>-0.17948</td>\n",
       "      <td>0.705145</td>\n",
       "      <td>-0.459522</td>\n",
       "      <td>-0.540008</td>\n",
       "      <td>0.459768</td>\n",
       "      <td>0.876096</td>\n",
       "      <td>-0.14515</td>\n",
       "      <td>0.539799</td>\n",
       "      <td>-0.145927</td>\n",
       "      <td>0.829049</td>\n",
       "      <td>-0.544986</td>\n",
       "      <td>8.690331e-09</td>\n",
       "      <td>-1.344103e-08</td>\n",
       "      <td>-1.348394</td>\n",
       "      <td>0.965377</td>\n",
       "      <td>1.665335e-16</td>\n",
       "      <td>-1.073379</td>\n",
       "      <td>-1.269321</td>\n",
       "      <td>-0.001004</td>\n",
       "      <td>-0.833953</td>\n",
       "      <td>1.844628</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.188789</td>\n",
       "      <td>-2.31793</td>\n",
       "      <td>0.012743</td>\n",
       "      <td>1.013565</td>\n",
       "      <td>-2.221993</td>\n",
       "      <td>0.031846</td>\n",
       "      <td>-0.898638</td>\n",
       "      <td>-3.478787</td>\n",
       "      <td>0.021642</td>\n",
       "      <td>-1.900923</td>\n",
       "      <td>-3.423511</td>\n",
       "      <td>-0.065852</td>\n",
       "      <td>0.840353</td>\n",
       "      <td>-4.567426</td>\n",
       "      <td>0.067962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  molecule_index  atom_index_0  atom_index_1  \\\n",
       "0  1567330  50893           10            1              \n",
       "\n",
       "   scalar_coupling_constant       x_0       y_0       z_0      x_1       y_1  \\\n",
       "0  140.645004                0.634779 -0.462826 -0.739286 -0.13381  0.038041   \n",
       "\n",
       "        z_1       x_c       y_c       z_c  atom_2  atom_3  atom_4  atom_5  \\\n",
       "0 -0.150691  0.250485 -0.212392 -0.444989  7       8       1       6        \n",
       "\n",
       "   atom_6  atom_7  atom_8  atom_9       x_2       x_3       x_4       x_5  \\\n",
       "0  8       7       1       1      -0.256479 -1.090539  0.509465 -0.941471   \n",
       "\n",
       "        x_6       x_7       x_8       x_9       y_2       y_3       y_4  \\\n",
       "0 -0.039216 -1.970939 -2.699512 -1.220216  1.252988 -0.831051  1.787187   \n",
       "\n",
       "        y_5       y_6       y_7       y_8       y_9       z_2       z_3  \\\n",
       "0 -2.158229 -2.629475 -2.850358 -2.328591 -4.609975  0.143031  0.318055   \n",
       "\n",
       "        z_4       z_5       z_6       z_7       z_8      z_9      ax_x  \\\n",
       "0 -0.264027  0.003972 -0.643397  0.563172  1.023855 -0.17948  0.705145   \n",
       "\n",
       "       ax_y      ax_z      ay_x      ay_y     ay_z      az_x      az_y  \\\n",
       "0 -0.459522 -0.540008  0.459768  0.876096 -0.14515  0.539799 -0.145927   \n",
       "\n",
       "       az_z     r_x_1         r_y_1         r_z_1     r_x_2     r_y_2  \\\n",
       "0  0.829049 -0.544986  8.690331e-09 -1.344103e-08 -1.348394  0.965377   \n",
       "\n",
       "          r_z_2     r_x_3     r_y_3     r_z_3     r_x_4     r_y_4     r_z_4  \\\n",
       "0  1.665335e-16 -1.073379 -1.269321 -0.001004 -0.833953  1.844628 -0.001969   \n",
       "\n",
       "      r_x_5    r_y_5     r_z_5     r_x_6     r_y_6     r_z_6     r_x_7  \\\n",
       "0 -0.188789 -2.31793  0.012743  1.013565 -2.221993  0.031846 -0.898638   \n",
       "\n",
       "      r_y_7     r_z_7     r_x_8     r_y_8     r_z_8     r_x_9     r_y_9  \\\n",
       "0 -3.478787  0.021642 -1.900923 -3.423511 -0.065852  0.840353 -4.567426   \n",
       "\n",
       "      r_z_9  \n",
       "0  0.067962  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "molecule_index = 50893\n",
    "some_csv = train_csv[train_csv.molecule_index == molecule_index]\n",
    "#some_csv = train_csv #[:6000]\n",
    "coupling_type = '1JHC'\n",
    "n_atoms = 10\n",
    "full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.19 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>molecule_index</th>\n",
       "      <th>atom_index_0</th>\n",
       "      <th>atom_index_1</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>z_0</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_c</th>\n",
       "      <th>y_c</th>\n",
       "      <th>z_c</th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>x_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>x_6</th>\n",
       "      <th>x_7</th>\n",
       "      <th>x_8</th>\n",
       "      <th>x_9</th>\n",
       "      <th>y_2</th>\n",
       "      <th>y_3</th>\n",
       "      <th>y_4</th>\n",
       "      <th>y_5</th>\n",
       "      <th>y_6</th>\n",
       "      <th>y_7</th>\n",
       "      <th>y_8</th>\n",
       "      <th>y_9</th>\n",
       "      <th>z_2</th>\n",
       "      <th>z_3</th>\n",
       "      <th>z_4</th>\n",
       "      <th>z_5</th>\n",
       "      <th>z_6</th>\n",
       "      <th>z_7</th>\n",
       "      <th>z_8</th>\n",
       "      <th>z_9</th>\n",
       "      <th>ax_x</th>\n",
       "      <th>ax_y</th>\n",
       "      <th>ax_z</th>\n",
       "      <th>ay_x</th>\n",
       "      <th>ay_y</th>\n",
       "      <th>ay_z</th>\n",
       "      <th>az_x</th>\n",
       "      <th>az_y</th>\n",
       "      <th>az_z</th>\n",
       "      <th>r_x_1</th>\n",
       "      <th>r_y_1</th>\n",
       "      <th>r_z_1</th>\n",
       "      <th>r_x_2</th>\n",
       "      <th>r_y_2</th>\n",
       "      <th>r_z_2</th>\n",
       "      <th>r_x_3</th>\n",
       "      <th>r_y_3</th>\n",
       "      <th>r_z_3</th>\n",
       "      <th>r_x_4</th>\n",
       "      <th>r_y_4</th>\n",
       "      <th>r_z_4</th>\n",
       "      <th>r_x_5</th>\n",
       "      <th>r_y_5</th>\n",
       "      <th>r_z_5</th>\n",
       "      <th>r_x_6</th>\n",
       "      <th>r_y_6</th>\n",
       "      <th>r_z_6</th>\n",
       "      <th>r_x_7</th>\n",
       "      <th>r_y_7</th>\n",
       "      <th>r_z_7</th>\n",
       "      <th>r_x_8</th>\n",
       "      <th>r_y_8</th>\n",
       "      <th>r_z_8</th>\n",
       "      <th>r_x_9</th>\n",
       "      <th>r_y_9</th>\n",
       "      <th>r_z_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32662</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>84.807404</td>\n",
       "      <td>1.011731</td>\n",
       "      <td>1.463751</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.012698</td>\n",
       "      <td>1.085804</td>\n",
       "      <td>0.008001</td>\n",
       "      <td>0.499516</td>\n",
       "      <td>1.274778</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>-0.523814</td>\n",
       "      <td>-0.540815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006031</td>\n",
       "      <td>1.437933</td>\n",
       "      <td>1.447527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.906397</td>\n",
       "      <td>-0.876644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938163</td>\n",
       "      <td>0.346121</td>\n",
       "      <td>-0.007074</td>\n",
       "      <td>0.346062</td>\n",
       "      <td>-0.938175</td>\n",
       "      <td>-0.008353</td>\n",
       "      <td>-0.009528</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>-0.999940</td>\n",
       "      <td>-0.545976</td>\n",
       "      <td>-7.734600e-09</td>\n",
       "      <td>2.711641e-10</td>\n",
       "      <td>-0.909910</td>\n",
       "      <td>1.029521</td>\n",
       "      <td>-4.336809e-19</td>\n",
       "      <td>-0.909962</td>\n",
       "      <td>-0.514740</td>\n",
       "      <td>-0.891575</td>\n",
       "      <td>-0.909978</td>\n",
       "      <td>-0.514731</td>\n",
       "      <td>0.891572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18352</th>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>83.548599</td>\n",
       "      <td>0.508626</td>\n",
       "      <td>-0.392470</td>\n",
       "      <td>-0.887601</td>\n",
       "      <td>0.002104</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.255365</td>\n",
       "      <td>-0.198176</td>\n",
       "      <td>-0.442801</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.525487</td>\n",
       "      <td>-1.011477</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>-0.542076</td>\n",
       "      <td>0.994873</td>\n",
       "      <td>-0.525241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.401908</td>\n",
       "      <td>-0.418034</td>\n",
       "      <td>1.525582</td>\n",
       "      <td>1.923611</td>\n",
       "      <td>1.939743</td>\n",
       "      <td>1.914173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.877544</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>-0.865117</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.900024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462591</td>\n",
       "      <td>-0.354886</td>\n",
       "      <td>-0.812444</td>\n",
       "      <td>0.646219</td>\n",
       "      <td>-0.492412</td>\n",
       "      <td>0.583037</td>\n",
       "      <td>-0.606968</td>\n",
       "      <td>-0.794724</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>-0.547484</td>\n",
       "      <td>-8.922295e-09</td>\n",
       "      <td>8.086858e-09</td>\n",
       "      <td>-0.875449</td>\n",
       "      <td>1.044688</td>\n",
       "      <td>-7.068998e-17</td>\n",
       "      <td>-0.875482</td>\n",
       "      <td>-0.446683</td>\n",
       "      <td>0.944359</td>\n",
       "      <td>-1.106746</td>\n",
       "      <td>-0.761655</td>\n",
       "      <td>-1.202860</td>\n",
       "      <td>-0.778773</td>\n",
       "      <td>-1.806340</td>\n",
       "      <td>-1.202868</td>\n",
       "      <td>-0.778768</td>\n",
       "      <td>-0.314968</td>\n",
       "      <td>-2.147224</td>\n",
       "      <td>-2.201715</td>\n",
       "      <td>-0.761671</td>\n",
       "      <td>-1.202853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49151</th>\n",
       "      <td>46</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>87.632599</td>\n",
       "      <td>1.006583</td>\n",
       "      <td>1.815564</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>1.390470</td>\n",
       "      <td>-0.005601</td>\n",
       "      <td>0.499148</td>\n",
       "      <td>1.603017</td>\n",
       "      <td>-0.001059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.522889</td>\n",
       "      <td>-0.546575</td>\n",
       "      <td>-0.007970</td>\n",
       "      <td>0.441420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.725552</td>\n",
       "      <td>1.799170</td>\n",
       "      <td>-0.025045</td>\n",
       "      <td>-0.333544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.899073</td>\n",
       "      <td>-0.873901</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>-0.771521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.922324</td>\n",
       "      <td>0.386329</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>-0.195323</td>\n",
       "      <td>0.447668</td>\n",
       "      <td>0.872607</td>\n",
       "      <td>0.333418</td>\n",
       "      <td>-0.806439</td>\n",
       "      <td>0.488353</td>\n",
       "      <td>-0.550171</td>\n",
       "      <td>4.183896e-09</td>\n",
       "      <td>-7.141945e-09</td>\n",
       "      <td>-0.887878</td>\n",
       "      <td>1.039944</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.895921</td>\n",
       "      <td>-0.469584</td>\n",
       "      <td>-0.933103</td>\n",
       "      <td>-1.096518</td>\n",
       "      <td>-0.611136</td>\n",
       "      <td>1.154284</td>\n",
       "      <td>-0.807754</td>\n",
       "      <td>-1.527970</td>\n",
       "      <td>1.166213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9014</th>\n",
       "      <td>119</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>80.704697</td>\n",
       "      <td>-0.542523</td>\n",
       "      <td>1.901535</td>\n",
       "      <td>0.930057</td>\n",
       "      <td>-0.031138</td>\n",
       "      <td>1.540816</td>\n",
       "      <td>0.031921</td>\n",
       "      <td>-0.286830</td>\n",
       "      <td>1.721176</td>\n",
       "      <td>0.480989</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.558402</td>\n",
       "      <td>0.979560</td>\n",
       "      <td>0.012153</td>\n",
       "      <td>-1.010706</td>\n",
       "      <td>0.515228</td>\n",
       "      <td>0.721691</td>\n",
       "      <td>1.758512</td>\n",
       "      <td>0.220234</td>\n",
       "      <td>1.948312</td>\n",
       "      <td>1.964591</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>-0.384570</td>\n",
       "      <td>-0.368402</td>\n",
       "      <td>-0.525834</td>\n",
       "      <td>-0.173766</td>\n",
       "      <td>-0.190512</td>\n",
       "      <td>-0.838161</td>\n",
       "      <td>0.030984</td>\n",
       "      <td>-0.016033</td>\n",
       "      <td>0.020518</td>\n",
       "      <td>0.882311</td>\n",
       "      <td>-1.262306</td>\n",
       "      <td>-1.308715</td>\n",
       "      <td>-2.17729</td>\n",
       "      <td>-0.467163</td>\n",
       "      <td>0.329527</td>\n",
       "      <td>0.820470</td>\n",
       "      <td>-0.654147</td>\n",
       "      <td>0.495496</td>\n",
       "      <td>-0.571468</td>\n",
       "      <td>-0.594853</td>\n",
       "      <td>-0.803677</td>\n",
       "      <td>-0.015918</td>\n",
       "      <td>-0.547330</td>\n",
       "      <td>1.247887e-08</td>\n",
       "      <td>5.717906e-09</td>\n",
       "      <td>-0.880607</td>\n",
       "      <td>1.044045</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-0.880614</td>\n",
       "      <td>-0.450630</td>\n",
       "      <td>-0.941781</td>\n",
       "      <td>-1.111039</td>\n",
       "      <td>-0.758971</td>\n",
       "      <td>1.204551</td>\n",
       "      <td>-0.733534</td>\n",
       "      <td>-0.306722</td>\n",
       "      <td>2.130268</td>\n",
       "      <td>-0.733990</td>\n",
       "      <td>-1.789384</td>\n",
       "      <td>1.195849</td>\n",
       "      <td>-2.641914</td>\n",
       "      <td>-0.776868</td>\n",
       "      <td>1.233697</td>\n",
       "      <td>-3.04834</td>\n",
       "      <td>-1.254132</td>\n",
       "      <td>0.33473</td>\n",
       "      <td>-3.047872</td>\n",
       "      <td>0.240194</td>\n",
       "      <td>1.277065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32039</th>\n",
       "      <td>293</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>201.884003</td>\n",
       "      <td>2.949600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.887666</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.418633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.680980</td>\n",
       "      <td>-0.680980</td>\n",
       "      <td>-1.887666</td>\n",
       "      <td>-2.949600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.530967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.737653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.099613</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.306299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.368233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  molecule_index  atom_index_0  atom_index_1  \\\n",
       "32662  4    1               2             0              \n",
       "18352  45   7               7             1              \n",
       "49151  46   8               2             0              \n",
       "9014   119  13              5             0              \n",
       "32039  293  23              5             3              \n",
       "\n",
       "       scalar_coupling_constant       x_0       y_0       z_0       x_1  \\\n",
       "32662  84.807404                 1.011731  1.463751  0.000277 -0.012698   \n",
       "18352  83.548599                 0.508626 -0.392470 -0.887601  0.002104   \n",
       "49151  87.632599                 1.006583  1.815564  0.003483 -0.008288   \n",
       "9014   80.704697                -0.542523  1.901535  0.930057 -0.031138   \n",
       "32039  201.884003                2.949600  0.000000  0.000000  1.887666   \n",
       "\n",
       "            y_1       z_1       x_c       y_c       z_c  atom_2  atom_3  \\\n",
       "32662  1.085804  0.008001  0.499516  1.274778  0.004139  1       1        \n",
       "18352 -0.003882  0.001999  0.255365 -0.198176 -0.442801  1       1        \n",
       "49151  1.390470 -0.005601  0.499148  1.603017 -0.001059  1       1        \n",
       "9014   1.540816  0.031921 -0.286830  1.721176  0.480989  1       1        \n",
       "32039  0.000000  0.000000  2.418633  0.000000  0.000000  6       6        \n",
       "\n",
       "       atom_4  atom_5  atom_6  atom_7  atom_8  atom_9       x_2       x_3  \\\n",
       "32662  1       0       0       0       0       0       0.002150 -0.523814   \n",
       "18352  6       1       1       1       0       0       0.525487 -1.011477   \n",
       "49151  8       1       0       0       0       0      -0.522889 -0.546575   \n",
       "9014   6       1       1       6       1       1      -0.558402  0.979560   \n",
       "32039  6       1       0       0       0       0       0.680980 -0.680980   \n",
       "\n",
       "            x_4       x_5       x_6       x_7       x_8       x_9       y_2  \\\n",
       "32662 -0.540815 NaN       NaN       NaN       NaN       NaN       -0.006031   \n",
       "18352 -0.018704 -0.542076  0.994873 -0.525241 NaN       NaN       -0.401908   \n",
       "49151 -0.007970  0.441420 NaN       NaN       NaN       NaN        1.725552   \n",
       "9014   0.012153 -1.010706  0.515228  0.721691  1.758512  0.220234  1.948312   \n",
       "32039 -1.887666 -2.949600 NaN       NaN       NaN       NaN        0.000000   \n",
       "\n",
       "            y_3       y_4       y_5       y_6       y_7       y_8       y_9  \\\n",
       "32662  1.437933  1.447527 NaN       NaN       NaN       NaN       NaN         \n",
       "18352 -0.418034  1.525582  1.923611  1.939743  1.914173 NaN       NaN         \n",
       "49151  1.799170 -0.025045 -0.333544 NaN       NaN       NaN       NaN         \n",
       "9014   1.964591  0.010922 -0.384570 -0.368402 -0.525834 -0.173766 -0.190512   \n",
       "32039  0.000000  0.000000  0.000000 NaN       NaN       NaN       NaN         \n",
       "\n",
       "            z_2       z_3       z_4       z_5       z_6       z_7       z_8  \\\n",
       "32662  0.001976  0.906397 -0.876644 NaN       NaN       NaN       NaN         \n",
       "18352  0.877544  0.009508  0.010433 -0.865117  0.002941  0.900024 NaN         \n",
       "49151  0.899073 -0.873901  0.020306 -0.771521 NaN       NaN       NaN         \n",
       "9014  -0.838161  0.030984 -0.016033  0.020518  0.882311 -1.262306 -1.308715   \n",
       "32039  0.000000  0.000000  0.000000  0.000000 NaN       NaN       NaN         \n",
       "\n",
       "           z_9      ax_x      ax_y      ax_z      ay_x      ay_y      ay_z  \\\n",
       "32662 NaN       0.938163  0.346121 -0.007074  0.346062 -0.938175 -0.008353   \n",
       "18352 NaN       0.462591 -0.354886 -0.812444  0.646219 -0.492412  0.583037   \n",
       "49151 NaN       0.922324  0.386329  0.008256 -0.195323  0.447668  0.872607   \n",
       "9014  -2.17729 -0.467163  0.329527  0.820470 -0.654147  0.495496 -0.571468   \n",
       "32039 NaN       1.000000  0.000000  0.000000 NaN       NaN       NaN         \n",
       "\n",
       "           az_x      az_y      az_z     r_x_1         r_y_1         r_z_1  \\\n",
       "32662 -0.009528  0.005388 -0.999940 -0.545976 -7.734600e-09  2.711641e-10   \n",
       "18352 -0.606968 -0.794724  0.001549 -0.547484 -8.922295e-09  8.086858e-09   \n",
       "49151  0.333418 -0.806439  0.488353 -0.550171  4.183896e-09 -7.141945e-09   \n",
       "9014  -0.594853 -0.803677 -0.015918 -0.547330  1.247887e-08  5.717906e-09   \n",
       "32039 NaN       NaN       NaN       -0.530967 NaN           NaN             \n",
       "\n",
       "          r_x_2     r_y_2         r_z_2     r_x_3     r_y_3     r_z_3  \\\n",
       "32662 -0.909910  1.029521 -4.336809e-19 -0.909962 -0.514740 -0.891575   \n",
       "18352 -0.875449  1.044688 -7.068998e-17 -0.875482 -0.446683  0.944359   \n",
       "49151 -0.887878  1.039944  0.000000e+00 -0.895921 -0.469584 -0.933103   \n",
       "9014  -0.880607  1.044045  0.000000e+00 -0.880614 -0.450630 -0.941781   \n",
       "32039 -1.737653 NaN       NaN           -3.099613 NaN       NaN         \n",
       "\n",
       "          r_x_4     r_y_4     r_z_4     r_x_5     r_y_5     r_z_5     r_x_6  \\\n",
       "32662 -0.909978 -0.514731  0.891572 NaN       NaN       NaN       NaN         \n",
       "18352 -1.106746 -0.761655 -1.202860 -0.778773 -1.806340 -1.202868 -0.778768   \n",
       "49151 -1.096518 -0.611136  1.154284 -0.807754 -1.527970  1.166213 NaN         \n",
       "9014  -1.111039 -0.758971  1.204551 -0.733534 -0.306722  2.130268 -0.733990   \n",
       "32039 -4.306299 NaN       NaN       -5.368233 NaN       NaN       NaN         \n",
       "\n",
       "          r_y_6     r_z_6     r_x_7     r_y_7     r_z_7    r_x_8     r_y_8  \\\n",
       "32662 NaN       NaN       NaN       NaN       NaN       NaN      NaN         \n",
       "18352 -0.314968 -2.147224 -2.201715 -0.761671 -1.202853 NaN      NaN         \n",
       "49151 NaN       NaN       NaN       NaN       NaN       NaN      NaN         \n",
       "9014  -1.789384  1.195849 -2.641914 -0.776868  1.233697 -3.04834 -1.254132   \n",
       "32039 NaN       NaN       NaN       NaN       NaN       NaN      NaN         \n",
       "\n",
       "         r_z_8     r_x_9     r_y_9     r_z_9  \n",
       "32662 NaN      NaN       NaN       NaN        \n",
       "18352 NaN      NaN       NaN       NaN        \n",
       "49151 NaN      NaN       NaN       NaN        \n",
       "9014   0.33473 -3.047872  0.240194  1.277065  \n",
       "32039 NaN      NaN       NaN       NaN        "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "coupling_type = '1JHC'\n",
    "full = build_couple_dataframe(train_csv, structures_csv, coupling_type, n_atoms=10)\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_n_atoms(df, n_atoms, four_start=4):\n",
    "    labels = []\n",
    "    for i in range(2, n_atoms):\n",
    "        label = f'atom_{i}'\n",
    "        labels.append(label)\n",
    "\n",
    "    for i in range(1, n_atoms):\n",
    "        labels.append(f'r_x_{i}')\n",
    "    for i in range(2, n_atoms):\n",
    "        labels.append(f'r_y_{i}')\n",
    "    for i in range(3, n_atoms):\n",
    "        labels.append(f'r_z_{i}')\n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        labels.append('scalar_coupling_constant')\n",
    "    output = df[labels]\n",
    "    #atoms_names = list([col for col in output if col.startswith('atom_')])[2:]\n",
    "    #output = output.drop(atoms_names, axis=1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_all =  pd.read_csv(f'{INPUT_ADDED}/{coupling_type}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atom_2</th>\n",
       "      <th>atom_3</th>\n",
       "      <th>atom_4</th>\n",
       "      <th>atom_5</th>\n",
       "      <th>atom_6</th>\n",
       "      <th>atom_7</th>\n",
       "      <th>atom_8</th>\n",
       "      <th>atom_9</th>\n",
       "      <th>atom_10</th>\n",
       "      <th>atom_11</th>\n",
       "      <th>atom_12</th>\n",
       "      <th>atom_13</th>\n",
       "      <th>atom_14</th>\n",
       "      <th>r_x_1</th>\n",
       "      <th>r_x_2</th>\n",
       "      <th>r_x_3</th>\n",
       "      <th>r_x_4</th>\n",
       "      <th>r_x_5</th>\n",
       "      <th>r_x_6</th>\n",
       "      <th>r_x_7</th>\n",
       "      <th>r_x_8</th>\n",
       "      <th>r_x_9</th>\n",
       "      <th>r_x_10</th>\n",
       "      <th>r_x_11</th>\n",
       "      <th>r_x_12</th>\n",
       "      <th>r_x_13</th>\n",
       "      <th>r_x_14</th>\n",
       "      <th>r_y_2</th>\n",
       "      <th>r_y_3</th>\n",
       "      <th>r_y_4</th>\n",
       "      <th>r_y_5</th>\n",
       "      <th>r_y_6</th>\n",
       "      <th>r_y_7</th>\n",
       "      <th>r_y_8</th>\n",
       "      <th>r_y_9</th>\n",
       "      <th>r_y_10</th>\n",
       "      <th>r_y_11</th>\n",
       "      <th>r_y_12</th>\n",
       "      <th>r_y_13</th>\n",
       "      <th>r_y_14</th>\n",
       "      <th>r_z_3</th>\n",
       "      <th>r_z_4</th>\n",
       "      <th>r_z_5</th>\n",
       "      <th>r_z_6</th>\n",
       "      <th>r_z_7</th>\n",
       "      <th>r_z_8</th>\n",
       "      <th>r_z_9</th>\n",
       "      <th>r_z_10</th>\n",
       "      <th>r_z_11</th>\n",
       "      <th>r_z_12</th>\n",
       "      <th>r_z_13</th>\n",
       "      <th>r_z_14</th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.00000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "      <td>709415.000000</td>\n",
       "      <td>709415.000000</td>\n",
       "      <td>709410.000000</td>\n",
       "      <td>709396.000000</td>\n",
       "      <td>709372.000000</td>\n",
       "      <td>709311.000000</td>\n",
       "      <td>709140.000000</td>\n",
       "      <td>708594.000000</td>\n",
       "      <td>707064.000000</td>\n",
       "      <td>703307.000000</td>\n",
       "      <td>694468.000000</td>\n",
       "      <td>675797.000000</td>\n",
       "      <td>7.094140e+05</td>\n",
       "      <td>709413.000000</td>\n",
       "      <td>709413.000000</td>\n",
       "      <td>709408.000000</td>\n",
       "      <td>709396.000000</td>\n",
       "      <td>709372.000000</td>\n",
       "      <td>709311.000000</td>\n",
       "      <td>709140.000000</td>\n",
       "      <td>708594.000000</td>\n",
       "      <td>707064.000000</td>\n",
       "      <td>703307.000000</td>\n",
       "      <td>694468.000000</td>\n",
       "      <td>675797.000000</td>\n",
       "      <td>709413.000000</td>\n",
       "      <td>709413.000000</td>\n",
       "      <td>709408.000000</td>\n",
       "      <td>7.093960e+05</td>\n",
       "      <td>709372.000000</td>\n",
       "      <td>709311.000000</td>\n",
       "      <td>709140.000000</td>\n",
       "      <td>708594.000000</td>\n",
       "      <td>707064.000000</td>\n",
       "      <td>703307.000000</td>\n",
       "      <td>694468.000000</td>\n",
       "      <td>675797.000000</td>\n",
       "      <td>709416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.571980</td>\n",
       "      <td>4.718922</td>\n",
       "      <td>5.776832</td>\n",
       "      <td>2.685567</td>\n",
       "      <td>3.561376</td>\n",
       "      <td>4.026453</td>\n",
       "      <td>4.10719</td>\n",
       "      <td>4.122326</td>\n",
       "      <td>4.002451</td>\n",
       "      <td>3.798915</td>\n",
       "      <td>3.583815</td>\n",
       "      <td>3.370508</td>\n",
       "      <td>3.067422</td>\n",
       "      <td>-0.546450</td>\n",
       "      <td>-0.979225</td>\n",
       "      <td>-1.101685</td>\n",
       "      <td>-1.150749</td>\n",
       "      <td>-0.722346</td>\n",
       "      <td>-0.889720</td>\n",
       "      <td>-1.195437</td>\n",
       "      <td>-1.361865</td>\n",
       "      <td>-1.515106</td>\n",
       "      <td>-1.628529</td>\n",
       "      <td>-1.741569</td>\n",
       "      <td>-1.856271</td>\n",
       "      <td>-1.967502</td>\n",
       "      <td>-2.055424</td>\n",
       "      <td>1.083090e+00</td>\n",
       "      <td>-0.697413</td>\n",
       "      <td>-0.728953</td>\n",
       "      <td>-1.044102</td>\n",
       "      <td>-1.044104</td>\n",
       "      <td>-0.935776</td>\n",
       "      <td>-0.905031</td>\n",
       "      <td>-0.899817</td>\n",
       "      <td>-0.900218</td>\n",
       "      <td>-0.961409</td>\n",
       "      <td>-1.075191</td>\n",
       "      <td>-1.213436</td>\n",
       "      <td>-1.324268</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>-0.004871</td>\n",
       "      <td>-0.036653</td>\n",
       "      <td>2.371743e-03</td>\n",
       "      <td>0.019784</td>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.014239</td>\n",
       "      <td>0.021524</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>0.018835</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>94.976153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.623271</td>\n",
       "      <td>2.590104</td>\n",
       "      <td>1.326641</td>\n",
       "      <td>2.572154</td>\n",
       "      <td>2.778925</td>\n",
       "      <td>2.734745</td>\n",
       "      <td>2.73514</td>\n",
       "      <td>2.738560</td>\n",
       "      <td>2.751343</td>\n",
       "      <td>2.774384</td>\n",
       "      <td>2.788014</td>\n",
       "      <td>2.792845</td>\n",
       "      <td>2.776449</td>\n",
       "      <td>0.003409</td>\n",
       "      <td>0.167632</td>\n",
       "      <td>0.288504</td>\n",
       "      <td>0.348882</td>\n",
       "      <td>0.745300</td>\n",
       "      <td>0.974305</td>\n",
       "      <td>1.118066</td>\n",
       "      <td>1.237562</td>\n",
       "      <td>1.306964</td>\n",
       "      <td>1.388093</td>\n",
       "      <td>1.456549</td>\n",
       "      <td>1.507591</td>\n",
       "      <td>1.562252</td>\n",
       "      <td>1.635915</td>\n",
       "      <td>1.735383e-01</td>\n",
       "      <td>0.338384</td>\n",
       "      <td>0.648011</td>\n",
       "      <td>1.143755</td>\n",
       "      <td>1.157626</td>\n",
       "      <td>1.197381</td>\n",
       "      <td>1.275927</td>\n",
       "      <td>1.382982</td>\n",
       "      <td>1.489190</td>\n",
       "      <td>1.595749</td>\n",
       "      <td>1.685591</td>\n",
       "      <td>1.765581</td>\n",
       "      <td>1.846532</td>\n",
       "      <td>0.991072</td>\n",
       "      <td>1.100457</td>\n",
       "      <td>1.547604</td>\n",
       "      <td>1.604829e+00</td>\n",
       "      <td>1.640480</td>\n",
       "      <td>1.707029</td>\n",
       "      <td>1.797695</td>\n",
       "      <td>1.946012</td>\n",
       "      <td>2.090539</td>\n",
       "      <td>2.236150</td>\n",
       "      <td>2.369307</td>\n",
       "      <td>2.508988</td>\n",
       "      <td>18.277237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.623971</td>\n",
       "      <td>-1.741393</td>\n",
       "      <td>-3.217345</td>\n",
       "      <td>-4.313008</td>\n",
       "      <td>-5.785330</td>\n",
       "      <td>-6.877647</td>\n",
       "      <td>-8.341340</td>\n",
       "      <td>-9.436249</td>\n",
       "      <td>-10.498619</td>\n",
       "      <td>-8.959737</td>\n",
       "      <td>-9.966637</td>\n",
       "      <td>-10.120631</td>\n",
       "      <td>-10.442879</td>\n",
       "      <td>-10.839585</td>\n",
       "      <td>1.296874e-07</td>\n",
       "      <td>-2.741247</td>\n",
       "      <td>-3.459233</td>\n",
       "      <td>-4.209876</td>\n",
       "      <td>-5.176523</td>\n",
       "      <td>-6.157640</td>\n",
       "      <td>-7.172949</td>\n",
       "      <td>-8.142640</td>\n",
       "      <td>-7.231229</td>\n",
       "      <td>-8.426347</td>\n",
       "      <td>-8.872462</td>\n",
       "      <td>-8.660447</td>\n",
       "      <td>-9.119188</td>\n",
       "      <td>-2.975889</td>\n",
       "      <td>-3.397849</td>\n",
       "      <td>-3.250526</td>\n",
       "      <td>-4.291014e+00</td>\n",
       "      <td>-4.921109</td>\n",
       "      <td>-6.307271</td>\n",
       "      <td>-6.798973</td>\n",
       "      <td>-7.330513</td>\n",
       "      <td>-8.250480</td>\n",
       "      <td>-9.006602</td>\n",
       "      <td>-9.212234</td>\n",
       "      <td>-9.301118</td>\n",
       "      <td>66.600800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.548073</td>\n",
       "      <td>-1.012368</td>\n",
       "      <td>-1.198351</td>\n",
       "      <td>-1.210536</td>\n",
       "      <td>-0.812748</td>\n",
       "      <td>-1.427922</td>\n",
       "      <td>-2.163070</td>\n",
       "      <td>-2.381790</td>\n",
       "      <td>-2.524487</td>\n",
       "      <td>-2.633375</td>\n",
       "      <td>-2.875624</td>\n",
       "      <td>-3.025711</td>\n",
       "      <td>-3.110226</td>\n",
       "      <td>-3.193569</td>\n",
       "      <td>1.036337e+00</td>\n",
       "      <td>-0.933856</td>\n",
       "      <td>-0.925234</td>\n",
       "      <td>-1.860262</td>\n",
       "      <td>-2.001435</td>\n",
       "      <td>-1.962557</td>\n",
       "      <td>-1.970145</td>\n",
       "      <td>-2.023035</td>\n",
       "      <td>-2.105782</td>\n",
       "      <td>-2.270733</td>\n",
       "      <td>-2.481364</td>\n",
       "      <td>-2.637766</td>\n",
       "      <td>-2.742671</td>\n",
       "      <td>-0.940911</td>\n",
       "      <td>-1.191681</td>\n",
       "      <td>-1.318307</td>\n",
       "      <td>-1.318267e+00</td>\n",
       "      <td>-1.323967</td>\n",
       "      <td>-1.351307</td>\n",
       "      <td>-1.374947</td>\n",
       "      <td>-1.448560</td>\n",
       "      <td>-1.604933</td>\n",
       "      <td>-1.796347</td>\n",
       "      <td>-1.921404</td>\n",
       "      <td>-2.041021</td>\n",
       "      <td>84.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.547013</td>\n",
       "      <td>-0.896096</td>\n",
       "      <td>-1.058140</td>\n",
       "      <td>-1.099114</td>\n",
       "      <td>-0.681519</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.075679</td>\n",
       "      <td>-1.435692</td>\n",
       "      <td>-1.720088</td>\n",
       "      <td>-1.883566</td>\n",
       "      <td>-1.985053</td>\n",
       "      <td>-2.074044</td>\n",
       "      <td>-2.165197</td>\n",
       "      <td>-2.255900</td>\n",
       "      <td>1.043768e+00</td>\n",
       "      <td>-0.675115</td>\n",
       "      <td>-0.748490</td>\n",
       "      <td>-1.505893</td>\n",
       "      <td>-1.303531</td>\n",
       "      <td>-0.907118</td>\n",
       "      <td>-0.868514</td>\n",
       "      <td>-0.862037</td>\n",
       "      <td>-0.870498</td>\n",
       "      <td>-0.939767</td>\n",
       "      <td>-1.129955</td>\n",
       "      <td>-1.347714</td>\n",
       "      <td>-1.495286</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.001370</td>\n",
       "      <td>3.091573e-07</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.001305</td>\n",
       "      <td>88.223650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>-0.545149</td>\n",
       "      <td>-0.878620</td>\n",
       "      <td>-0.899870</td>\n",
       "      <td>-1.067675</td>\n",
       "      <td>-0.499887</td>\n",
       "      <td>-0.466961</td>\n",
       "      <td>-0.508269</td>\n",
       "      <td>-0.520835</td>\n",
       "      <td>-0.588746</td>\n",
       "      <td>-0.636282</td>\n",
       "      <td>-0.746931</td>\n",
       "      <td>-0.845237</td>\n",
       "      <td>-0.917255</td>\n",
       "      <td>-0.957479</td>\n",
       "      <td>1.057164e+00</td>\n",
       "      <td>-0.474206</td>\n",
       "      <td>-0.698513</td>\n",
       "      <td>-0.269260</td>\n",
       "      <td>-0.229039</td>\n",
       "      <td>-0.207843</td>\n",
       "      <td>-0.183835</td>\n",
       "      <td>-0.073549</td>\n",
       "      <td>0.066152</td>\n",
       "      <td>0.155828</td>\n",
       "      <td>0.127140</td>\n",
       "      <td>0.001297</td>\n",
       "      <td>-0.123886</td>\n",
       "      <td>0.940711</td>\n",
       "      <td>1.189938</td>\n",
       "      <td>1.282949</td>\n",
       "      <td>1.321673e+00</td>\n",
       "      <td>1.343632</td>\n",
       "      <td>1.363182</td>\n",
       "      <td>1.385096</td>\n",
       "      <td>1.489774</td>\n",
       "      <td>1.664508</td>\n",
       "      <td>1.848623</td>\n",
       "      <td>1.974257</td>\n",
       "      <td>2.083270</td>\n",
       "      <td>100.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-0.530450</td>\n",
       "      <td>-0.788244</td>\n",
       "      <td>-0.838856</td>\n",
       "      <td>2.132262</td>\n",
       "      <td>2.458819</td>\n",
       "      <td>2.724302</td>\n",
       "      <td>2.775157</td>\n",
       "      <td>3.525226</td>\n",
       "      <td>3.766236</td>\n",
       "      <td>4.123412</td>\n",
       "      <td>4.365712</td>\n",
       "      <td>4.481402</td>\n",
       "      <td>5.812980</td>\n",
       "      <td>6.533106</td>\n",
       "      <td>1.551002e+00</td>\n",
       "      <td>2.661143</td>\n",
       "      <td>3.285397</td>\n",
       "      <td>3.642872</td>\n",
       "      <td>3.734608</td>\n",
       "      <td>4.377157</td>\n",
       "      <td>4.863626</td>\n",
       "      <td>5.222322</td>\n",
       "      <td>6.184158</td>\n",
       "      <td>7.229568</td>\n",
       "      <td>8.095702</td>\n",
       "      <td>7.993703</td>\n",
       "      <td>8.029213</td>\n",
       "      <td>2.429946</td>\n",
       "      <td>3.268313</td>\n",
       "      <td>3.585795</td>\n",
       "      <td>4.305361e+00</td>\n",
       "      <td>4.921108</td>\n",
       "      <td>5.651057</td>\n",
       "      <td>6.775976</td>\n",
       "      <td>7.330512</td>\n",
       "      <td>8.247309</td>\n",
       "      <td>9.006602</td>\n",
       "      <td>9.212233</td>\n",
       "      <td>9.301118</td>\n",
       "      <td>204.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              atom_2         atom_3         atom_4         atom_5  \\\n",
       "count  709416.000000  709416.000000  709416.000000  709416.000000   \n",
       "mean   2.571980       4.718922       5.776832       2.685567        \n",
       "std    2.623271       2.590104       1.326641       2.572154        \n",
       "min    1.000000       0.000000       0.000000       0.000000        \n",
       "25%    1.000000       1.000000       6.000000       1.000000        \n",
       "50%    1.000000       6.000000       6.000000       1.000000        \n",
       "75%    6.000000       6.000000       6.000000       6.000000        \n",
       "max    8.000000       8.000000       9.000000       9.000000        \n",
       "\n",
       "              atom_6         atom_7        atom_8         atom_9  \\\n",
       "count  709416.000000  709416.000000  709416.00000  709416.000000   \n",
       "mean   3.561376       4.026453       4.10719       4.122326        \n",
       "std    2.778925       2.734745       2.73514       2.738560        \n",
       "min    0.000000       0.000000       0.00000       0.000000        \n",
       "25%    1.000000       1.000000       1.00000       1.000000        \n",
       "50%    1.000000       6.000000       6.00000       6.000000        \n",
       "75%    6.000000       6.000000       6.00000       6.000000        \n",
       "max    9.000000       9.000000       9.00000       9.000000        \n",
       "\n",
       "             atom_10        atom_11        atom_12        atom_13  \\\n",
       "count  709416.000000  709416.000000  709416.000000  709416.000000   \n",
       "mean   4.002451       3.798915       3.583815       3.370508        \n",
       "std    2.751343       2.774384       2.788014       2.792845        \n",
       "min    0.000000       0.000000       0.000000       0.000000        \n",
       "25%    1.000000       1.000000       1.000000       1.000000        \n",
       "50%    6.000000       6.000000       1.000000       1.000000        \n",
       "75%    6.000000       6.000000       6.000000       6.000000        \n",
       "max    9.000000       9.000000       9.000000       9.000000        \n",
       "\n",
       "             atom_14          r_x_1          r_x_2          r_x_3  \\\n",
       "count  709416.000000  709416.000000  709416.000000  709415.000000   \n",
       "mean   3.067422      -0.546450      -0.979225      -1.101685        \n",
       "std    2.776449       0.003409       0.167632       0.288504        \n",
       "min    0.000000      -0.623971      -1.741393      -3.217345        \n",
       "25%    1.000000      -0.548073      -1.012368      -1.198351        \n",
       "50%    1.000000      -0.547013      -0.896096      -1.058140        \n",
       "75%    6.000000      -0.545149      -0.878620      -0.899870        \n",
       "max    9.000000      -0.530450      -0.788244      -0.838856        \n",
       "\n",
       "               r_x_4          r_x_5          r_x_6          r_x_7  \\\n",
       "count  709415.000000  709410.000000  709396.000000  709372.000000   \n",
       "mean  -1.150749      -0.722346      -0.889720      -1.195437        \n",
       "std    0.348882       0.745300       0.974305       1.118066        \n",
       "min   -4.313008      -5.785330      -6.877647      -8.341340        \n",
       "25%   -1.210536      -0.812748      -1.427922      -2.163070        \n",
       "50%   -1.099114      -0.681519      -0.727940      -1.075679        \n",
       "75%   -1.067675      -0.499887      -0.466961      -0.508269        \n",
       "max    2.132262       2.458819       2.724302       2.775157        \n",
       "\n",
       "               r_x_8          r_x_9         r_x_10         r_x_11  \\\n",
       "count  709311.000000  709140.000000  708594.000000  707064.000000   \n",
       "mean  -1.361865      -1.515106      -1.628529      -1.741569        \n",
       "std    1.237562       1.306964       1.388093       1.456549        \n",
       "min   -9.436249      -10.498619     -8.959737      -9.966637        \n",
       "25%   -2.381790      -2.524487      -2.633375      -2.875624        \n",
       "50%   -1.435692      -1.720088      -1.883566      -1.985053        \n",
       "75%   -0.520835      -0.588746      -0.636282      -0.746931        \n",
       "max    3.525226       3.766236       4.123412       4.365712        \n",
       "\n",
       "              r_x_12         r_x_13         r_x_14         r_y_2  \\\n",
       "count  703307.000000  694468.000000  675797.000000  7.094140e+05   \n",
       "mean  -1.856271      -1.967502      -2.055424       1.083090e+00   \n",
       "std    1.507591       1.562252       1.635915       1.735383e-01   \n",
       "min   -10.120631     -10.442879     -10.839585      1.296874e-07   \n",
       "25%   -3.025711      -3.110226      -3.193569       1.036337e+00   \n",
       "50%   -2.074044      -2.165197      -2.255900       1.043768e+00   \n",
       "75%   -0.845237      -0.917255      -0.957479       1.057164e+00   \n",
       "max    4.481402       5.812980       6.533106       1.551002e+00   \n",
       "\n",
       "               r_y_3          r_y_4          r_y_5          r_y_6  \\\n",
       "count  709413.000000  709413.000000  709408.000000  709396.000000   \n",
       "mean  -0.697413      -0.728953      -1.044102      -1.044104        \n",
       "std    0.338384       0.648011       1.143755       1.157626        \n",
       "min   -2.741247      -3.459233      -4.209876      -5.176523        \n",
       "25%   -0.933856      -0.925234      -1.860262      -2.001435        \n",
       "50%   -0.675115      -0.748490      -1.505893      -1.303531        \n",
       "75%   -0.474206      -0.698513      -0.269260      -0.229039        \n",
       "max    2.661143       3.285397       3.642872       3.734608        \n",
       "\n",
       "               r_y_7          r_y_8          r_y_9         r_y_10  \\\n",
       "count  709372.000000  709311.000000  709140.000000  708594.000000   \n",
       "mean  -0.935776      -0.905031      -0.899817      -0.900218        \n",
       "std    1.197381       1.275927       1.382982       1.489190        \n",
       "min   -6.157640      -7.172949      -8.142640      -7.231229        \n",
       "25%   -1.962557      -1.970145      -2.023035      -2.105782        \n",
       "50%   -0.907118      -0.868514      -0.862037      -0.870498        \n",
       "75%   -0.207843      -0.183835      -0.073549       0.066152        \n",
       "max    4.377157       4.863626       5.222322       6.184158        \n",
       "\n",
       "              r_y_11         r_y_12         r_y_13         r_y_14  \\\n",
       "count  707064.000000  703307.000000  694468.000000  675797.000000   \n",
       "mean  -0.961409      -1.075191      -1.213436      -1.324268        \n",
       "std    1.595749       1.685591       1.765581       1.846532        \n",
       "min   -8.426347      -8.872462      -8.660447      -9.119188        \n",
       "25%   -2.270733      -2.481364      -2.637766      -2.742671        \n",
       "50%   -0.939767      -1.129955      -1.347714      -1.495286        \n",
       "75%    0.155828       0.127140       0.001297      -0.123886        \n",
       "max    7.229568       8.095702       7.993703       8.029213        \n",
       "\n",
       "               r_z_3          r_z_4          r_z_5         r_z_6  \\\n",
       "count  709413.000000  709413.000000  709408.000000  7.093960e+05   \n",
       "mean   0.001968      -0.004871      -0.036653       2.371743e-03   \n",
       "std    0.991072       1.100457       1.547604       1.604829e+00   \n",
       "min   -2.975889      -3.397849      -3.250526      -4.291014e+00   \n",
       "25%   -0.940911      -1.191681      -1.318307      -1.318267e+00   \n",
       "50%    0.000012      -0.000004      -0.001370       3.091573e-07   \n",
       "75%    0.940711       1.189938       1.282949       1.321673e+00   \n",
       "max    2.429946       3.268313       3.585795       4.305361e+00   \n",
       "\n",
       "               r_z_7          r_z_8          r_z_9         r_z_10  \\\n",
       "count  709372.000000  709311.000000  709140.000000  708594.000000   \n",
       "mean   0.019784       0.007585       0.003711       0.014239        \n",
       "std    1.640480       1.707029       1.797695       1.946012        \n",
       "min   -4.921109      -6.307271      -6.798973      -7.330513        \n",
       "25%   -1.323967      -1.351307      -1.374947      -1.448560        \n",
       "50%    0.000085       0.000026       0.000020       0.000107        \n",
       "75%    1.343632       1.363182       1.385096       1.489774        \n",
       "max    4.921108       5.651057       6.775976       7.330512        \n",
       "\n",
       "              r_z_11         r_z_12         r_z_13         r_z_14  \\\n",
       "count  707064.000000  703307.000000  694468.000000  675797.000000   \n",
       "mean   0.021524       0.016087       0.018835       0.019659        \n",
       "std    2.090539       2.236150       2.369307       2.508988        \n",
       "min   -8.250480      -9.006602      -9.212234      -9.301118        \n",
       "25%   -1.604933      -1.796347      -1.921404      -2.041021        \n",
       "50%    0.000464       0.000162       0.000308       0.001305        \n",
       "75%    1.664508       1.848623       1.974257       2.083270        \n",
       "max    8.247309       9.006602       9.212233       9.301118        \n",
       "\n",
       "       scalar_coupling_constant  \n",
       "count  709416.000000             \n",
       "mean   94.976153                 \n",
       "std    18.277237                 \n",
       "min    66.600800                 \n",
       "25%    84.023000                 \n",
       "50%    88.223650                 \n",
       "75%    100.735000                \n",
       "max    204.880000                "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#full, _ = train_test_split(full_all, test_size=0.9, random_state=42)\n",
    "full = full_all\n",
    "full.head()\n",
    "\n",
    "#n_atoms = full.atom_index_0.max()\n",
    "n_atoms = 15\n",
    "df = take_n_atoms(full, n_atoms)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
       "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
       "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
       "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
       "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
       "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
       "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
       "       'r_z_13', 'r_z_14', 'scalar_coupling_constant'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LightGBM performs better with 0-s then with NaN-s\n",
    "df = df.fillna(0)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.info()\n",
    "# df.hist(bins=10, figsize = [20,20] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x215b8f112b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot.scatter(x='r_y_3', y = 'scalar_coupling_constant') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((567532, 52), (141884, 52), (567532,), (141884,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_data = df.drop(['scalar_coupling_constant'], axis=1).values.astype('float32')\n",
    "#y_data = df['scalar_coupling_constant'].values.astype('float32')\n",
    "X_data = df.drop(['scalar_coupling_constant'], axis=1)\n",
    "y_data = df['scalar_coupling_constant']\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_data, y_data, test_size=0.2, random_state=128)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration params are copied from @artgor kernel:\n",
    "# https://www.kaggle.com/artgor/brute-force-feature-engineering\n",
    "if False:\n",
    "    LGB_PARAMS = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'mae',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'learning_rate': 0.3,\n",
    "        'num_leaves': 128,\n",
    "        'min_child_samples': 79,\n",
    "        'max_depth': 9,\n",
    "        'subsample_freq': 1,\n",
    "        'subsample': 0.9,\n",
    "        'bagging_seed': 11,\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.3,\n",
    "        'colsample_bytree': 1.0\n",
    "    }\n",
    "LGB_PARAMS = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'verbosity': -1,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_leaves': 400,\n",
    "    'min_child_samples': 60,\n",
    "    'max_depth': 9,\n",
    "    'reg_alpha': 0.01,\n",
    "    'reg_lambda': 0.3,\n",
    "    'bagging_freq': 2000,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_seed': 11,\n",
    "    'colsample_bytree': 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 1.60781\tvalid_1's l1: 1.64599\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's l1: 1.60781\tvalid_1's l1: 1.64599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4983415454740128"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time \n",
    "categorical_features = [col for col in X_train if col.startswith('atom_')]\n",
    "\n",
    "model = LGBMRegressor(**LGB_PARAMS, n_estimators=100, n_jobs = -1)\n",
    "model.fit(X_train, y_train, \n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "        verbose=100, early_stopping_rounds=1000,\n",
    "         categorical_feature = categorical_features)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "np.log(mean_absolute_error(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad score for such a simple set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.7, bagging_freq=2000, bagging_seed=11,\n",
       "              boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.05, max_depth=9,\n",
       "              metric='mae', min_child_samples=60, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=400,\n",
       "              objective='regression', random_state=None, reg_alpha=0.01,\n",
       "              reg_lambda=0.3, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0, verbosity=-1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    141884.000000\n",
       "mean     0.000084     \n",
       "std      2.283513     \n",
       "min     -43.735946    \n",
       "25%     -1.177550     \n",
       "50%      0.019702     \n",
       "75%      1.225679     \n",
       "max      21.078929    \n",
       "Name: scalar_coupling_constant, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = y_pred- y_val\n",
    "tmp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('scalar_coupling_constant')\n",
    "cols\n",
    "df_importance = pd.DataFrame({'feature': cols, 'importance': model.feature_importances_})\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=df_importance.sort_values('importance', ascending=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>r_x_1</td>\n",
       "      <td>2757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>r_y_2</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>r_y_3</td>\n",
       "      <td>1666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>r_x_3</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>r_x_5</td>\n",
       "      <td>1527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>r_x_2</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>r_y_4</td>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>r_x_4</td>\n",
       "      <td>1398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>r_x_6</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>r_x_7</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>r_y_5</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atom_2</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>r_x_8</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>r_y_6</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atom_3</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>r_y_7</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>r_x_9</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>r_x_10</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>r_y_8</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>r_y_9</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>r_z_3</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>r_x_11</td>\n",
       "      <td>402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>r_y_10</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>r_x_12</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>r_z_4</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atom_5</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atom_6</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>atom_7</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>r_y_11</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atom_4</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>r_x_14</td>\n",
       "      <td>285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>r_y_12</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>r_x_13</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>r_y_13</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>r_z_7</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>atom_8</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>r_y_14</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>r_z_5</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>r_z_6</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>atom_9</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>r_z_10</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>r_z_9</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>r_z_8</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>r_z_11</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>r_z_12</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>r_z_13</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>r_z_14</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>atom_14</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>atom_10</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>atom_12</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>atom_13</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>atom_11</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "13  r_x_1    2757      \n",
       "27  r_y_2    1974      \n",
       "28  r_y_3    1666      \n",
       "15  r_x_3    1567      \n",
       "17  r_x_5    1527      \n",
       "14  r_x_2    1520      \n",
       "29  r_y_4    1444      \n",
       "16  r_x_4    1398      \n",
       "18  r_x_6    1288      \n",
       "19  r_x_7    1056      \n",
       "30  r_y_5    1034      \n",
       "0   atom_2   921       \n",
       "20  r_x_8    820       \n",
       "31  r_y_6    790       \n",
       "1   atom_3   750       \n",
       "32  r_y_7    694       \n",
       "21  r_x_9    666       \n",
       "22  r_x_10   558       \n",
       "33  r_y_8    555       \n",
       "34  r_y_9    452       \n",
       "40  r_z_3    440       \n",
       "23  r_x_11   402       \n",
       "35  r_y_10   328       \n",
       "24  r_x_12   326       \n",
       "41  r_z_4    324       \n",
       "3   atom_5   314       \n",
       "4   atom_6   308       \n",
       "5   atom_7   297       \n",
       "36  r_y_11   295       \n",
       "2   atom_4   292       \n",
       "26  r_x_14   285       \n",
       "37  r_y_12   255       \n",
       "25  r_x_13   245       \n",
       "38  r_y_13   243       \n",
       "44  r_z_7    221       \n",
       "6   atom_8   216       \n",
       "39  r_y_14   186       \n",
       "42  r_z_5    172       \n",
       "43  r_z_6    169       \n",
       "7   atom_9   164       \n",
       "47  r_z_10   160       \n",
       "46  r_z_9    152       \n",
       "45  r_z_8    142       \n",
       "48  r_z_11   132       \n",
       "49  r_z_12   129       \n",
       "50  r_z_13   104       \n",
       "51  r_z_14   87        \n",
       "12  atom_14  68        \n",
       "8   atom_10  64        \n",
       "10  atom_12  50        \n",
       "11  atom_13  50        \n",
       "9   atom_11  46        "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x215ba9c22e8>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_val, y_pred- y_val, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(2,9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_x_y_data(some_csv, coupling_type, n_atoms, isTest = False):\n",
    "   #full = build_couple_dataframe(some_csv, structures_csv, coupling_type, n_atoms=n_atoms)\n",
    "    if isTest:\n",
    "        full_all = pd.read_csv(f'{INPUT_ADDED}/test_{coupling_type}.csv')\n",
    "    else:\n",
    "        full_all =  pd.read_csv(f'{INPUT_ADDED}/{coupling_type}.csv')\n",
    "    full = full_all\n",
    "    df = take_n_atoms(full, n_atoms)\n",
    "    df = df.fillna(0)\n",
    "    print(df.columns)\n",
    "    \n",
    "    if 'scalar_coupling_constant' in df:\n",
    "        X_data = df.drop(['scalar_coupling_constant'], axis=1)\n",
    "        y_data = df['scalar_coupling_constant']\n",
    "    else:\n",
    "        X_data = df\n",
    "        y_data = None\n",
    "    \n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict_for_one_coupling_type(coupling_type, submission, n_atoms, n_folds=3, n_splits=3, random_state=128):\n",
    "    model_type =  'lgb' #lgb  cat\n",
    "    print(f'*** Training Model for {coupling_type} ***')\n",
    "    \n",
    "    X_data, y_data = build_x_y_data(train_csv, coupling_type, n_atoms, False)\n",
    "    columns = X_data.columns \n",
    "    X_test, _ = build_x_y_data(test_csv, coupling_type, n_atoms, True)\n",
    "    y_pred = np.zeros(X_test.shape[0], dtype='float32')\n",
    "\n",
    "\n",
    "    cv_score = 0\n",
    "    \n",
    "    if n_folds > n_splits:\n",
    "        n_splits = n_folds\n",
    "    \n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(kfold.split(X_data, y_data)):\n",
    "        if fold >= n_folds:\n",
    "            break\n",
    "\n",
    "        #X_train, X_val = X_data[train_index], X_data[val_index]\n",
    "        #y_train, y_val = y_data[train_index], y_data[val_index]\n",
    "        X_train, X_val = X_data[columns].iloc[train_index], X_data[columns].iloc[val_index]\n",
    "        y_train, y_val = y_data.iloc[train_index], y_data.iloc[val_index]\n",
    "\n",
    "        model = \"\"\n",
    "        categorical_features = [col for col in X_train if col.startswith('atom_')]\n",
    "        if model_type == 'lgb':\n",
    "\n",
    "            model = LGBMRegressor(**LGB_PARAMS, n_estimators=10000, n_jobs = -1)\n",
    "            #model = LGBMRegressor(**LGB_PARAMS, n_estimators=6000, n_jobs = -1)\n",
    "            model.fit(X_train, y_train, \n",
    "                eval_set=[(X_train, y_train), (X_val, y_val)], eval_metric='mae',\n",
    "                verbose=100, early_stopping_rounds=1000,\n",
    "                     categorical_feature = categorical_features)\n",
    "        \n",
    "        if model_type == 'cat': \n",
    "            model = CatBoostRegressor(eval_metric='MAE', **CAT_PARAMS, loss_function='MAE')\n",
    "            X_trainGlob = X_train\n",
    "            model.fit(X_train, y_train, eval_set=((X_val, y_val)), \n",
    "                      cat_features = categorical_features,\n",
    "                      use_best_model=True,\n",
    "                      verbose=False)\n",
    "\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        val_score = np.log(mean_absolute_error(y_val, y_val_pred))\n",
    "        print(f'{coupling_type} Fold {fold}, logMAE: {val_score}')\n",
    "        \n",
    "        cv_score += val_score / n_folds\n",
    "        y_pred += model.predict(X_test) / n_folds\n",
    "        \n",
    "    submission.loc[test_csv['type'] == coupling_type, 'scalar_coupling_constant'] = y_pred\n",
    "    return cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a separate model for each type of coupling. Dataset is split into 5 pieces and in this kernel we will use only 3 folds for speed up.\n",
    "\n",
    "Main tuning parameter is the number of atoms. I took good numbers, but accuracy can be improved a bit by tuning them for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False: \n",
    "    model_params = {\n",
    "        '1JHC': 10,\n",
    "        '1JHN': 7,    \n",
    "        '2JHH': 9,\n",
    "        '2JHN': 9,\n",
    "        '2JHC': 9,\n",
    "        '3JHH': 9,\n",
    "        '3JHC': 10,\n",
    "        '3JHN': 10\n",
    "    }\n",
    "model_params = {\n",
    "        '1JHN': 10,    \n",
    "        '1JHC': 15,\n",
    "        '2JHH': 13,\n",
    "        '2JHN': 13,\n",
    "        '2JHC': 13,\n",
    "        '3JHH': 13,\n",
    "        '3JHC': 15,\n",
    "        '3JHN': 15\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking cross-validation scores for each type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Training Model for 1JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7',\n",
      "       'r_x_8', 'r_x_9', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7',\n",
      "       'r_y_8', 'r_y_9', 'r_z_3', 'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8',\n",
      "       'r_z_9'],\n",
      "      dtype='object')\n",
      "Training until validation scores don't improve for 1000 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's l1: 0.595661\tvalid_1's l1: 0.680035\n",
      "[200]\ttraining's l1: 0.50095\tvalid_1's l1: 0.606997\n",
      "[300]\ttraining's l1: 0.462818\tvalid_1's l1: 0.581784\n",
      "[400]\ttraining's l1: 0.434137\tvalid_1's l1: 0.563719\n",
      "[500]\ttraining's l1: 0.412179\tvalid_1's l1: 0.550646\n",
      "[600]\ttraining's l1: 0.395662\tvalid_1's l1: 0.541894\n",
      "[700]\ttraining's l1: 0.381706\tvalid_1's l1: 0.534004\n",
      "[800]\ttraining's l1: 0.368874\tvalid_1's l1: 0.527508\n",
      "[900]\ttraining's l1: 0.357287\tvalid_1's l1: 0.521344\n",
      "[1000]\ttraining's l1: 0.346683\tvalid_1's l1: 0.516896\n",
      "[1100]\ttraining's l1: 0.337975\tvalid_1's l1: 0.513055\n",
      "[1200]\ttraining's l1: 0.330414\tvalid_1's l1: 0.510199\n",
      "[1300]\ttraining's l1: 0.322677\tvalid_1's l1: 0.50738\n",
      "[1400]\ttraining's l1: 0.316508\tvalid_1's l1: 0.504946\n",
      "[1500]\ttraining's l1: 0.3099\tvalid_1's l1: 0.502399\n",
      "[1600]\ttraining's l1: 0.304041\tvalid_1's l1: 0.500128\n",
      "[1700]\ttraining's l1: 0.298829\tvalid_1's l1: 0.498314\n",
      "[1800]\ttraining's l1: 0.294264\tvalid_1's l1: 0.49679\n",
      "[1900]\ttraining's l1: 0.290142\tvalid_1's l1: 0.495287\n",
      "[2000]\ttraining's l1: 0.285724\tvalid_1's l1: 0.493704\n",
      "[2100]\ttraining's l1: 0.274368\tvalid_1's l1: 0.487153\n",
      "[2200]\ttraining's l1: 0.268257\tvalid_1's l1: 0.48363\n",
      "[2300]\ttraining's l1: 0.262729\tvalid_1's l1: 0.480761\n",
      "[2400]\ttraining's l1: 0.257008\tvalid_1's l1: 0.478251\n",
      "[2500]\ttraining's l1: 0.251996\tvalid_1's l1: 0.476156\n",
      "[2600]\ttraining's l1: 0.247566\tvalid_1's l1: 0.474373\n",
      "[2700]\ttraining's l1: 0.242668\tvalid_1's l1: 0.4727\n",
      "[2800]\ttraining's l1: 0.238279\tvalid_1's l1: 0.470878\n",
      "[2900]\ttraining's l1: 0.233328\tvalid_1's l1: 0.468832\n",
      "[3000]\ttraining's l1: 0.228276\tvalid_1's l1: 0.467026\n",
      "[3100]\ttraining's l1: 0.223058\tvalid_1's l1: 0.465347\n",
      "[3200]\ttraining's l1: 0.219149\tvalid_1's l1: 0.464108\n",
      "[3300]\ttraining's l1: 0.215124\tvalid_1's l1: 0.46284\n",
      "[3400]\ttraining's l1: 0.210918\tvalid_1's l1: 0.461339\n",
      "[3500]\ttraining's l1: 0.206584\tvalid_1's l1: 0.460421\n",
      "[3600]\ttraining's l1: 0.202937\tvalid_1's l1: 0.459605\n",
      "[3700]\ttraining's l1: 0.199411\tvalid_1's l1: 0.458655\n",
      "[3800]\ttraining's l1: 0.19618\tvalid_1's l1: 0.457782\n",
      "[3900]\ttraining's l1: 0.193141\tvalid_1's l1: 0.45695\n",
      "[4000]\ttraining's l1: 0.190081\tvalid_1's l1: 0.456188\n",
      "[4100]\ttraining's l1: 0.183683\tvalid_1's l1: 0.453937\n",
      "[4200]\ttraining's l1: 0.178992\tvalid_1's l1: 0.45267\n",
      "[4300]\ttraining's l1: 0.175168\tvalid_1's l1: 0.451649\n",
      "[4400]\ttraining's l1: 0.171869\tvalid_1's l1: 0.450753\n",
      "[4500]\ttraining's l1: 0.168597\tvalid_1's l1: 0.450064\n",
      "[4600]\ttraining's l1: 0.165725\tvalid_1's l1: 0.449608\n",
      "[4700]\ttraining's l1: 0.162924\tvalid_1's l1: 0.44912\n",
      "[4800]\ttraining's l1: 0.160101\tvalid_1's l1: 0.448685\n",
      "[4900]\ttraining's l1: 0.157846\tvalid_1's l1: 0.448487\n",
      "[5000]\ttraining's l1: 0.155309\tvalid_1's l1: 0.448107\n",
      "[5100]\ttraining's l1: 0.153361\tvalid_1's l1: 0.447748\n",
      "[5200]\ttraining's l1: 0.151239\tvalid_1's l1: 0.447394\n",
      "[5300]\ttraining's l1: 0.149158\tvalid_1's l1: 0.447072\n",
      "[5400]\ttraining's l1: 0.147016\tvalid_1's l1: 0.446905\n",
      "[5500]\ttraining's l1: 0.144938\tvalid_1's l1: 0.446636\n",
      "[5600]\ttraining's l1: 0.142964\tvalid_1's l1: 0.446408\n",
      "[5700]\ttraining's l1: 0.14119\tvalid_1's l1: 0.446059\n",
      "[5800]\ttraining's l1: 0.139467\tvalid_1's l1: 0.445809\n",
      "[5900]\ttraining's l1: 0.137932\tvalid_1's l1: 0.445591\n",
      "[6000]\ttraining's l1: 0.136501\tvalid_1's l1: 0.44533\n",
      "[6100]\ttraining's l1: 0.133769\tvalid_1's l1: 0.444204\n",
      "[6200]\ttraining's l1: 0.131201\tvalid_1's l1: 0.443346\n",
      "[6300]\ttraining's l1: 0.129036\tvalid_1's l1: 0.442701\n",
      "[6400]\ttraining's l1: 0.127044\tvalid_1's l1: 0.442173\n",
      "[6500]\ttraining's l1: 0.125095\tvalid_1's l1: 0.441749\n",
      "[6600]\ttraining's l1: 0.123285\tvalid_1's l1: 0.441255\n",
      "[6700]\ttraining's l1: 0.121551\tvalid_1's l1: 0.440805\n",
      "[6800]\ttraining's l1: 0.11999\tvalid_1's l1: 0.440631\n",
      "[6900]\ttraining's l1: 0.1184\tvalid_1's l1: 0.440342\n",
      "[7000]\ttraining's l1: 0.116768\tvalid_1's l1: 0.440076\n",
      "[7100]\ttraining's l1: 0.115197\tvalid_1's l1: 0.439778\n",
      "[7200]\ttraining's l1: 0.113502\tvalid_1's l1: 0.439502\n",
      "[7300]\ttraining's l1: 0.112172\tvalid_1's l1: 0.439307\n",
      "[7400]\ttraining's l1: 0.110933\tvalid_1's l1: 0.439097\n",
      "[7500]\ttraining's l1: 0.109609\tvalid_1's l1: 0.438877\n",
      "[7600]\ttraining's l1: 0.108396\tvalid_1's l1: 0.43868\n",
      "[7700]\ttraining's l1: 0.107276\tvalid_1's l1: 0.438517\n",
      "[7800]\ttraining's l1: 0.106069\tvalid_1's l1: 0.43842\n",
      "[7900]\ttraining's l1: 0.105085\tvalid_1's l1: 0.438262\n",
      "[8000]\ttraining's l1: 0.103916\tvalid_1's l1: 0.438164\n",
      "[8100]\ttraining's l1: 0.101879\tvalid_1's l1: 0.437339\n",
      "[8200]\ttraining's l1: 0.100869\tvalid_1's l1: 0.43704\n",
      "[8300]\ttraining's l1: 0.0999483\tvalid_1's l1: 0.436779\n",
      "[8400]\ttraining's l1: 0.0990644\tvalid_1's l1: 0.436537\n",
      "[8500]\ttraining's l1: 0.0981773\tvalid_1's l1: 0.436302\n",
      "[8600]\ttraining's l1: 0.0973488\tvalid_1's l1: 0.436208\n",
      "[8700]\ttraining's l1: 0.0962738\tvalid_1's l1: 0.435966\n",
      "[8800]\ttraining's l1: 0.0950178\tvalid_1's l1: 0.435742\n",
      "[8900]\ttraining's l1: 0.094005\tvalid_1's l1: 0.435492\n",
      "[9000]\ttraining's l1: 0.0929476\tvalid_1's l1: 0.435367\n",
      "[9100]\ttraining's l1: 0.0919863\tvalid_1's l1: 0.43529\n",
      "[9200]\ttraining's l1: 0.0909029\tvalid_1's l1: 0.435149\n",
      "[9300]\ttraining's l1: 0.089951\tvalid_1's l1: 0.434984\n",
      "[9400]\ttraining's l1: 0.0890027\tvalid_1's l1: 0.43488\n",
      "[9500]\ttraining's l1: 0.0880662\tvalid_1's l1: 0.434694\n",
      "[9600]\ttraining's l1: 0.0872325\tvalid_1's l1: 0.43458\n",
      "[9700]\ttraining's l1: 0.08641\tvalid_1's l1: 0.43442\n",
      "[9800]\ttraining's l1: 0.0855099\tvalid_1's l1: 0.43436\n",
      "[9900]\ttraining's l1: 0.0847158\tvalid_1's l1: 0.434198\n",
      "[10000]\ttraining's l1: 0.0838844\tvalid_1's l1: 0.434138\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0838844\tvalid_1's l1: 0.434138\n",
      "1JHN Fold 0, logMAE: -0.8343937993858948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.593417\tvalid_1's l1: 0.675058\n",
      "[200]\ttraining's l1: 0.509382\tvalid_1's l1: 0.609108\n",
      "[300]\ttraining's l1: 0.472599\tvalid_1's l1: 0.583616\n",
      "[400]\ttraining's l1: 0.447028\tvalid_1's l1: 0.565903\n",
      "[500]\ttraining's l1: 0.424962\tvalid_1's l1: 0.551302\n",
      "[600]\ttraining's l1: 0.406106\tvalid_1's l1: 0.539606\n",
      "[700]\ttraining's l1: 0.390556\tvalid_1's l1: 0.530813\n",
      "[800]\ttraining's l1: 0.374971\tvalid_1's l1: 0.52322\n",
      "[900]\ttraining's l1: 0.361031\tvalid_1's l1: 0.516694\n",
      "[1000]\ttraining's l1: 0.349071\tvalid_1's l1: 0.510998\n",
      "[1100]\ttraining's l1: 0.338592\tvalid_1's l1: 0.506796\n",
      "[1200]\ttraining's l1: 0.32823\tvalid_1's l1: 0.502523\n",
      "[1300]\ttraining's l1: 0.320204\tvalid_1's l1: 0.49933\n",
      "[1400]\ttraining's l1: 0.3124\tvalid_1's l1: 0.496686\n",
      "[1500]\ttraining's l1: 0.30401\tvalid_1's l1: 0.493669\n",
      "[1600]\ttraining's l1: 0.296393\tvalid_1's l1: 0.491027\n",
      "[1700]\ttraining's l1: 0.289729\tvalid_1's l1: 0.488791\n",
      "[1800]\ttraining's l1: 0.283718\tvalid_1's l1: 0.486806\n",
      "[1900]\ttraining's l1: 0.277809\tvalid_1's l1: 0.484831\n",
      "[2000]\ttraining's l1: 0.272148\tvalid_1's l1: 0.482895\n",
      "[2100]\ttraining's l1: 0.26426\tvalid_1's l1: 0.477248\n",
      "[2200]\ttraining's l1: 0.25832\tvalid_1's l1: 0.474694\n",
      "[2300]\ttraining's l1: 0.253004\tvalid_1's l1: 0.471757\n",
      "[2400]\ttraining's l1: 0.248103\tvalid_1's l1: 0.469921\n",
      "[2500]\ttraining's l1: 0.243441\tvalid_1's l1: 0.468193\n",
      "[2600]\ttraining's l1: 0.239354\tvalid_1's l1: 0.466936\n",
      "[2700]\ttraining's l1: 0.235184\tvalid_1's l1: 0.465601\n",
      "[2800]\ttraining's l1: 0.231551\tvalid_1's l1: 0.46442\n",
      "[2900]\ttraining's l1: 0.228237\tvalid_1's l1: 0.463044\n",
      "[3000]\ttraining's l1: 0.224463\tvalid_1's l1: 0.461881\n",
      "[3100]\ttraining's l1: 0.221034\tvalid_1's l1: 0.460807\n",
      "[3200]\ttraining's l1: 0.217922\tvalid_1's l1: 0.459856\n",
      "[3300]\ttraining's l1: 0.214751\tvalid_1's l1: 0.458917\n",
      "[3400]\ttraining's l1: 0.212089\tvalid_1's l1: 0.458353\n",
      "[3500]\ttraining's l1: 0.209319\tvalid_1's l1: 0.457395\n",
      "[3600]\ttraining's l1: 0.20682\tvalid_1's l1: 0.456703\n",
      "[3700]\ttraining's l1: 0.204376\tvalid_1's l1: 0.456189\n",
      "[3800]\ttraining's l1: 0.201723\tvalid_1's l1: 0.455472\n",
      "[3900]\ttraining's l1: 0.199288\tvalid_1's l1: 0.454964\n",
      "[4000]\ttraining's l1: 0.197235\tvalid_1's l1: 0.454309\n",
      "[4100]\ttraining's l1: 0.192092\tvalid_1's l1: 0.453035\n",
      "[4200]\ttraining's l1: 0.187946\tvalid_1's l1: 0.451848\n",
      "[4300]\ttraining's l1: 0.184908\tvalid_1's l1: 0.450838\n",
      "[4400]\ttraining's l1: 0.181696\tvalid_1's l1: 0.450084\n",
      "[4500]\ttraining's l1: 0.17802\tvalid_1's l1: 0.449127\n",
      "[4600]\ttraining's l1: 0.175172\tvalid_1's l1: 0.448458\n",
      "[4700]\ttraining's l1: 0.172237\tvalid_1's l1: 0.447727\n",
      "[4800]\ttraining's l1: 0.16972\tvalid_1's l1: 0.447316\n",
      "[4900]\ttraining's l1: 0.167063\tvalid_1's l1: 0.446924\n",
      "[5000]\ttraining's l1: 0.16463\tvalid_1's l1: 0.446574\n",
      "[5100]\ttraining's l1: 0.162208\tvalid_1's l1: 0.446012\n",
      "[5200]\ttraining's l1: 0.159991\tvalid_1's l1: 0.445628\n",
      "[5300]\ttraining's l1: 0.158065\tvalid_1's l1: 0.445222\n",
      "[5400]\ttraining's l1: 0.155492\tvalid_1's l1: 0.444524\n",
      "[5500]\ttraining's l1: 0.153047\tvalid_1's l1: 0.444033\n",
      "[5600]\ttraining's l1: 0.151093\tvalid_1's l1: 0.443686\n",
      "[5700]\ttraining's l1: 0.148954\tvalid_1's l1: 0.443374\n",
      "[5800]\ttraining's l1: 0.147283\tvalid_1's l1: 0.44322\n",
      "[5900]\ttraining's l1: 0.145446\tvalid_1's l1: 0.443013\n",
      "[6000]\ttraining's l1: 0.143583\tvalid_1's l1: 0.442819\n",
      "[6100]\ttraining's l1: 0.140035\tvalid_1's l1: 0.441758\n",
      "[6200]\ttraining's l1: 0.137344\tvalid_1's l1: 0.441311\n",
      "[6300]\ttraining's l1: 0.135334\tvalid_1's l1: 0.440922\n",
      "[6400]\ttraining's l1: 0.133413\tvalid_1's l1: 0.440503\n",
      "[6500]\ttraining's l1: 0.131216\tvalid_1's l1: 0.440186\n",
      "[6600]\ttraining's l1: 0.129163\tvalid_1's l1: 0.439843\n",
      "[6700]\ttraining's l1: 0.127343\tvalid_1's l1: 0.439575\n",
      "[6800]\ttraining's l1: 0.125803\tvalid_1's l1: 0.439342\n",
      "[6900]\ttraining's l1: 0.124742\tvalid_1's l1: 0.439129\n",
      "[7000]\ttraining's l1: 0.1237\tvalid_1's l1: 0.438956\n",
      "[7100]\ttraining's l1: 0.122578\tvalid_1's l1: 0.438797\n",
      "[7200]\ttraining's l1: 0.121454\tvalid_1's l1: 0.438702\n",
      "[7300]\ttraining's l1: 0.120388\tvalid_1's l1: 0.438537\n",
      "[7400]\ttraining's l1: 0.119395\tvalid_1's l1: 0.43838\n",
      "[7500]\ttraining's l1: 0.1183\tvalid_1's l1: 0.438285\n",
      "[7600]\ttraining's l1: 0.117449\tvalid_1's l1: 0.438095\n",
      "[7700]\ttraining's l1: 0.11616\tvalid_1's l1: 0.437889\n",
      "[7800]\ttraining's l1: 0.114912\tvalid_1's l1: 0.437785\n",
      "[7900]\ttraining's l1: 0.113696\tvalid_1's l1: 0.437623\n",
      "[8000]\ttraining's l1: 0.112377\tvalid_1's l1: 0.437406\n",
      "[8100]\ttraining's l1: 0.110115\tvalid_1's l1: 0.436586\n",
      "[8200]\ttraining's l1: 0.108269\tvalid_1's l1: 0.436267\n",
      "[8300]\ttraining's l1: 0.106719\tvalid_1's l1: 0.435979\n",
      "[8400]\ttraining's l1: 0.10502\tvalid_1's l1: 0.435655\n",
      "[8500]\ttraining's l1: 0.10335\tvalid_1's l1: 0.43544\n",
      "[8600]\ttraining's l1: 0.101918\tvalid_1's l1: 0.435271\n",
      "[8700]\ttraining's l1: 0.10063\tvalid_1's l1: 0.435106\n",
      "[8800]\ttraining's l1: 0.0995494\tvalid_1's l1: 0.435013\n",
      "[8900]\ttraining's l1: 0.0985912\tvalid_1's l1: 0.435\n",
      "[9000]\ttraining's l1: 0.0975295\tvalid_1's l1: 0.434852\n",
      "[9100]\ttraining's l1: 0.0964556\tvalid_1's l1: 0.43472\n",
      "[9200]\ttraining's l1: 0.0954774\tvalid_1's l1: 0.434597\n",
      "[9300]\ttraining's l1: 0.094396\tvalid_1's l1: 0.434471\n",
      "[9400]\ttraining's l1: 0.0935192\tvalid_1's l1: 0.43431\n",
      "[9500]\ttraining's l1: 0.0925786\tvalid_1's l1: 0.434193\n",
      "[9600]\ttraining's l1: 0.0916088\tvalid_1's l1: 0.434071\n",
      "[9700]\ttraining's l1: 0.0907495\tvalid_1's l1: 0.43398\n",
      "[9800]\ttraining's l1: 0.0899044\tvalid_1's l1: 0.433788\n",
      "[9900]\ttraining's l1: 0.0890568\tvalid_1's l1: 0.433695\n",
      "[10000]\ttraining's l1: 0.088098\tvalid_1's l1: 0.433585\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.088098\tvalid_1's l1: 0.433585\n",
      "1JHN Fold 1, logMAE: -0.8356663692663813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.591456\tvalid_1's l1: 0.670075\n",
      "[200]\ttraining's l1: 0.511939\tvalid_1's l1: 0.606114\n",
      "[300]\ttraining's l1: 0.475046\tvalid_1's l1: 0.581148\n",
      "[400]\ttraining's l1: 0.448345\tvalid_1's l1: 0.564103\n",
      "[500]\ttraining's l1: 0.425278\tvalid_1's l1: 0.550201\n",
      "[600]\ttraining's l1: 0.406202\tvalid_1's l1: 0.53959\n",
      "[700]\ttraining's l1: 0.390766\tvalid_1's l1: 0.531914\n",
      "[800]\ttraining's l1: 0.376424\tvalid_1's l1: 0.525129\n",
      "[900]\ttraining's l1: 0.364322\tvalid_1's l1: 0.51941\n",
      "[1000]\ttraining's l1: 0.351953\tvalid_1's l1: 0.513872\n",
      "[1100]\ttraining's l1: 0.340836\tvalid_1's l1: 0.508972\n",
      "[1200]\ttraining's l1: 0.330564\tvalid_1's l1: 0.504674\n",
      "[1300]\ttraining's l1: 0.322427\tvalid_1's l1: 0.501661\n",
      "[1400]\ttraining's l1: 0.314297\tvalid_1's l1: 0.499066\n",
      "[1500]\ttraining's l1: 0.306724\tvalid_1's l1: 0.496207\n",
      "[1600]\ttraining's l1: 0.299787\tvalid_1's l1: 0.493739\n",
      "[1700]\ttraining's l1: 0.292263\tvalid_1's l1: 0.491098\n",
      "[1800]\ttraining's l1: 0.286043\tvalid_1's l1: 0.48921\n",
      "[1900]\ttraining's l1: 0.279871\tvalid_1's l1: 0.487141\n",
      "[2000]\ttraining's l1: 0.274835\tvalid_1's l1: 0.485529\n",
      "[2100]\ttraining's l1: 0.267951\tvalid_1's l1: 0.480447\n",
      "[2200]\ttraining's l1: 0.263843\tvalid_1's l1: 0.478022\n",
      "[2300]\ttraining's l1: 0.259358\tvalid_1's l1: 0.475356\n",
      "[2400]\ttraining's l1: 0.255137\tvalid_1's l1: 0.473507\n",
      "[2500]\ttraining's l1: 0.251657\tvalid_1's l1: 0.471973\n",
      "[2600]\ttraining's l1: 0.247805\tvalid_1's l1: 0.470329\n",
      "[2700]\ttraining's l1: 0.244446\tvalid_1's l1: 0.469051\n",
      "[2800]\ttraining's l1: 0.240687\tvalid_1's l1: 0.467694\n",
      "[2900]\ttraining's l1: 0.236497\tvalid_1's l1: 0.466383\n",
      "[3000]\ttraining's l1: 0.232917\tvalid_1's l1: 0.465363\n",
      "[3100]\ttraining's l1: 0.230002\tvalid_1's l1: 0.464432\n",
      "[3200]\ttraining's l1: 0.226571\tvalid_1's l1: 0.463218\n",
      "[3300]\ttraining's l1: 0.223466\tvalid_1's l1: 0.462455\n",
      "[3400]\ttraining's l1: 0.220705\tvalid_1's l1: 0.461561\n",
      "[3500]\ttraining's l1: 0.217763\tvalid_1's l1: 0.460555\n",
      "[3600]\ttraining's l1: 0.215067\tvalid_1's l1: 0.459899\n",
      "[3700]\ttraining's l1: 0.212357\tvalid_1's l1: 0.459086\n",
      "[3800]\ttraining's l1: 0.209909\tvalid_1's l1: 0.458418\n",
      "[3900]\ttraining's l1: 0.207668\tvalid_1's l1: 0.457775\n",
      "[4000]\ttraining's l1: 0.205444\tvalid_1's l1: 0.457322\n",
      "[4100]\ttraining's l1: 0.200593\tvalid_1's l1: 0.455451\n",
      "[4200]\ttraining's l1: 0.19691\tvalid_1's l1: 0.45397\n",
      "[4300]\ttraining's l1: 0.193467\tvalid_1's l1: 0.453036\n",
      "[4400]\ttraining's l1: 0.190167\tvalid_1's l1: 0.452208\n",
      "[4500]\ttraining's l1: 0.186994\tvalid_1's l1: 0.451357\n",
      "[4600]\ttraining's l1: 0.184246\tvalid_1's l1: 0.450638\n",
      "[4700]\ttraining's l1: 0.181614\tvalid_1's l1: 0.450041\n",
      "[4800]\ttraining's l1: 0.179082\tvalid_1's l1: 0.449577\n",
      "[4900]\ttraining's l1: 0.176023\tvalid_1's l1: 0.448784\n",
      "[5000]\ttraining's l1: 0.173513\tvalid_1's l1: 0.448348\n",
      "[5100]\ttraining's l1: 0.171393\tvalid_1's l1: 0.44775\n",
      "[5200]\ttraining's l1: 0.168853\tvalid_1's l1: 0.447295\n",
      "[5300]\ttraining's l1: 0.166581\tvalid_1's l1: 0.446756\n",
      "[5400]\ttraining's l1: 0.164624\tvalid_1's l1: 0.446553\n",
      "[5500]\ttraining's l1: 0.162422\tvalid_1's l1: 0.446149\n",
      "[5600]\ttraining's l1: 0.160643\tvalid_1's l1: 0.44577\n",
      "[5700]\ttraining's l1: 0.158413\tvalid_1's l1: 0.445334\n",
      "[5800]\ttraining's l1: 0.156493\tvalid_1's l1: 0.445062\n",
      "[5900]\ttraining's l1: 0.154735\tvalid_1's l1: 0.444786\n",
      "[6000]\ttraining's l1: 0.152965\tvalid_1's l1: 0.444424\n",
      "[6100]\ttraining's l1: 0.149421\tvalid_1's l1: 0.443332\n",
      "[6200]\ttraining's l1: 0.14663\tvalid_1's l1: 0.442294\n",
      "[6300]\ttraining's l1: 0.144455\tvalid_1's l1: 0.441577\n",
      "[6400]\ttraining's l1: 0.142458\tvalid_1's l1: 0.440924\n",
      "[6500]\ttraining's l1: 0.140618\tvalid_1's l1: 0.440477\n",
      "[6600]\ttraining's l1: 0.138776\tvalid_1's l1: 0.439986\n",
      "[6700]\ttraining's l1: 0.136918\tvalid_1's l1: 0.43947\n",
      "[6800]\ttraining's l1: 0.135187\tvalid_1's l1: 0.438943\n",
      "[6900]\ttraining's l1: 0.133605\tvalid_1's l1: 0.438426\n",
      "[7000]\ttraining's l1: 0.131892\tvalid_1's l1: 0.437967\n",
      "[7100]\ttraining's l1: 0.130416\tvalid_1's l1: 0.43771\n",
      "[7200]\ttraining's l1: 0.128715\tvalid_1's l1: 0.437354\n",
      "[7300]\ttraining's l1: 0.127036\tvalid_1's l1: 0.436797\n",
      "[7400]\ttraining's l1: 0.125319\tvalid_1's l1: 0.436393\n",
      "[7500]\ttraining's l1: 0.123785\tvalid_1's l1: 0.435995\n",
      "[7600]\ttraining's l1: 0.122217\tvalid_1's l1: 0.435725\n",
      "[7700]\ttraining's l1: 0.120833\tvalid_1's l1: 0.435352\n",
      "[7800]\ttraining's l1: 0.119432\tvalid_1's l1: 0.435109\n",
      "[7900]\ttraining's l1: 0.118162\tvalid_1's l1: 0.434772\n",
      "[8000]\ttraining's l1: 0.116851\tvalid_1's l1: 0.434442\n",
      "[8100]\ttraining's l1: 0.114325\tvalid_1's l1: 0.433563\n",
      "[8200]\ttraining's l1: 0.112735\tvalid_1's l1: 0.433212\n",
      "[8300]\ttraining's l1: 0.111259\tvalid_1's l1: 0.433051\n",
      "[8400]\ttraining's l1: 0.109969\tvalid_1's l1: 0.432763\n",
      "[8500]\ttraining's l1: 0.108784\tvalid_1's l1: 0.432405\n",
      "[8600]\ttraining's l1: 0.107649\tvalid_1's l1: 0.431987\n",
      "[8700]\ttraining's l1: 0.106503\tvalid_1's l1: 0.431894\n",
      "[8800]\ttraining's l1: 0.105535\tvalid_1's l1: 0.431768\n",
      "[8900]\ttraining's l1: 0.10451\tvalid_1's l1: 0.431599\n",
      "[9000]\ttraining's l1: 0.103637\tvalid_1's l1: 0.4315\n",
      "[9100]\ttraining's l1: 0.102781\tvalid_1's l1: 0.431353\n",
      "[9200]\ttraining's l1: 0.102096\tvalid_1's l1: 0.431242\n",
      "[9300]\ttraining's l1: 0.101346\tvalid_1's l1: 0.431147\n",
      "[9400]\ttraining's l1: 0.10078\tvalid_1's l1: 0.431051\n",
      "[9500]\ttraining's l1: 0.100238\tvalid_1's l1: 0.430951\n",
      "[9600]\ttraining's l1: 0.0997414\tvalid_1's l1: 0.430874\n",
      "[9700]\ttraining's l1: 0.0991592\tvalid_1's l1: 0.430801\n",
      "[9800]\ttraining's l1: 0.0985952\tvalid_1's l1: 0.430751\n",
      "[9900]\ttraining's l1: 0.0981042\tvalid_1's l1: 0.430648\n",
      "[10000]\ttraining's l1: 0.0975764\tvalid_1's l1: 0.430564\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0975764\tvalid_1's l1: 0.430564\n",
      "1JHN Fold 2, logMAE: -0.8426603112608367\n",
      "*** Training Model for 1JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
      "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
      "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
      "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
      "       'r_z_13', 'r_z_14', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
      "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
      "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
      "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
      "       'r_z_13', 'r_z_14'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 1.61703\tvalid_1's l1: 1.65331\n",
      "[200]\ttraining's l1: 1.26377\tvalid_1's l1: 1.33203\n",
      "[300]\ttraining's l1: 1.11715\tvalid_1's l1: 1.20646\n",
      "[400]\ttraining's l1: 1.0242\tvalid_1's l1: 1.13136\n",
      "[500]\ttraining's l1: 0.957488\tvalid_1's l1: 1.08011\n",
      "[600]\ttraining's l1: 0.905254\tvalid_1's l1: 1.04141\n",
      "[700]\ttraining's l1: 0.864173\tvalid_1's l1: 1.01204\n",
      "[800]\ttraining's l1: 0.83267\tvalid_1's l1: 0.990718\n",
      "[900]\ttraining's l1: 0.803941\tvalid_1's l1: 0.971741\n",
      "[1000]\ttraining's l1: 0.780048\tvalid_1's l1: 0.956002\n",
      "[1100]\ttraining's l1: 0.756115\tvalid_1's l1: 0.941158\n",
      "[1200]\ttraining's l1: 0.735661\tvalid_1's l1: 0.928587\n",
      "[1300]\ttraining's l1: 0.716544\tvalid_1's l1: 0.917226\n",
      "[1400]\ttraining's l1: 0.699738\tvalid_1's l1: 0.907483\n",
      "[1500]\ttraining's l1: 0.683987\tvalid_1's l1: 0.898345\n",
      "[1600]\ttraining's l1: 0.669216\tvalid_1's l1: 0.890242\n",
      "[1700]\ttraining's l1: 0.656705\tvalid_1's l1: 0.883452\n",
      "[1800]\ttraining's l1: 0.643754\tvalid_1's l1: 0.87659\n",
      "[1900]\ttraining's l1: 0.632551\tvalid_1's l1: 0.87107\n",
      "[2000]\ttraining's l1: 0.62149\tvalid_1's l1: 0.865716\n",
      "[2100]\ttraining's l1: 0.610596\tvalid_1's l1: 0.85931\n",
      "[2200]\ttraining's l1: 0.600763\tvalid_1's l1: 0.854031\n",
      "[2300]\ttraining's l1: 0.59139\tvalid_1's l1: 0.849283\n",
      "[2400]\ttraining's l1: 0.581893\tvalid_1's l1: 0.84452\n",
      "[2500]\ttraining's l1: 0.572847\tvalid_1's l1: 0.840165\n",
      "[2600]\ttraining's l1: 0.564244\tvalid_1's l1: 0.836011\n",
      "[2700]\ttraining's l1: 0.556087\tvalid_1's l1: 0.832239\n",
      "[2800]\ttraining's l1: 0.547605\tvalid_1's l1: 0.828149\n",
      "[2900]\ttraining's l1: 0.539463\tvalid_1's l1: 0.82438\n",
      "[3000]\ttraining's l1: 0.531813\tvalid_1's l1: 0.821076\n",
      "[3100]\ttraining's l1: 0.524661\tvalid_1's l1: 0.818023\n",
      "[3200]\ttraining's l1: 0.517447\tvalid_1's l1: 0.814854\n",
      "[3300]\ttraining's l1: 0.510213\tvalid_1's l1: 0.811911\n",
      "[3400]\ttraining's l1: 0.503559\tvalid_1's l1: 0.809118\n",
      "[3500]\ttraining's l1: 0.49609\tvalid_1's l1: 0.806009\n",
      "[3600]\ttraining's l1: 0.48937\tvalid_1's l1: 0.803287\n",
      "[3700]\ttraining's l1: 0.482931\tvalid_1's l1: 0.8007\n",
      "[3800]\ttraining's l1: 0.476852\tvalid_1's l1: 0.798242\n",
      "[3900]\ttraining's l1: 0.470964\tvalid_1's l1: 0.796039\n",
      "[4000]\ttraining's l1: 0.464986\tvalid_1's l1: 0.793674\n",
      "[4100]\ttraining's l1: 0.458558\tvalid_1's l1: 0.791115\n",
      "[4200]\ttraining's l1: 0.453008\tvalid_1's l1: 0.789067\n",
      "[4300]\ttraining's l1: 0.447538\tvalid_1's l1: 0.786914\n",
      "[4400]\ttraining's l1: 0.441704\tvalid_1's l1: 0.784902\n",
      "[4500]\ttraining's l1: 0.436401\tvalid_1's l1: 0.783038\n",
      "[4600]\ttraining's l1: 0.430952\tvalid_1's l1: 0.781122\n",
      "[4700]\ttraining's l1: 0.425699\tvalid_1's l1: 0.779203\n",
      "[4800]\ttraining's l1: 0.420477\tvalid_1's l1: 0.77749\n",
      "[4900]\ttraining's l1: 0.41508\tvalid_1's l1: 0.775666\n",
      "[5000]\ttraining's l1: 0.409958\tvalid_1's l1: 0.773889\n",
      "[5100]\ttraining's l1: 0.405324\tvalid_1's l1: 0.772311\n",
      "[5200]\ttraining's l1: 0.40024\tvalid_1's l1: 0.770671\n",
      "[5300]\ttraining's l1: 0.39569\tvalid_1's l1: 0.769135\n",
      "[5400]\ttraining's l1: 0.391428\tvalid_1's l1: 0.767775\n",
      "[5500]\ttraining's l1: 0.386745\tvalid_1's l1: 0.766262\n",
      "[5600]\ttraining's l1: 0.382359\tvalid_1's l1: 0.764818\n",
      "[5700]\ttraining's l1: 0.378429\tvalid_1's l1: 0.763623\n",
      "[5800]\ttraining's l1: 0.374756\tvalid_1's l1: 0.76256\n",
      "[5900]\ttraining's l1: 0.370987\tvalid_1's l1: 0.761412\n",
      "[6000]\ttraining's l1: 0.367192\tvalid_1's l1: 0.760279\n",
      "[6100]\ttraining's l1: 0.362886\tvalid_1's l1: 0.758927\n",
      "[6200]\ttraining's l1: 0.359039\tvalid_1's l1: 0.75786\n",
      "[6300]\ttraining's l1: 0.355076\tvalid_1's l1: 0.756611\n",
      "[6400]\ttraining's l1: 0.351167\tvalid_1's l1: 0.755493\n",
      "[6500]\ttraining's l1: 0.347375\tvalid_1's l1: 0.754363\n",
      "[6600]\ttraining's l1: 0.343813\tvalid_1's l1: 0.753386\n",
      "[6700]\ttraining's l1: 0.340412\tvalid_1's l1: 0.752451\n",
      "[6800]\ttraining's l1: 0.336746\tvalid_1's l1: 0.751386\n",
      "[6900]\ttraining's l1: 0.333413\tvalid_1's l1: 0.750403\n",
      "[7000]\ttraining's l1: 0.330165\tvalid_1's l1: 0.749499\n",
      "[7100]\ttraining's l1: 0.32694\tvalid_1's l1: 0.748663\n",
      "[7200]\ttraining's l1: 0.323805\tvalid_1's l1: 0.747783\n",
      "[7300]\ttraining's l1: 0.320959\tvalid_1's l1: 0.747046\n",
      "[7400]\ttraining's l1: 0.317861\tvalid_1's l1: 0.74621\n",
      "[7500]\ttraining's l1: 0.315054\tvalid_1's l1: 0.745451\n",
      "[7600]\ttraining's l1: 0.311932\tvalid_1's l1: 0.744597\n",
      "[7700]\ttraining's l1: 0.309191\tvalid_1's l1: 0.743918\n",
      "[7800]\ttraining's l1: 0.306693\tvalid_1's l1: 0.743309\n",
      "[7900]\ttraining's l1: 0.303831\tvalid_1's l1: 0.742569\n",
      "[8000]\ttraining's l1: 0.300988\tvalid_1's l1: 0.741871\n",
      "[8100]\ttraining's l1: 0.297492\tvalid_1's l1: 0.740824\n",
      "[8200]\ttraining's l1: 0.294648\tvalid_1's l1: 0.740039\n",
      "[8300]\ttraining's l1: 0.292049\tvalid_1's l1: 0.739389\n",
      "[8400]\ttraining's l1: 0.289092\tvalid_1's l1: 0.738675\n",
      "[8500]\ttraining's l1: 0.286507\tvalid_1's l1: 0.738076\n",
      "[8600]\ttraining's l1: 0.283779\tvalid_1's l1: 0.737384\n",
      "[8700]\ttraining's l1: 0.28117\tvalid_1's l1: 0.736749\n",
      "[8800]\ttraining's l1: 0.278547\tvalid_1's l1: 0.736065\n",
      "[8900]\ttraining's l1: 0.275902\tvalid_1's l1: 0.735414\n",
      "[9000]\ttraining's l1: 0.273312\tvalid_1's l1: 0.73479\n",
      "[9100]\ttraining's l1: 0.270824\tvalid_1's l1: 0.73422\n",
      "[9200]\ttraining's l1: 0.268328\tvalid_1's l1: 0.733636\n",
      "[9300]\ttraining's l1: 0.265964\tvalid_1's l1: 0.733105\n",
      "[9400]\ttraining's l1: 0.263624\tvalid_1's l1: 0.73261\n",
      "[9500]\ttraining's l1: 0.261176\tvalid_1's l1: 0.732031\n",
      "[9600]\ttraining's l1: 0.259121\tvalid_1's l1: 0.731563\n",
      "[9700]\ttraining's l1: 0.25703\tvalid_1's l1: 0.731087\n",
      "[9800]\ttraining's l1: 0.254834\tvalid_1's l1: 0.730575\n",
      "[9900]\ttraining's l1: 0.252558\tvalid_1's l1: 0.730031\n",
      "[10000]\ttraining's l1: 0.250528\tvalid_1's l1: 0.729586\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.250528\tvalid_1's l1: 0.729586\n",
      "1JHC Fold 0, logMAE: -0.3152830731482107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 1.61583\tvalid_1's l1: 1.66255\n",
      "[200]\ttraining's l1: 1.25573\tvalid_1's l1: 1.32854\n",
      "[300]\ttraining's l1: 1.10822\tvalid_1's l1: 1.202\n",
      "[400]\ttraining's l1: 1.01738\tvalid_1's l1: 1.12884\n",
      "[500]\ttraining's l1: 0.95171\tvalid_1's l1: 1.07798\n",
      "[600]\ttraining's l1: 0.903396\tvalid_1's l1: 1.04244\n",
      "[700]\ttraining's l1: 0.863812\tvalid_1's l1: 1.01466\n",
      "[800]\ttraining's l1: 0.831055\tvalid_1's l1: 0.992237\n",
      "[900]\ttraining's l1: 0.80284\tvalid_1's l1: 0.973726\n",
      "[1000]\ttraining's l1: 0.77857\tvalid_1's l1: 0.958165\n",
      "[1100]\ttraining's l1: 0.755821\tvalid_1's l1: 0.943962\n",
      "[1200]\ttraining's l1: 0.736435\tvalid_1's l1: 0.932193\n",
      "[1300]\ttraining's l1: 0.717712\tvalid_1's l1: 0.921035\n",
      "[1400]\ttraining's l1: 0.700155\tvalid_1's l1: 0.910763\n",
      "[1500]\ttraining's l1: 0.684665\tvalid_1's l1: 0.902094\n",
      "[1600]\ttraining's l1: 0.670348\tvalid_1's l1: 0.894687\n",
      "[1700]\ttraining's l1: 0.656686\tvalid_1's l1: 0.887473\n",
      "[1800]\ttraining's l1: 0.643592\tvalid_1's l1: 0.880815\n",
      "[1900]\ttraining's l1: 0.631602\tvalid_1's l1: 0.874773\n",
      "[2000]\ttraining's l1: 0.621363\tvalid_1's l1: 0.869755\n",
      "[2100]\ttraining's l1: 0.610877\tvalid_1's l1: 0.863488\n",
      "[2200]\ttraining's l1: 0.600923\tvalid_1's l1: 0.857906\n",
      "[2300]\ttraining's l1: 0.590685\tvalid_1's l1: 0.852601\n",
      "[2400]\ttraining's l1: 0.580651\tvalid_1's l1: 0.847398\n",
      "[2500]\ttraining's l1: 0.571106\tvalid_1's l1: 0.842704\n",
      "[2600]\ttraining's l1: 0.561872\tvalid_1's l1: 0.838314\n",
      "[2700]\ttraining's l1: 0.55371\tvalid_1's l1: 0.834621\n",
      "[2800]\ttraining's l1: 0.544839\tvalid_1's l1: 0.830363\n",
      "[2900]\ttraining's l1: 0.537011\tvalid_1's l1: 0.826855\n",
      "[3000]\ttraining's l1: 0.528542\tvalid_1's l1: 0.82312\n",
      "[3100]\ttraining's l1: 0.521222\tvalid_1's l1: 0.81997\n",
      "[3200]\ttraining's l1: 0.513571\tvalid_1's l1: 0.816594\n",
      "[3300]\ttraining's l1: 0.506436\tvalid_1's l1: 0.813788\n",
      "[3400]\ttraining's l1: 0.498993\tvalid_1's l1: 0.810811\n",
      "[3500]\ttraining's l1: 0.491954\tvalid_1's l1: 0.807994\n",
      "[3600]\ttraining's l1: 0.485387\tvalid_1's l1: 0.805409\n",
      "[3700]\ttraining's l1: 0.479033\tvalid_1's l1: 0.802934\n",
      "[3800]\ttraining's l1: 0.472692\tvalid_1's l1: 0.800603\n",
      "[3900]\ttraining's l1: 0.466197\tvalid_1's l1: 0.798034\n",
      "[4000]\ttraining's l1: 0.460586\tvalid_1's l1: 0.795929\n",
      "[4100]\ttraining's l1: 0.453852\tvalid_1's l1: 0.793379\n",
      "[4200]\ttraining's l1: 0.44845\tvalid_1's l1: 0.791335\n",
      "[4300]\ttraining's l1: 0.442513\tvalid_1's l1: 0.789185\n",
      "[4400]\ttraining's l1: 0.437525\tvalid_1's l1: 0.787444\n",
      "[4500]\ttraining's l1: 0.432566\tvalid_1's l1: 0.785598\n",
      "[4600]\ttraining's l1: 0.427513\tvalid_1's l1: 0.783835\n",
      "[4700]\ttraining's l1: 0.422146\tvalid_1's l1: 0.782021\n",
      "[4800]\ttraining's l1: 0.417369\tvalid_1's l1: 0.78034\n",
      "[4900]\ttraining's l1: 0.412663\tvalid_1's l1: 0.778644\n",
      "[5000]\ttraining's l1: 0.408113\tvalid_1's l1: 0.777121\n",
      "[5100]\ttraining's l1: 0.403324\tvalid_1's l1: 0.775549\n",
      "[5200]\ttraining's l1: 0.398856\tvalid_1's l1: 0.774092\n",
      "[5300]\ttraining's l1: 0.394348\tvalid_1's l1: 0.772565\n",
      "[5400]\ttraining's l1: 0.389505\tvalid_1's l1: 0.77102\n",
      "[5500]\ttraining's l1: 0.385183\tvalid_1's l1: 0.769685\n",
      "[5600]\ttraining's l1: 0.381229\tvalid_1's l1: 0.768495\n",
      "[5700]\ttraining's l1: 0.376962\tvalid_1's l1: 0.767165\n",
      "[5800]\ttraining's l1: 0.372602\tvalid_1's l1: 0.765922\n",
      "[5900]\ttraining's l1: 0.368672\tvalid_1's l1: 0.764705\n",
      "[6000]\ttraining's l1: 0.365019\tvalid_1's l1: 0.763619\n",
      "[6100]\ttraining's l1: 0.360659\tvalid_1's l1: 0.762052\n",
      "[6200]\ttraining's l1: 0.356982\tvalid_1's l1: 0.760943\n",
      "[6300]\ttraining's l1: 0.353569\tvalid_1's l1: 0.759964\n",
      "[6400]\ttraining's l1: 0.349442\tvalid_1's l1: 0.758729\n",
      "[6500]\ttraining's l1: 0.345918\tvalid_1's l1: 0.757656\n",
      "[6600]\ttraining's l1: 0.342427\tvalid_1's l1: 0.756607\n",
      "[6700]\ttraining's l1: 0.339046\tvalid_1's l1: 0.755676\n",
      "[6800]\ttraining's l1: 0.335851\tvalid_1's l1: 0.75483\n",
      "[6900]\ttraining's l1: 0.332585\tvalid_1's l1: 0.75392\n",
      "[7000]\ttraining's l1: 0.329349\tvalid_1's l1: 0.752982\n",
      "[7100]\ttraining's l1: 0.325985\tvalid_1's l1: 0.752093\n",
      "[7200]\ttraining's l1: 0.323122\tvalid_1's l1: 0.751373\n",
      "[7300]\ttraining's l1: 0.320025\tvalid_1's l1: 0.75048\n",
      "[7400]\ttraining's l1: 0.316826\tvalid_1's l1: 0.749675\n",
      "[7500]\ttraining's l1: 0.313654\tvalid_1's l1: 0.748901\n",
      "[7600]\ttraining's l1: 0.31068\tvalid_1's l1: 0.748165\n",
      "[7700]\ttraining's l1: 0.307728\tvalid_1's l1: 0.74738\n",
      "[7800]\ttraining's l1: 0.305055\tvalid_1's l1: 0.74671\n",
      "[7900]\ttraining's l1: 0.302548\tvalid_1's l1: 0.746038\n",
      "[8000]\ttraining's l1: 0.300048\tvalid_1's l1: 0.745389\n",
      "[8100]\ttraining's l1: 0.29686\tvalid_1's l1: 0.744535\n",
      "[8200]\ttraining's l1: 0.293911\tvalid_1's l1: 0.743795\n",
      "[8300]\ttraining's l1: 0.290792\tvalid_1's l1: 0.742953\n",
      "[8400]\ttraining's l1: 0.287676\tvalid_1's l1: 0.742071\n",
      "[8500]\ttraining's l1: 0.284713\tvalid_1's l1: 0.741344\n",
      "[8600]\ttraining's l1: 0.281887\tvalid_1's l1: 0.740564\n",
      "[8700]\ttraining's l1: 0.279225\tvalid_1's l1: 0.739902\n",
      "[8800]\ttraining's l1: 0.276765\tvalid_1's l1: 0.739267\n",
      "[8900]\ttraining's l1: 0.274409\tvalid_1's l1: 0.738675\n",
      "[9000]\ttraining's l1: 0.271735\tvalid_1's l1: 0.738067\n",
      "[9100]\ttraining's l1: 0.269246\tvalid_1's l1: 0.737476\n",
      "[9200]\ttraining's l1: 0.266809\tvalid_1's l1: 0.736886\n",
      "[9300]\ttraining's l1: 0.264397\tvalid_1's l1: 0.736353\n",
      "[9400]\ttraining's l1: 0.262164\tvalid_1's l1: 0.735878\n",
      "[9500]\ttraining's l1: 0.259828\tvalid_1's l1: 0.735348\n",
      "[9600]\ttraining's l1: 0.257298\tvalid_1's l1: 0.734777\n",
      "[9700]\ttraining's l1: 0.255074\tvalid_1's l1: 0.734287\n",
      "[9800]\ttraining's l1: 0.25285\tvalid_1's l1: 0.73381\n",
      "[9900]\ttraining's l1: 0.250513\tvalid_1's l1: 0.733286\n",
      "[10000]\ttraining's l1: 0.248535\tvalid_1's l1: 0.73288\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.248535\tvalid_1's l1: 0.73288\n",
      "1JHC Fold 1, logMAE: -0.31077291174136634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 1.62056\tvalid_1's l1: 1.66525\n",
      "[200]\ttraining's l1: 1.26364\tvalid_1's l1: 1.33723\n",
      "[300]\ttraining's l1: 1.11427\tvalid_1's l1: 1.20884\n",
      "[400]\ttraining's l1: 1.01867\tvalid_1's l1: 1.1306\n",
      "[500]\ttraining's l1: 0.954788\tvalid_1's l1: 1.08084\n",
      "[600]\ttraining's l1: 0.908724\tvalid_1's l1: 1.04649\n",
      "[700]\ttraining's l1: 0.867326\tvalid_1's l1: 1.0166\n",
      "[800]\ttraining's l1: 0.834282\tvalid_1's l1: 0.993678\n",
      "[900]\ttraining's l1: 0.806131\tvalid_1's l1: 0.974742\n",
      "[1000]\ttraining's l1: 0.780738\tvalid_1's l1: 0.958688\n",
      "[1100]\ttraining's l1: 0.75899\tvalid_1's l1: 0.945057\n",
      "[1200]\ttraining's l1: 0.73948\tvalid_1's l1: 0.933556\n",
      "[1300]\ttraining's l1: 0.720852\tvalid_1's l1: 0.922744\n",
      "[1400]\ttraining's l1: 0.703745\tvalid_1's l1: 0.912663\n",
      "[1500]\ttraining's l1: 0.687659\tvalid_1's l1: 0.903599\n",
      "[1600]\ttraining's l1: 0.674191\tvalid_1's l1: 0.896228\n",
      "[1700]\ttraining's l1: 0.659801\tvalid_1's l1: 0.888488\n",
      "[1800]\ttraining's l1: 0.646919\tvalid_1's l1: 0.881621\n",
      "[1900]\ttraining's l1: 0.63486\tvalid_1's l1: 0.875354\n",
      "[2000]\ttraining's l1: 0.624061\tvalid_1's l1: 0.869983\n",
      "[2100]\ttraining's l1: 0.612714\tvalid_1's l1: 0.863313\n",
      "[2200]\ttraining's l1: 0.601833\tvalid_1's l1: 0.857279\n",
      "[2300]\ttraining's l1: 0.591951\tvalid_1's l1: 0.851871\n",
      "[2400]\ttraining's l1: 0.582647\tvalid_1's l1: 0.847185\n",
      "[2500]\ttraining's l1: 0.573302\tvalid_1's l1: 0.842566\n",
      "[2600]\ttraining's l1: 0.56422\tvalid_1's l1: 0.838118\n",
      "[2700]\ttraining's l1: 0.555595\tvalid_1's l1: 0.833941\n",
      "[2800]\ttraining's l1: 0.547467\tvalid_1's l1: 0.830147\n",
      "[2900]\ttraining's l1: 0.539414\tvalid_1's l1: 0.826456\n",
      "[3000]\ttraining's l1: 0.531595\tvalid_1's l1: 0.822804\n",
      "[3100]\ttraining's l1: 0.52246\tvalid_1's l1: 0.818807\n",
      "[3200]\ttraining's l1: 0.515258\tvalid_1's l1: 0.815673\n",
      "[3300]\ttraining's l1: 0.507616\tvalid_1's l1: 0.812483\n",
      "[3400]\ttraining's l1: 0.500189\tvalid_1's l1: 0.809361\n",
      "[3500]\ttraining's l1: 0.493641\tvalid_1's l1: 0.806791\n",
      "[3600]\ttraining's l1: 0.487178\tvalid_1's l1: 0.804243\n",
      "[3700]\ttraining's l1: 0.48098\tvalid_1's l1: 0.801831\n",
      "[3800]\ttraining's l1: 0.47486\tvalid_1's l1: 0.799623\n",
      "[3900]\ttraining's l1: 0.468792\tvalid_1's l1: 0.797414\n",
      "[4000]\ttraining's l1: 0.462994\tvalid_1's l1: 0.795285\n",
      "[4100]\ttraining's l1: 0.456346\tvalid_1's l1: 0.792768\n",
      "[4200]\ttraining's l1: 0.450927\tvalid_1's l1: 0.790858\n",
      "[4300]\ttraining's l1: 0.44567\tvalid_1's l1: 0.788877\n",
      "[4400]\ttraining's l1: 0.4397\tvalid_1's l1: 0.786651\n",
      "[4500]\ttraining's l1: 0.434607\tvalid_1's l1: 0.784745\n",
      "[4600]\ttraining's l1: 0.429536\tvalid_1's l1: 0.782949\n",
      "[4700]\ttraining's l1: 0.424444\tvalid_1's l1: 0.781342\n",
      "[4800]\ttraining's l1: 0.419265\tvalid_1's l1: 0.77957\n",
      "[4900]\ttraining's l1: 0.414239\tvalid_1's l1: 0.777752\n",
      "[5000]\ttraining's l1: 0.408905\tvalid_1's l1: 0.775983\n",
      "[5100]\ttraining's l1: 0.403803\tvalid_1's l1: 0.774371\n",
      "[5200]\ttraining's l1: 0.399285\tvalid_1's l1: 0.772886\n",
      "[5300]\ttraining's l1: 0.394421\tvalid_1's l1: 0.771205\n",
      "[5400]\ttraining's l1: 0.389775\tvalid_1's l1: 0.76975\n",
      "[5500]\ttraining's l1: 0.385506\tvalid_1's l1: 0.76845\n",
      "[5600]\ttraining's l1: 0.381417\tvalid_1's l1: 0.767109\n",
      "[5700]\ttraining's l1: 0.377384\tvalid_1's l1: 0.765861\n",
      "[5800]\ttraining's l1: 0.373313\tvalid_1's l1: 0.764691\n",
      "[5900]\ttraining's l1: 0.369352\tvalid_1's l1: 0.763505\n",
      "[6000]\ttraining's l1: 0.365618\tvalid_1's l1: 0.76237\n",
      "[6100]\ttraining's l1: 0.361413\tvalid_1's l1: 0.76101\n",
      "[6200]\ttraining's l1: 0.357489\tvalid_1's l1: 0.759729\n",
      "[6300]\ttraining's l1: 0.353464\tvalid_1's l1: 0.758518\n",
      "[6400]\ttraining's l1: 0.349736\tvalid_1's l1: 0.757382\n",
      "[6500]\ttraining's l1: 0.346025\tvalid_1's l1: 0.756232\n",
      "[6600]\ttraining's l1: 0.342319\tvalid_1's l1: 0.755199\n",
      "[6700]\ttraining's l1: 0.338427\tvalid_1's l1: 0.754094\n",
      "[6800]\ttraining's l1: 0.334938\tvalid_1's l1: 0.75314\n",
      "[6900]\ttraining's l1: 0.33156\tvalid_1's l1: 0.752186\n",
      "[7000]\ttraining's l1: 0.328388\tvalid_1's l1: 0.751361\n",
      "[7100]\ttraining's l1: 0.325203\tvalid_1's l1: 0.750486\n",
      "[7200]\ttraining's l1: 0.322073\tvalid_1's l1: 0.749615\n",
      "[7300]\ttraining's l1: 0.318984\tvalid_1's l1: 0.748777\n",
      "[7400]\ttraining's l1: 0.315935\tvalid_1's l1: 0.747938\n",
      "[7500]\ttraining's l1: 0.313099\tvalid_1's l1: 0.747112\n",
      "[7600]\ttraining's l1: 0.310218\tvalid_1's l1: 0.746332\n",
      "[7700]\ttraining's l1: 0.307291\tvalid_1's l1: 0.745534\n",
      "[7800]\ttraining's l1: 0.304477\tvalid_1's l1: 0.744848\n",
      "[7900]\ttraining's l1: 0.301915\tvalid_1's l1: 0.744234\n",
      "[8000]\ttraining's l1: 0.299275\tvalid_1's l1: 0.743562\n",
      "[8100]\ttraining's l1: 0.29642\tvalid_1's l1: 0.742698\n",
      "[8200]\ttraining's l1: 0.293654\tvalid_1's l1: 0.741946\n",
      "[8300]\ttraining's l1: 0.290626\tvalid_1's l1: 0.741144\n",
      "[8400]\ttraining's l1: 0.287525\tvalid_1's l1: 0.740404\n",
      "[8500]\ttraining's l1: 0.284716\tvalid_1's l1: 0.739713\n",
      "[8600]\ttraining's l1: 0.282129\tvalid_1's l1: 0.739063\n",
      "[8700]\ttraining's l1: 0.279514\tvalid_1's l1: 0.738451\n",
      "[8800]\ttraining's l1: 0.276739\tvalid_1's l1: 0.737792\n",
      "[8900]\ttraining's l1: 0.274132\tvalid_1's l1: 0.73711\n",
      "[9000]\ttraining's l1: 0.271672\tvalid_1's l1: 0.736499\n",
      "[9100]\ttraining's l1: 0.269239\tvalid_1's l1: 0.735892\n",
      "[9200]\ttraining's l1: 0.266658\tvalid_1's l1: 0.735277\n",
      "[9300]\ttraining's l1: 0.264286\tvalid_1's l1: 0.734742\n",
      "[9400]\ttraining's l1: 0.261988\tvalid_1's l1: 0.734226\n",
      "[9500]\ttraining's l1: 0.259806\tvalid_1's l1: 0.733743\n",
      "[9600]\ttraining's l1: 0.257577\tvalid_1's l1: 0.733246\n",
      "[9700]\ttraining's l1: 0.255334\tvalid_1's l1: 0.732726\n",
      "[9800]\ttraining's l1: 0.253106\tvalid_1's l1: 0.732258\n",
      "[9900]\ttraining's l1: 0.251121\tvalid_1's l1: 0.731794\n",
      "[10000]\ttraining's l1: 0.249167\tvalid_1's l1: 0.731357\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.249167\tvalid_1's l1: 0.731357\n",
      "1JHC Fold 2, logMAE: -0.3128535235843799\n",
      "*** Training Model for 2JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.32679\tvalid_1's l1: 0.34356\n",
      "[200]\ttraining's l1: 0.267017\tvalid_1's l1: 0.291971\n",
      "[300]\ttraining's l1: 0.240857\tvalid_1's l1: 0.270956\n",
      "[400]\ttraining's l1: 0.223532\tvalid_1's l1: 0.257738\n",
      "[500]\ttraining's l1: 0.212325\tvalid_1's l1: 0.249564\n",
      "[600]\ttraining's l1: 0.202263\tvalid_1's l1: 0.242658\n",
      "[700]\ttraining's l1: 0.194264\tvalid_1's l1: 0.237322\n",
      "[800]\ttraining's l1: 0.187058\tvalid_1's l1: 0.232653\n",
      "[900]\ttraining's l1: 0.180633\tvalid_1's l1: 0.228677\n",
      "[1000]\ttraining's l1: 0.175084\tvalid_1's l1: 0.225334\n",
      "[1100]\ttraining's l1: 0.170132\tvalid_1's l1: 0.222464\n",
      "[1200]\ttraining's l1: 0.165592\tvalid_1's l1: 0.219956\n",
      "[1300]\ttraining's l1: 0.16169\tvalid_1's l1: 0.217762\n",
      "[1400]\ttraining's l1: 0.157702\tvalid_1's l1: 0.215656\n",
      "[1500]\ttraining's l1: 0.153899\tvalid_1's l1: 0.213592\n",
      "[1600]\ttraining's l1: 0.150461\tvalid_1's l1: 0.21182\n",
      "[1700]\ttraining's l1: 0.147267\tvalid_1's l1: 0.210188\n",
      "[1800]\ttraining's l1: 0.144322\tvalid_1's l1: 0.208702\n",
      "[1900]\ttraining's l1: 0.141292\tvalid_1's l1: 0.207242\n",
      "[2000]\ttraining's l1: 0.138691\tvalid_1's l1: 0.20597\n",
      "[2100]\ttraining's l1: 0.135483\tvalid_1's l1: 0.204056\n",
      "[2200]\ttraining's l1: 0.132809\tvalid_1's l1: 0.202686\n",
      "[2300]\ttraining's l1: 0.130416\tvalid_1's l1: 0.201526\n",
      "[2400]\ttraining's l1: 0.128161\tvalid_1's l1: 0.200444\n",
      "[2500]\ttraining's l1: 0.125938\tvalid_1's l1: 0.199445\n",
      "[2600]\ttraining's l1: 0.123686\tvalid_1's l1: 0.198392\n",
      "[2700]\ttraining's l1: 0.121463\tvalid_1's l1: 0.197379\n",
      "[2800]\ttraining's l1: 0.119386\tvalid_1's l1: 0.196483\n",
      "[2900]\ttraining's l1: 0.117258\tvalid_1's l1: 0.195628\n",
      "[3000]\ttraining's l1: 0.115388\tvalid_1's l1: 0.194808\n",
      "[3100]\ttraining's l1: 0.113569\tvalid_1's l1: 0.194039\n",
      "[3200]\ttraining's l1: 0.111645\tvalid_1's l1: 0.193207\n",
      "[3300]\ttraining's l1: 0.109914\tvalid_1's l1: 0.192488\n",
      "[3400]\ttraining's l1: 0.108225\tvalid_1's l1: 0.191816\n",
      "[3500]\ttraining's l1: 0.10664\tvalid_1's l1: 0.191212\n",
      "[3600]\ttraining's l1: 0.104962\tvalid_1's l1: 0.190555\n",
      "[3700]\ttraining's l1: 0.103488\tvalid_1's l1: 0.18997\n",
      "[3800]\ttraining's l1: 0.101861\tvalid_1's l1: 0.189368\n",
      "[3900]\ttraining's l1: 0.100502\tvalid_1's l1: 0.188887\n",
      "[4000]\ttraining's l1: 0.0991444\tvalid_1's l1: 0.188409\n",
      "[4100]\ttraining's l1: 0.0976057\tvalid_1's l1: 0.187803\n",
      "[4200]\ttraining's l1: 0.0963113\tvalid_1's l1: 0.187324\n",
      "[4300]\ttraining's l1: 0.0949535\tvalid_1's l1: 0.186839\n",
      "[4400]\ttraining's l1: 0.0935916\tvalid_1's l1: 0.186327\n",
      "[4500]\ttraining's l1: 0.0923074\tvalid_1's l1: 0.185885\n",
      "[4600]\ttraining's l1: 0.0911129\tvalid_1's l1: 0.185465\n",
      "[4700]\ttraining's l1: 0.0899831\tvalid_1's l1: 0.185063\n",
      "[4800]\ttraining's l1: 0.0887647\tvalid_1's l1: 0.184646\n",
      "[4900]\ttraining's l1: 0.0874911\tvalid_1's l1: 0.184238\n",
      "[5000]\ttraining's l1: 0.0863615\tvalid_1's l1: 0.183887\n",
      "[5100]\ttraining's l1: 0.0852082\tvalid_1's l1: 0.183535\n",
      "[5200]\ttraining's l1: 0.0840578\tvalid_1's l1: 0.183129\n",
      "[5300]\ttraining's l1: 0.0829562\tvalid_1's l1: 0.182764\n",
      "[5400]\ttraining's l1: 0.0819604\tvalid_1's l1: 0.182466\n",
      "[5500]\ttraining's l1: 0.0809995\tvalid_1's l1: 0.182168\n",
      "[5600]\ttraining's l1: 0.0799813\tvalid_1's l1: 0.181848\n",
      "[5700]\ttraining's l1: 0.0790249\tvalid_1's l1: 0.18156\n",
      "[5800]\ttraining's l1: 0.0781166\tvalid_1's l1: 0.181299\n",
      "[5900]\ttraining's l1: 0.0771913\tvalid_1's l1: 0.181041\n",
      "[6000]\ttraining's l1: 0.0762636\tvalid_1's l1: 0.180774\n",
      "[6100]\ttraining's l1: 0.0751941\tvalid_1's l1: 0.180415\n",
      "[6200]\ttraining's l1: 0.0743731\tvalid_1's l1: 0.180173\n",
      "[6300]\ttraining's l1: 0.0735919\tvalid_1's l1: 0.17997\n",
      "[6400]\ttraining's l1: 0.0728243\tvalid_1's l1: 0.179761\n",
      "[6500]\ttraining's l1: 0.0720321\tvalid_1's l1: 0.179567\n",
      "[6600]\ttraining's l1: 0.0712518\tvalid_1's l1: 0.17933\n",
      "[6700]\ttraining's l1: 0.0704686\tvalid_1's l1: 0.179102\n",
      "[6800]\ttraining's l1: 0.069715\tvalid_1's l1: 0.178902\n",
      "[6900]\ttraining's l1: 0.068977\tvalid_1's l1: 0.178702\n",
      "[7000]\ttraining's l1: 0.0682425\tvalid_1's l1: 0.178486\n",
      "[7100]\ttraining's l1: 0.0675335\tvalid_1's l1: 0.178312\n",
      "[7200]\ttraining's l1: 0.0668024\tvalid_1's l1: 0.178113\n",
      "[7300]\ttraining's l1: 0.0661357\tvalid_1's l1: 0.177936\n",
      "[7400]\ttraining's l1: 0.0653867\tvalid_1's l1: 0.177732\n",
      "[7500]\ttraining's l1: 0.0647582\tvalid_1's l1: 0.177579\n",
      "[7600]\ttraining's l1: 0.0641525\tvalid_1's l1: 0.177442\n",
      "[7700]\ttraining's l1: 0.063528\tvalid_1's l1: 0.177284\n",
      "[7800]\ttraining's l1: 0.0628649\tvalid_1's l1: 0.177113\n",
      "[7900]\ttraining's l1: 0.0622545\tvalid_1's l1: 0.176962\n",
      "[8000]\ttraining's l1: 0.0616508\tvalid_1's l1: 0.176805\n",
      "[8100]\ttraining's l1: 0.0609021\tvalid_1's l1: 0.176574\n",
      "[8200]\ttraining's l1: 0.0602584\tvalid_1's l1: 0.176413\n",
      "[8300]\ttraining's l1: 0.059669\tvalid_1's l1: 0.176263\n",
      "[8400]\ttraining's l1: 0.0591242\tvalid_1's l1: 0.176138\n",
      "[8500]\ttraining's l1: 0.0585289\tvalid_1's l1: 0.175999\n",
      "[8600]\ttraining's l1: 0.0579808\tvalid_1's l1: 0.175865\n",
      "[8700]\ttraining's l1: 0.057474\tvalid_1's l1: 0.175748\n",
      "[8800]\ttraining's l1: 0.0568784\tvalid_1's l1: 0.175619\n",
      "[8900]\ttraining's l1: 0.0563183\tvalid_1's l1: 0.175484\n",
      "[9000]\ttraining's l1: 0.0557907\tvalid_1's l1: 0.175355\n",
      "[9100]\ttraining's l1: 0.0553011\tvalid_1's l1: 0.175255\n",
      "[9200]\ttraining's l1: 0.0547803\tvalid_1's l1: 0.175153\n",
      "[9300]\ttraining's l1: 0.0542771\tvalid_1's l1: 0.175019\n",
      "[9400]\ttraining's l1: 0.0538216\tvalid_1's l1: 0.174904\n",
      "[9500]\ttraining's l1: 0.0533472\tvalid_1's l1: 0.174789\n",
      "[9600]\ttraining's l1: 0.0528323\tvalid_1's l1: 0.17468\n",
      "[9700]\ttraining's l1: 0.0523649\tvalid_1's l1: 0.174577\n",
      "[9800]\ttraining's l1: 0.0519099\tvalid_1's l1: 0.174474\n",
      "[9900]\ttraining's l1: 0.0514634\tvalid_1's l1: 0.174374\n",
      "[10000]\ttraining's l1: 0.050996\tvalid_1's l1: 0.174274\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.050996\tvalid_1's l1: 0.174274\n",
      "2JHH Fold 0, logMAE: -1.747099884428782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.326968\tvalid_1's l1: 0.341338\n",
      "[200]\ttraining's l1: 0.267635\tvalid_1's l1: 0.289899\n",
      "[300]\ttraining's l1: 0.242367\tvalid_1's l1: 0.269199\n",
      "[400]\ttraining's l1: 0.225867\tvalid_1's l1: 0.256621\n",
      "[500]\ttraining's l1: 0.213505\tvalid_1's l1: 0.247547\n",
      "[600]\ttraining's l1: 0.202705\tvalid_1's l1: 0.240185\n",
      "[700]\ttraining's l1: 0.1942\tvalid_1's l1: 0.234693\n",
      "[800]\ttraining's l1: 0.186396\tvalid_1's l1: 0.229841\n",
      "[900]\ttraining's l1: 0.179637\tvalid_1's l1: 0.22581\n",
      "[1000]\ttraining's l1: 0.173586\tvalid_1's l1: 0.22226\n",
      "[1100]\ttraining's l1: 0.168363\tvalid_1's l1: 0.219352\n",
      "[1200]\ttraining's l1: 0.163278\tvalid_1's l1: 0.216555\n",
      "[1300]\ttraining's l1: 0.159145\tvalid_1's l1: 0.214311\n",
      "[1400]\ttraining's l1: 0.155065\tvalid_1's l1: 0.212153\n",
      "[1500]\ttraining's l1: 0.151405\tvalid_1's l1: 0.210254\n",
      "[1600]\ttraining's l1: 0.148033\tvalid_1's l1: 0.208595\n",
      "[1700]\ttraining's l1: 0.144765\tvalid_1's l1: 0.207035\n",
      "[1800]\ttraining's l1: 0.141822\tvalid_1's l1: 0.205615\n",
      "[1900]\ttraining's l1: 0.138779\tvalid_1's l1: 0.204183\n",
      "[2000]\ttraining's l1: 0.136021\tvalid_1's l1: 0.202924\n",
      "[2100]\ttraining's l1: 0.133495\tvalid_1's l1: 0.201485\n",
      "[2200]\ttraining's l1: 0.131362\tvalid_1's l1: 0.200383\n",
      "[2300]\ttraining's l1: 0.129296\tvalid_1's l1: 0.199384\n",
      "[2400]\ttraining's l1: 0.127203\tvalid_1's l1: 0.198433\n",
      "[2500]\ttraining's l1: 0.125281\tvalid_1's l1: 0.197635\n",
      "[2600]\ttraining's l1: 0.123558\tvalid_1's l1: 0.196872\n",
      "[2700]\ttraining's l1: 0.121675\tvalid_1's l1: 0.196131\n",
      "[2800]\ttraining's l1: 0.119914\tvalid_1's l1: 0.195345\n",
      "[2900]\ttraining's l1: 0.118213\tvalid_1's l1: 0.194609\n",
      "[3000]\ttraining's l1: 0.116514\tvalid_1's l1: 0.193898\n",
      "[3100]\ttraining's l1: 0.114705\tvalid_1's l1: 0.193198\n",
      "[3200]\ttraining's l1: 0.113129\tvalid_1's l1: 0.192593\n",
      "[3300]\ttraining's l1: 0.111595\tvalid_1's l1: 0.192008\n",
      "[3400]\ttraining's l1: 0.110102\tvalid_1's l1: 0.19144\n",
      "[3500]\ttraining's l1: 0.108435\tvalid_1's l1: 0.190779\n",
      "[3600]\ttraining's l1: 0.106869\tvalid_1's l1: 0.190138\n",
      "[3700]\ttraining's l1: 0.105407\tvalid_1's l1: 0.189562\n",
      "[3800]\ttraining's l1: 0.103908\tvalid_1's l1: 0.189006\n",
      "[3900]\ttraining's l1: 0.102619\tvalid_1's l1: 0.188527\n",
      "[4000]\ttraining's l1: 0.101221\tvalid_1's l1: 0.188015\n",
      "[4100]\ttraining's l1: 0.0997694\tvalid_1's l1: 0.187483\n",
      "[4200]\ttraining's l1: 0.0983956\tvalid_1's l1: 0.186993\n",
      "[4300]\ttraining's l1: 0.0970219\tvalid_1's l1: 0.186477\n",
      "[4400]\ttraining's l1: 0.095742\tvalid_1's l1: 0.186032\n",
      "[4500]\ttraining's l1: 0.0945409\tvalid_1's l1: 0.185645\n",
      "[4600]\ttraining's l1: 0.0933413\tvalid_1's l1: 0.185283\n",
      "[4700]\ttraining's l1: 0.0921062\tvalid_1's l1: 0.184854\n",
      "[4800]\ttraining's l1: 0.0910014\tvalid_1's l1: 0.184508\n",
      "[4900]\ttraining's l1: 0.0898775\tvalid_1's l1: 0.18414\n",
      "[5000]\ttraining's l1: 0.088778\tvalid_1's l1: 0.183773\n",
      "[5100]\ttraining's l1: 0.087836\tvalid_1's l1: 0.183449\n",
      "[5200]\ttraining's l1: 0.0867683\tvalid_1's l1: 0.183092\n",
      "[5300]\ttraining's l1: 0.0857078\tvalid_1's l1: 0.18277\n",
      "[5400]\ttraining's l1: 0.0846562\tvalid_1's l1: 0.182484\n",
      "[5500]\ttraining's l1: 0.0836592\tvalid_1's l1: 0.182165\n",
      "[5600]\ttraining's l1: 0.0826657\tvalid_1's l1: 0.18187\n",
      "[5700]\ttraining's l1: 0.0817126\tvalid_1's l1: 0.181564\n",
      "[5800]\ttraining's l1: 0.0807313\tvalid_1's l1: 0.181243\n",
      "[5900]\ttraining's l1: 0.0798205\tvalid_1's l1: 0.180952\n",
      "[6000]\ttraining's l1: 0.078941\tvalid_1's l1: 0.180676\n",
      "[6100]\ttraining's l1: 0.0778077\tvalid_1's l1: 0.180321\n",
      "[6200]\ttraining's l1: 0.0768676\tvalid_1's l1: 0.180005\n",
      "[6300]\ttraining's l1: 0.0760197\tvalid_1's l1: 0.17976\n",
      "[6400]\ttraining's l1: 0.0752077\tvalid_1's l1: 0.17953\n",
      "[6500]\ttraining's l1: 0.0743853\tvalid_1's l1: 0.179311\n",
      "[6600]\ttraining's l1: 0.0736269\tvalid_1's l1: 0.179113\n",
      "[6700]\ttraining's l1: 0.0727358\tvalid_1's l1: 0.178836\n",
      "[6800]\ttraining's l1: 0.071993\tvalid_1's l1: 0.178586\n",
      "[6900]\ttraining's l1: 0.0711171\tvalid_1's l1: 0.178341\n",
      "[7000]\ttraining's l1: 0.0703307\tvalid_1's l1: 0.178137\n",
      "[7100]\ttraining's l1: 0.0695481\tvalid_1's l1: 0.177901\n",
      "[7200]\ttraining's l1: 0.0688381\tvalid_1's l1: 0.177699\n",
      "[7300]\ttraining's l1: 0.0680508\tvalid_1's l1: 0.177496\n",
      "[7400]\ttraining's l1: 0.0672856\tvalid_1's l1: 0.177279\n",
      "[7500]\ttraining's l1: 0.0665723\tvalid_1's l1: 0.17709\n",
      "[7600]\ttraining's l1: 0.0658902\tvalid_1's l1: 0.176926\n",
      "[7700]\ttraining's l1: 0.0651901\tvalid_1's l1: 0.176759\n",
      "[7800]\ttraining's l1: 0.0645372\tvalid_1's l1: 0.176592\n",
      "[7900]\ttraining's l1: 0.0638911\tvalid_1's l1: 0.176429\n",
      "[8000]\ttraining's l1: 0.0632466\tvalid_1's l1: 0.176277\n",
      "[8100]\ttraining's l1: 0.0624645\tvalid_1's l1: 0.176017\n",
      "[8200]\ttraining's l1: 0.0617848\tvalid_1's l1: 0.175819\n",
      "[8300]\ttraining's l1: 0.0611331\tvalid_1's l1: 0.175642\n",
      "[8400]\ttraining's l1: 0.0604508\tvalid_1's l1: 0.175443\n",
      "[8500]\ttraining's l1: 0.0598585\tvalid_1's l1: 0.175269\n",
      "[8600]\ttraining's l1: 0.0592913\tvalid_1's l1: 0.175128\n",
      "[8700]\ttraining's l1: 0.0586996\tvalid_1's l1: 0.174985\n",
      "[8800]\ttraining's l1: 0.0581264\tvalid_1's l1: 0.174836\n",
      "[8900]\ttraining's l1: 0.0575244\tvalid_1's l1: 0.174695\n",
      "[9000]\ttraining's l1: 0.0569136\tvalid_1's l1: 0.174542\n",
      "[9100]\ttraining's l1: 0.056339\tvalid_1's l1: 0.174405\n",
      "[9200]\ttraining's l1: 0.0558031\tvalid_1's l1: 0.174274\n",
      "[9300]\ttraining's l1: 0.0552408\tvalid_1's l1: 0.174134\n",
      "[9400]\ttraining's l1: 0.0546499\tvalid_1's l1: 0.173999\n",
      "[9500]\ttraining's l1: 0.0541543\tvalid_1's l1: 0.173882\n",
      "[9600]\ttraining's l1: 0.0536432\tvalid_1's l1: 0.173781\n",
      "[9700]\ttraining's l1: 0.0531501\tvalid_1's l1: 0.17366\n",
      "[9800]\ttraining's l1: 0.0526056\tvalid_1's l1: 0.173541\n",
      "[9900]\ttraining's l1: 0.0520979\tvalid_1's l1: 0.173439\n",
      "[10000]\ttraining's l1: 0.0516105\tvalid_1's l1: 0.17333\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0516105\tvalid_1's l1: 0.17333\n",
      "2JHH Fold 1, logMAE: -1.7525563947447391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.328378\tvalid_1's l1: 0.343864\n",
      "[200]\ttraining's l1: 0.267232\tvalid_1's l1: 0.291238\n",
      "[300]\ttraining's l1: 0.240687\tvalid_1's l1: 0.269849\n",
      "[400]\ttraining's l1: 0.223094\tvalid_1's l1: 0.256432\n",
      "[500]\ttraining's l1: 0.210749\tvalid_1's l1: 0.24764\n",
      "[600]\ttraining's l1: 0.200449\tvalid_1's l1: 0.240454\n",
      "[700]\ttraining's l1: 0.191439\tvalid_1's l1: 0.23446\n",
      "[800]\ttraining's l1: 0.18416\tvalid_1's l1: 0.229801\n",
      "[900]\ttraining's l1: 0.177716\tvalid_1's l1: 0.225767\n",
      "[1000]\ttraining's l1: 0.171881\tvalid_1's l1: 0.222117\n",
      "[1100]\ttraining's l1: 0.166872\tvalid_1's l1: 0.219162\n",
      "[1200]\ttraining's l1: 0.162202\tvalid_1's l1: 0.216501\n",
      "[1300]\ttraining's l1: 0.157872\tvalid_1's l1: 0.214111\n",
      "[1400]\ttraining's l1: 0.154391\tvalid_1's l1: 0.212255\n",
      "[1500]\ttraining's l1: 0.150829\tvalid_1's l1: 0.210357\n",
      "[1600]\ttraining's l1: 0.147536\tvalid_1's l1: 0.208592\n",
      "[1700]\ttraining's l1: 0.144374\tvalid_1's l1: 0.206985\n",
      "[1800]\ttraining's l1: 0.141096\tvalid_1's l1: 0.205299\n",
      "[1900]\ttraining's l1: 0.138314\tvalid_1's l1: 0.20396\n",
      "[2000]\ttraining's l1: 0.135617\tvalid_1's l1: 0.202666\n",
      "[2100]\ttraining's l1: 0.1329\tvalid_1's l1: 0.201157\n",
      "[2200]\ttraining's l1: 0.130686\tvalid_1's l1: 0.199905\n",
      "[2300]\ttraining's l1: 0.128363\tvalid_1's l1: 0.19879\n",
      "[2400]\ttraining's l1: 0.126252\tvalid_1's l1: 0.197859\n",
      "[2500]\ttraining's l1: 0.124144\tvalid_1's l1: 0.196834\n",
      "[2600]\ttraining's l1: 0.122145\tvalid_1's l1: 0.195969\n",
      "[2700]\ttraining's l1: 0.120112\tvalid_1's l1: 0.195137\n",
      "[2800]\ttraining's l1: 0.118118\tvalid_1's l1: 0.194279\n",
      "[2900]\ttraining's l1: 0.116109\tvalid_1's l1: 0.193456\n",
      "[3000]\ttraining's l1: 0.114312\tvalid_1's l1: 0.19272\n",
      "[3100]\ttraining's l1: 0.112372\tvalid_1's l1: 0.19197\n",
      "[3200]\ttraining's l1: 0.110727\tvalid_1's l1: 0.191325\n",
      "[3300]\ttraining's l1: 0.108952\tvalid_1's l1: 0.190664\n",
      "[3400]\ttraining's l1: 0.107311\tvalid_1's l1: 0.190001\n",
      "[3500]\ttraining's l1: 0.105647\tvalid_1's l1: 0.189383\n",
      "[3600]\ttraining's l1: 0.10411\tvalid_1's l1: 0.188796\n",
      "[3700]\ttraining's l1: 0.102562\tvalid_1's l1: 0.188158\n",
      "[3800]\ttraining's l1: 0.100946\tvalid_1's l1: 0.187552\n",
      "[3900]\ttraining's l1: 0.0995946\tvalid_1's l1: 0.18705\n",
      "[4000]\ttraining's l1: 0.0982099\tvalid_1's l1: 0.186551\n",
      "[4100]\ttraining's l1: 0.0968471\tvalid_1's l1: 0.18597\n",
      "[4200]\ttraining's l1: 0.095711\tvalid_1's l1: 0.185512\n",
      "[4300]\ttraining's l1: 0.0945486\tvalid_1's l1: 0.185113\n",
      "[4400]\ttraining's l1: 0.0933325\tvalid_1's l1: 0.184679\n",
      "[4500]\ttraining's l1: 0.0922499\tvalid_1's l1: 0.184279\n",
      "[4600]\ttraining's l1: 0.0910933\tvalid_1's l1: 0.183881\n",
      "[4700]\ttraining's l1: 0.0900627\tvalid_1's l1: 0.183563\n",
      "[4800]\ttraining's l1: 0.0889527\tvalid_1's l1: 0.183173\n",
      "[4900]\ttraining's l1: 0.0879118\tvalid_1's l1: 0.182827\n",
      "[5000]\ttraining's l1: 0.0867834\tvalid_1's l1: 0.182449\n",
      "[5100]\ttraining's l1: 0.0856716\tvalid_1's l1: 0.182122\n",
      "[5200]\ttraining's l1: 0.0846863\tvalid_1's l1: 0.181778\n",
      "[5300]\ttraining's l1: 0.0836329\tvalid_1's l1: 0.181442\n",
      "[5400]\ttraining's l1: 0.0826487\tvalid_1's l1: 0.181133\n",
      "[5500]\ttraining's l1: 0.081678\tvalid_1's l1: 0.180845\n",
      "[5600]\ttraining's l1: 0.0807303\tvalid_1's l1: 0.180574\n",
      "[5700]\ttraining's l1: 0.0797479\tvalid_1's l1: 0.18029\n",
      "[5800]\ttraining's l1: 0.0787664\tvalid_1's l1: 0.180001\n",
      "[5900]\ttraining's l1: 0.0778768\tvalid_1's l1: 0.179777\n",
      "[6000]\ttraining's l1: 0.0770415\tvalid_1's l1: 0.179545\n",
      "[6100]\ttraining's l1: 0.0760771\tvalid_1's l1: 0.17924\n",
      "[6200]\ttraining's l1: 0.075278\tvalid_1's l1: 0.178992\n",
      "[6300]\ttraining's l1: 0.0744737\tvalid_1's l1: 0.178776\n",
      "[6400]\ttraining's l1: 0.0736908\tvalid_1's l1: 0.178574\n",
      "[6500]\ttraining's l1: 0.0729582\tvalid_1's l1: 0.17837\n",
      "[6600]\ttraining's l1: 0.0721579\tvalid_1's l1: 0.178141\n",
      "[6700]\ttraining's l1: 0.0713352\tvalid_1's l1: 0.17791\n",
      "[6800]\ttraining's l1: 0.0705912\tvalid_1's l1: 0.177711\n",
      "[6900]\ttraining's l1: 0.069775\tvalid_1's l1: 0.177475\n",
      "[7000]\ttraining's l1: 0.0689918\tvalid_1's l1: 0.177255\n",
      "[7100]\ttraining's l1: 0.0682583\tvalid_1's l1: 0.177058\n",
      "[7200]\ttraining's l1: 0.0675787\tvalid_1's l1: 0.176878\n",
      "[7300]\ttraining's l1: 0.0668344\tvalid_1's l1: 0.17666\n",
      "[7400]\ttraining's l1: 0.0661025\tvalid_1's l1: 0.176473\n",
      "[7500]\ttraining's l1: 0.0653978\tvalid_1's l1: 0.176286\n",
      "[7600]\ttraining's l1: 0.0647937\tvalid_1's l1: 0.176133\n",
      "[7700]\ttraining's l1: 0.0641017\tvalid_1's l1: 0.17597\n",
      "[7800]\ttraining's l1: 0.0633671\tvalid_1's l1: 0.175795\n",
      "[7900]\ttraining's l1: 0.0627195\tvalid_1's l1: 0.175639\n",
      "[8000]\ttraining's l1: 0.0620918\tvalid_1's l1: 0.175476\n",
      "[8100]\ttraining's l1: 0.0614007\tvalid_1's l1: 0.175257\n",
      "[8200]\ttraining's l1: 0.0608471\tvalid_1's l1: 0.175097\n",
      "[8300]\ttraining's l1: 0.0602806\tvalid_1's l1: 0.174945\n",
      "[8400]\ttraining's l1: 0.0597313\tvalid_1's l1: 0.174795\n",
      "[8500]\ttraining's l1: 0.0591147\tvalid_1's l1: 0.174638\n",
      "[8600]\ttraining's l1: 0.0585681\tvalid_1's l1: 0.174519\n",
      "[8700]\ttraining's l1: 0.0580952\tvalid_1's l1: 0.174432\n",
      "[8800]\ttraining's l1: 0.0575746\tvalid_1's l1: 0.174314\n",
      "[8900]\ttraining's l1: 0.0570621\tvalid_1's l1: 0.174189\n",
      "[9000]\ttraining's l1: 0.0565396\tvalid_1's l1: 0.174059\n",
      "[9100]\ttraining's l1: 0.0559927\tvalid_1's l1: 0.173934\n",
      "[9200]\ttraining's l1: 0.0555334\tvalid_1's l1: 0.173819\n",
      "[9300]\ttraining's l1: 0.0550005\tvalid_1's l1: 0.173705\n",
      "[9400]\ttraining's l1: 0.0544914\tvalid_1's l1: 0.173581\n",
      "[9500]\ttraining's l1: 0.0540014\tvalid_1's l1: 0.173463\n",
      "[9600]\ttraining's l1: 0.0535228\tvalid_1's l1: 0.173361\n",
      "[9700]\ttraining's l1: 0.0530398\tvalid_1's l1: 0.173235\n",
      "[9800]\ttraining's l1: 0.0525575\tvalid_1's l1: 0.173117\n",
      "[9900]\ttraining's l1: 0.0520857\tvalid_1's l1: 0.17302\n",
      "[10000]\ttraining's l1: 0.0515993\tvalid_1's l1: 0.172902\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0515993\tvalid_1's l1: 0.172902\n",
      "2JHH Fold 2, logMAE: -1.755032843942727\n",
      "*** Training Model for 2JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.269789\tvalid_1's l1: 0.29323\n",
      "[200]\ttraining's l1: 0.223892\tvalid_1's l1: 0.255586\n",
      "[300]\ttraining's l1: 0.20024\tvalid_1's l1: 0.238084\n",
      "[400]\ttraining's l1: 0.184531\tvalid_1's l1: 0.227014\n",
      "[500]\ttraining's l1: 0.172643\tvalid_1's l1: 0.219362\n",
      "[600]\ttraining's l1: 0.163549\tvalid_1's l1: 0.214005\n",
      "[700]\ttraining's l1: 0.155769\tvalid_1's l1: 0.209533\n",
      "[800]\ttraining's l1: 0.148512\tvalid_1's l1: 0.205773\n",
      "[900]\ttraining's l1: 0.142339\tvalid_1's l1: 0.202434\n",
      "[1000]\ttraining's l1: 0.137231\tvalid_1's l1: 0.200039\n",
      "[1100]\ttraining's l1: 0.132614\tvalid_1's l1: 0.197856\n",
      "[1200]\ttraining's l1: 0.128746\tvalid_1's l1: 0.196032\n",
      "[1300]\ttraining's l1: 0.125007\tvalid_1's l1: 0.194194\n",
      "[1400]\ttraining's l1: 0.121762\tvalid_1's l1: 0.19269\n",
      "[1500]\ttraining's l1: 0.1189\tvalid_1's l1: 0.191436\n",
      "[1600]\ttraining's l1: 0.116059\tvalid_1's l1: 0.190229\n",
      "[1700]\ttraining's l1: 0.113429\tvalid_1's l1: 0.189194\n",
      "[1800]\ttraining's l1: 0.11092\tvalid_1's l1: 0.188214\n",
      "[1900]\ttraining's l1: 0.108681\tvalid_1's l1: 0.187363\n",
      "[2000]\ttraining's l1: 0.106546\tvalid_1's l1: 0.186459\n",
      "[2100]\ttraining's l1: 0.104509\tvalid_1's l1: 0.185058\n",
      "[2200]\ttraining's l1: 0.103047\tvalid_1's l1: 0.184237\n",
      "[2300]\ttraining's l1: 0.10166\tvalid_1's l1: 0.183492\n",
      "[2400]\ttraining's l1: 0.0997282\tvalid_1's l1: 0.182449\n",
      "[2500]\ttraining's l1: 0.0976797\tvalid_1's l1: 0.181608\n",
      "[2600]\ttraining's l1: 0.0956376\tvalid_1's l1: 0.180734\n",
      "[2700]\ttraining's l1: 0.0939292\tvalid_1's l1: 0.180115\n",
      "[2800]\ttraining's l1: 0.0928358\tvalid_1's l1: 0.179658\n",
      "[2900]\ttraining's l1: 0.0917248\tvalid_1's l1: 0.179249\n",
      "[3000]\ttraining's l1: 0.089966\tvalid_1's l1: 0.178607\n",
      "[3100]\ttraining's l1: 0.088676\tvalid_1's l1: 0.178131\n",
      "[3200]\ttraining's l1: 0.0872319\tvalid_1's l1: 0.177564\n",
      "[3300]\ttraining's l1: 0.085805\tvalid_1's l1: 0.177103\n",
      "[3400]\ttraining's l1: 0.0845969\tvalid_1's l1: 0.176661\n",
      "[3500]\ttraining's l1: 0.083332\tvalid_1's l1: 0.176206\n",
      "[3600]\ttraining's l1: 0.0819358\tvalid_1's l1: 0.175788\n",
      "[3700]\ttraining's l1: 0.0807001\tvalid_1's l1: 0.175363\n",
      "[3800]\ttraining's l1: 0.0793192\tvalid_1's l1: 0.174966\n",
      "[3900]\ttraining's l1: 0.0782436\tvalid_1's l1: 0.17462\n",
      "[4000]\ttraining's l1: 0.076929\tvalid_1's l1: 0.17418\n",
      "[4100]\ttraining's l1: 0.0756302\tvalid_1's l1: 0.173674\n",
      "[4200]\ttraining's l1: 0.0740435\tvalid_1's l1: 0.173119\n",
      "[4300]\ttraining's l1: 0.0726782\tvalid_1's l1: 0.172643\n",
      "[4400]\ttraining's l1: 0.0714629\tvalid_1's l1: 0.172251\n",
      "[4500]\ttraining's l1: 0.0702188\tvalid_1's l1: 0.171874\n",
      "[4600]\ttraining's l1: 0.0690904\tvalid_1's l1: 0.171508\n",
      "[4700]\ttraining's l1: 0.0680755\tvalid_1's l1: 0.171224\n",
      "[4800]\ttraining's l1: 0.0669121\tvalid_1's l1: 0.170917\n",
      "[4900]\ttraining's l1: 0.0658911\tvalid_1's l1: 0.170698\n",
      "[5000]\ttraining's l1: 0.0649756\tvalid_1's l1: 0.170449\n",
      "[5100]\ttraining's l1: 0.0640168\tvalid_1's l1: 0.170228\n",
      "[5200]\ttraining's l1: 0.0630678\tvalid_1's l1: 0.169991\n",
      "[5300]\ttraining's l1: 0.0621455\tvalid_1's l1: 0.169774\n",
      "[5400]\ttraining's l1: 0.0612596\tvalid_1's l1: 0.169554\n",
      "[5500]\ttraining's l1: 0.0604783\tvalid_1's l1: 0.169369\n",
      "[5600]\ttraining's l1: 0.0597527\tvalid_1's l1: 0.169174\n",
      "[5700]\ttraining's l1: 0.058934\tvalid_1's l1: 0.168976\n",
      "[5800]\ttraining's l1: 0.0582555\tvalid_1's l1: 0.168832\n",
      "[5900]\ttraining's l1: 0.0575159\tvalid_1's l1: 0.16867\n",
      "[6000]\ttraining's l1: 0.0567887\tvalid_1's l1: 0.168493\n",
      "[6100]\ttraining's l1: 0.0557913\tvalid_1's l1: 0.168176\n",
      "[6200]\ttraining's l1: 0.0549933\tvalid_1's l1: 0.167965\n",
      "[6300]\ttraining's l1: 0.0543347\tvalid_1's l1: 0.167831\n",
      "[6400]\ttraining's l1: 0.0537402\tvalid_1's l1: 0.16768\n",
      "[6500]\ttraining's l1: 0.0531309\tvalid_1's l1: 0.167523\n",
      "[6600]\ttraining's l1: 0.0524878\tvalid_1's l1: 0.16733\n",
      "[6700]\ttraining's l1: 0.0518624\tvalid_1's l1: 0.167157\n",
      "[6800]\ttraining's l1: 0.0511568\tvalid_1's l1: 0.166974\n",
      "[6900]\ttraining's l1: 0.0505524\tvalid_1's l1: 0.166855\n",
      "[7000]\ttraining's l1: 0.049904\tvalid_1's l1: 0.166725\n",
      "[7100]\ttraining's l1: 0.0493579\tvalid_1's l1: 0.166626\n",
      "[7200]\ttraining's l1: 0.0487925\tvalid_1's l1: 0.166515\n",
      "[7300]\ttraining's l1: 0.0481839\tvalid_1's l1: 0.166383\n",
      "[7400]\ttraining's l1: 0.0476099\tvalid_1's l1: 0.166264\n",
      "[7500]\ttraining's l1: 0.0469871\tvalid_1's l1: 0.16614\n",
      "[7600]\ttraining's l1: 0.0463868\tvalid_1's l1: 0.166019\n",
      "[7700]\ttraining's l1: 0.045811\tvalid_1's l1: 0.16591\n",
      "[7800]\ttraining's l1: 0.0452181\tvalid_1's l1: 0.165805\n",
      "[7900]\ttraining's l1: 0.0446969\tvalid_1's l1: 0.165721\n",
      "[8000]\ttraining's l1: 0.0441558\tvalid_1's l1: 0.165624\n",
      "[8100]\ttraining's l1: 0.0433242\tvalid_1's l1: 0.165384\n",
      "[8200]\ttraining's l1: 0.0427\tvalid_1's l1: 0.165208\n",
      "[8300]\ttraining's l1: 0.0420569\tvalid_1's l1: 0.165069\n",
      "[8400]\ttraining's l1: 0.0414732\tvalid_1's l1: 0.164963\n",
      "[8500]\ttraining's l1: 0.0409667\tvalid_1's l1: 0.164862\n",
      "[8600]\ttraining's l1: 0.0404605\tvalid_1's l1: 0.164763\n",
      "[8700]\ttraining's l1: 0.0400199\tvalid_1's l1: 0.164666\n",
      "[8800]\ttraining's l1: 0.039587\tvalid_1's l1: 0.164566\n",
      "[8900]\ttraining's l1: 0.0390993\tvalid_1's l1: 0.16448\n",
      "[9000]\ttraining's l1: 0.0386686\tvalid_1's l1: 0.164402\n",
      "[9100]\ttraining's l1: 0.0382738\tvalid_1's l1: 0.164313\n",
      "[9200]\ttraining's l1: 0.037871\tvalid_1's l1: 0.164241\n",
      "[9300]\ttraining's l1: 0.0375028\tvalid_1's l1: 0.164162\n",
      "[9400]\ttraining's l1: 0.0371476\tvalid_1's l1: 0.164098\n",
      "[9500]\ttraining's l1: 0.0367176\tvalid_1's l1: 0.164011\n",
      "[9600]\ttraining's l1: 0.0363177\tvalid_1's l1: 0.163951\n",
      "[9700]\ttraining's l1: 0.0359494\tvalid_1's l1: 0.16389\n",
      "[9800]\ttraining's l1: 0.0355744\tvalid_1's l1: 0.163831\n",
      "[9900]\ttraining's l1: 0.0352438\tvalid_1's l1: 0.163775\n",
      "[10000]\ttraining's l1: 0.0349174\tvalid_1's l1: 0.16372\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0349174\tvalid_1's l1: 0.16372\n",
      "2JHN Fold 0, logMAE: -1.809600150719997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.271759\tvalid_1's l1: 0.288613\n",
      "[200]\ttraining's l1: 0.223629\tvalid_1's l1: 0.248914\n",
      "[300]\ttraining's l1: 0.201351\tvalid_1's l1: 0.232405\n",
      "[400]\ttraining's l1: 0.18508\tvalid_1's l1: 0.221352\n",
      "[500]\ttraining's l1: 0.172535\tvalid_1's l1: 0.213542\n",
      "[600]\ttraining's l1: 0.163135\tvalid_1's l1: 0.207834\n",
      "[700]\ttraining's l1: 0.155481\tvalid_1's l1: 0.203717\n",
      "[800]\ttraining's l1: 0.148324\tvalid_1's l1: 0.199934\n",
      "[900]\ttraining's l1: 0.142156\tvalid_1's l1: 0.1967\n",
      "[1000]\ttraining's l1: 0.137074\tvalid_1's l1: 0.194199\n",
      "[1100]\ttraining's l1: 0.132565\tvalid_1's l1: 0.192198\n",
      "[1200]\ttraining's l1: 0.128282\tvalid_1's l1: 0.190231\n",
      "[1300]\ttraining's l1: 0.12464\tvalid_1's l1: 0.188635\n",
      "[1400]\ttraining's l1: 0.121281\tvalid_1's l1: 0.187248\n",
      "[1500]\ttraining's l1: 0.118042\tvalid_1's l1: 0.18585\n",
      "[1600]\ttraining's l1: 0.115185\tvalid_1's l1: 0.184728\n",
      "[1700]\ttraining's l1: 0.112341\tvalid_1's l1: 0.183687\n",
      "[1800]\ttraining's l1: 0.109872\tvalid_1's l1: 0.18273\n",
      "[1900]\ttraining's l1: 0.107494\tvalid_1's l1: 0.181839\n",
      "[2000]\ttraining's l1: 0.10527\tvalid_1's l1: 0.181136\n",
      "[2100]\ttraining's l1: 0.102534\tvalid_1's l1: 0.179506\n",
      "[2200]\ttraining's l1: 0.100351\tvalid_1's l1: 0.178442\n",
      "[2300]\ttraining's l1: 0.0981208\tvalid_1's l1: 0.177356\n",
      "[2400]\ttraining's l1: 0.0958478\tvalid_1's l1: 0.176369\n",
      "[2500]\ttraining's l1: 0.0937445\tvalid_1's l1: 0.175572\n",
      "[2600]\ttraining's l1: 0.0915919\tvalid_1's l1: 0.174732\n",
      "[2700]\ttraining's l1: 0.0895984\tvalid_1's l1: 0.173938\n",
      "[2800]\ttraining's l1: 0.087862\tvalid_1's l1: 0.173328\n",
      "[2900]\ttraining's l1: 0.086249\tvalid_1's l1: 0.172668\n",
      "[3000]\ttraining's l1: 0.0845891\tvalid_1's l1: 0.172085\n",
      "[3100]\ttraining's l1: 0.0830043\tvalid_1's l1: 0.171614\n",
      "[3200]\ttraining's l1: 0.081427\tvalid_1's l1: 0.171088\n",
      "[3300]\ttraining's l1: 0.0800764\tvalid_1's l1: 0.170669\n",
      "[3400]\ttraining's l1: 0.0786471\tvalid_1's l1: 0.170211\n",
      "[3500]\ttraining's l1: 0.0772648\tvalid_1's l1: 0.169815\n",
      "[3600]\ttraining's l1: 0.0759988\tvalid_1's l1: 0.169433\n",
      "[3700]\ttraining's l1: 0.074735\tvalid_1's l1: 0.169055\n",
      "[3800]\ttraining's l1: 0.0736367\tvalid_1's l1: 0.168725\n",
      "[3900]\ttraining's l1: 0.072506\tvalid_1's l1: 0.168436\n",
      "[4000]\ttraining's l1: 0.0714411\tvalid_1's l1: 0.168144\n",
      "[4100]\ttraining's l1: 0.0698451\tvalid_1's l1: 0.167517\n",
      "[4200]\ttraining's l1: 0.0686206\tvalid_1's l1: 0.167101\n",
      "[4300]\ttraining's l1: 0.0673902\tvalid_1's l1: 0.166712\n",
      "[4400]\ttraining's l1: 0.0661639\tvalid_1's l1: 0.166336\n",
      "[4500]\ttraining's l1: 0.0651169\tvalid_1's l1: 0.166069\n",
      "[4600]\ttraining's l1: 0.0640435\tvalid_1's l1: 0.165736\n",
      "[4700]\ttraining's l1: 0.0630126\tvalid_1's l1: 0.165469\n",
      "[4800]\ttraining's l1: 0.0619621\tvalid_1's l1: 0.165242\n",
      "[4900]\ttraining's l1: 0.0609933\tvalid_1's l1: 0.164967\n",
      "[5000]\ttraining's l1: 0.0600643\tvalid_1's l1: 0.164762\n",
      "[5100]\ttraining's l1: 0.0591445\tvalid_1's l1: 0.164507\n",
      "[5200]\ttraining's l1: 0.0582661\tvalid_1's l1: 0.164338\n",
      "[5300]\ttraining's l1: 0.0574951\tvalid_1's l1: 0.16415\n",
      "[5400]\ttraining's l1: 0.0566492\tvalid_1's l1: 0.163981\n",
      "[5500]\ttraining's l1: 0.0558871\tvalid_1's l1: 0.16381\n",
      "[5600]\ttraining's l1: 0.0551777\tvalid_1's l1: 0.163667\n",
      "[5700]\ttraining's l1: 0.0544328\tvalid_1's l1: 0.163505\n",
      "[5800]\ttraining's l1: 0.0536793\tvalid_1's l1: 0.163365\n",
      "[5900]\ttraining's l1: 0.0528673\tvalid_1's l1: 0.163223\n",
      "[6000]\ttraining's l1: 0.0522865\tvalid_1's l1: 0.163146\n",
      "[6100]\ttraining's l1: 0.0511371\tvalid_1's l1: 0.162815\n",
      "[6200]\ttraining's l1: 0.0503311\tvalid_1's l1: 0.162641\n",
      "[6300]\ttraining's l1: 0.0495871\tvalid_1's l1: 0.162496\n",
      "[6400]\ttraining's l1: 0.0488476\tvalid_1's l1: 0.162293\n",
      "[6500]\ttraining's l1: 0.0482338\tvalid_1's l1: 0.162163\n",
      "[6600]\ttraining's l1: 0.0475554\tvalid_1's l1: 0.162014\n",
      "[6700]\ttraining's l1: 0.0469212\tvalid_1's l1: 0.161876\n",
      "[6800]\ttraining's l1: 0.0463356\tvalid_1's l1: 0.161745\n",
      "[6900]\ttraining's l1: 0.045743\tvalid_1's l1: 0.16164\n",
      "[7000]\ttraining's l1: 0.0451962\tvalid_1's l1: 0.161537\n",
      "[7100]\ttraining's l1: 0.0446094\tvalid_1's l1: 0.161418\n",
      "[7200]\ttraining's l1: 0.044065\tvalid_1's l1: 0.16129\n",
      "[7300]\ttraining's l1: 0.0435199\tvalid_1's l1: 0.161169\n",
      "[7400]\ttraining's l1: 0.0429631\tvalid_1's l1: 0.161053\n",
      "[7500]\ttraining's l1: 0.0425094\tvalid_1's l1: 0.16095\n",
      "[7600]\ttraining's l1: 0.0420701\tvalid_1's l1: 0.160862\n",
      "[7700]\ttraining's l1: 0.0415991\tvalid_1's l1: 0.160769\n",
      "[7800]\ttraining's l1: 0.0411302\tvalid_1's l1: 0.160696\n",
      "[7900]\ttraining's l1: 0.0407033\tvalid_1's l1: 0.160626\n",
      "[8000]\ttraining's l1: 0.0402897\tvalid_1's l1: 0.160553\n",
      "[8100]\ttraining's l1: 0.0396042\tvalid_1's l1: 0.160382\n",
      "[8200]\ttraining's l1: 0.0390512\tvalid_1's l1: 0.160279\n",
      "[8300]\ttraining's l1: 0.0385689\tvalid_1's l1: 0.160173\n",
      "[8400]\ttraining's l1: 0.0380753\tvalid_1's l1: 0.160095\n",
      "[8500]\ttraining's l1: 0.0375798\tvalid_1's l1: 0.159997\n",
      "[8600]\ttraining's l1: 0.0371699\tvalid_1's l1: 0.15991\n",
      "[8700]\ttraining's l1: 0.0367095\tvalid_1's l1: 0.159847\n",
      "[8800]\ttraining's l1: 0.0363405\tvalid_1's l1: 0.159801\n",
      "[8900]\ttraining's l1: 0.0359389\tvalid_1's l1: 0.159713\n",
      "[9000]\ttraining's l1: 0.0355934\tvalid_1's l1: 0.159645\n",
      "[9100]\ttraining's l1: 0.0351939\tvalid_1's l1: 0.159583\n",
      "[9200]\ttraining's l1: 0.034817\tvalid_1's l1: 0.159505\n",
      "[9300]\ttraining's l1: 0.0344912\tvalid_1's l1: 0.159449\n",
      "[9400]\ttraining's l1: 0.0341887\tvalid_1's l1: 0.159396\n",
      "[9500]\ttraining's l1: 0.0338767\tvalid_1's l1: 0.159358\n",
      "[9600]\ttraining's l1: 0.0335791\tvalid_1's l1: 0.159316\n",
      "[9700]\ttraining's l1: 0.0332715\tvalid_1's l1: 0.15928\n",
      "[9800]\ttraining's l1: 0.0329577\tvalid_1's l1: 0.159231\n",
      "[9900]\ttraining's l1: 0.0326819\tvalid_1's l1: 0.159198\n",
      "[10000]\ttraining's l1: 0.03238\tvalid_1's l1: 0.159156\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.03238\tvalid_1's l1: 0.159156\n",
      "2JHN Fold 1, logMAE: -1.8378684667393042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.280779\tvalid_1's l1: 0.296716\n",
      "[200]\ttraining's l1: 0.228372\tvalid_1's l1: 0.253007\n",
      "[300]\ttraining's l1: 0.20255\tvalid_1's l1: 0.234348\n",
      "[400]\ttraining's l1: 0.186695\tvalid_1's l1: 0.223668\n",
      "[500]\ttraining's l1: 0.174263\tvalid_1's l1: 0.215613\n",
      "[600]\ttraining's l1: 0.16514\tvalid_1's l1: 0.209931\n",
      "[700]\ttraining's l1: 0.156548\tvalid_1's l1: 0.204696\n",
      "[800]\ttraining's l1: 0.149586\tvalid_1's l1: 0.2011\n",
      "[900]\ttraining's l1: 0.143315\tvalid_1's l1: 0.197779\n",
      "[1000]\ttraining's l1: 0.137855\tvalid_1's l1: 0.195045\n",
      "[1100]\ttraining's l1: 0.132893\tvalid_1's l1: 0.19269\n",
      "[1200]\ttraining's l1: 0.128742\tvalid_1's l1: 0.190668\n",
      "[1300]\ttraining's l1: 0.124932\tvalid_1's l1: 0.188936\n",
      "[1400]\ttraining's l1: 0.121527\tvalid_1's l1: 0.187425\n",
      "[1500]\ttraining's l1: 0.118643\tvalid_1's l1: 0.186251\n",
      "[1600]\ttraining's l1: 0.11564\tvalid_1's l1: 0.185058\n",
      "[1700]\ttraining's l1: 0.112781\tvalid_1's l1: 0.183897\n",
      "[1800]\ttraining's l1: 0.110312\tvalid_1's l1: 0.182944\n",
      "[1900]\ttraining's l1: 0.108031\tvalid_1's l1: 0.182033\n",
      "[2000]\ttraining's l1: 0.105709\tvalid_1's l1: 0.18116\n",
      "[2100]\ttraining's l1: 0.103789\tvalid_1's l1: 0.179945\n",
      "[2200]\ttraining's l1: 0.101907\tvalid_1's l1: 0.17895\n",
      "[2300]\ttraining's l1: 0.100017\tvalid_1's l1: 0.178012\n",
      "[2400]\ttraining's l1: 0.0982805\tvalid_1's l1: 0.177133\n",
      "[2500]\ttraining's l1: 0.0963371\tvalid_1's l1: 0.176434\n",
      "[2600]\ttraining's l1: 0.0946835\tvalid_1's l1: 0.175739\n",
      "[2700]\ttraining's l1: 0.0929969\tvalid_1's l1: 0.175114\n",
      "[2800]\ttraining's l1: 0.091497\tvalid_1's l1: 0.17447\n",
      "[2900]\ttraining's l1: 0.0900911\tvalid_1's l1: 0.173984\n",
      "[3000]\ttraining's l1: 0.0886275\tvalid_1's l1: 0.173476\n",
      "[3100]\ttraining's l1: 0.0875517\tvalid_1's l1: 0.173093\n",
      "[3200]\ttraining's l1: 0.0866702\tvalid_1's l1: 0.172872\n",
      "[3300]\ttraining's l1: 0.0858106\tvalid_1's l1: 0.172539\n",
      "[3400]\ttraining's l1: 0.0842809\tvalid_1's l1: 0.172114\n",
      "[3500]\ttraining's l1: 0.082866\tvalid_1's l1: 0.17169\n",
      "[3600]\ttraining's l1: 0.0814284\tvalid_1's l1: 0.171253\n",
      "[3700]\ttraining's l1: 0.0801007\tvalid_1's l1: 0.170846\n",
      "[3800]\ttraining's l1: 0.0787853\tvalid_1's l1: 0.170451\n",
      "[3900]\ttraining's l1: 0.0774159\tvalid_1's l1: 0.170083\n",
      "[4000]\ttraining's l1: 0.0764764\tvalid_1's l1: 0.169842\n",
      "[4100]\ttraining's l1: 0.0747468\tvalid_1's l1: 0.169194\n",
      "[4200]\ttraining's l1: 0.0732473\tvalid_1's l1: 0.168677\n",
      "[4300]\ttraining's l1: 0.0719084\tvalid_1's l1: 0.168236\n",
      "[4400]\ttraining's l1: 0.0706407\tvalid_1's l1: 0.167791\n",
      "[4500]\ttraining's l1: 0.0693151\tvalid_1's l1: 0.167376\n",
      "[4600]\ttraining's l1: 0.0680347\tvalid_1's l1: 0.166972\n",
      "[4700]\ttraining's l1: 0.0669572\tvalid_1's l1: 0.166635\n",
      "[4800]\ttraining's l1: 0.0657328\tvalid_1's l1: 0.166363\n",
      "[4900]\ttraining's l1: 0.0646978\tvalid_1's l1: 0.166061\n",
      "[5000]\ttraining's l1: 0.0637197\tvalid_1's l1: 0.165783\n",
      "[5100]\ttraining's l1: 0.0626903\tvalid_1's l1: 0.165504\n",
      "[5200]\ttraining's l1: 0.0617862\tvalid_1's l1: 0.165315\n",
      "[5300]\ttraining's l1: 0.0608578\tvalid_1's l1: 0.165104\n",
      "[5400]\ttraining's l1: 0.0599262\tvalid_1's l1: 0.164866\n",
      "[5500]\ttraining's l1: 0.059005\tvalid_1's l1: 0.164647\n",
      "[5600]\ttraining's l1: 0.0581974\tvalid_1's l1: 0.164466\n",
      "[5700]\ttraining's l1: 0.0573998\tvalid_1's l1: 0.164252\n",
      "[5800]\ttraining's l1: 0.0566385\tvalid_1's l1: 0.164083\n",
      "[5900]\ttraining's l1: 0.0558872\tvalid_1's l1: 0.163925\n",
      "[6000]\ttraining's l1: 0.0551629\tvalid_1's l1: 0.163773\n",
      "[6100]\ttraining's l1: 0.0540701\tvalid_1's l1: 0.163415\n",
      "[6200]\ttraining's l1: 0.0533108\tvalid_1's l1: 0.163182\n",
      "[6300]\ttraining's l1: 0.0526216\tvalid_1's l1: 0.163005\n",
      "[6400]\ttraining's l1: 0.0520064\tvalid_1's l1: 0.162849\n",
      "[6500]\ttraining's l1: 0.0514663\tvalid_1's l1: 0.162728\n",
      "[6600]\ttraining's l1: 0.0509921\tvalid_1's l1: 0.162615\n",
      "[6700]\ttraining's l1: 0.0504792\tvalid_1's l1: 0.162466\n",
      "[6800]\ttraining's l1: 0.0500189\tvalid_1's l1: 0.162357\n",
      "[6900]\ttraining's l1: 0.0494811\tvalid_1's l1: 0.16223\n",
      "[7000]\ttraining's l1: 0.0489997\tvalid_1's l1: 0.162115\n",
      "[7100]\ttraining's l1: 0.0485493\tvalid_1's l1: 0.162003\n",
      "[7200]\ttraining's l1: 0.0480682\tvalid_1's l1: 0.161918\n",
      "[7300]\ttraining's l1: 0.0476013\tvalid_1's l1: 0.161811\n",
      "[7400]\ttraining's l1: 0.0470275\tvalid_1's l1: 0.161679\n",
      "[7500]\ttraining's l1: 0.0465082\tvalid_1's l1: 0.161598\n",
      "[7600]\ttraining's l1: 0.0459915\tvalid_1's l1: 0.161492\n",
      "[7700]\ttraining's l1: 0.045431\tvalid_1's l1: 0.161365\n",
      "[7800]\ttraining's l1: 0.0448863\tvalid_1's l1: 0.161278\n",
      "[7900]\ttraining's l1: 0.0443853\tvalid_1's l1: 0.161158\n",
      "[8000]\ttraining's l1: 0.0438111\tvalid_1's l1: 0.161046\n",
      "[8100]\ttraining's l1: 0.0431108\tvalid_1's l1: 0.160876\n",
      "[8200]\ttraining's l1: 0.0425012\tvalid_1's l1: 0.160744\n",
      "[8300]\ttraining's l1: 0.0418922\tvalid_1's l1: 0.160579\n",
      "[8400]\ttraining's l1: 0.0413037\tvalid_1's l1: 0.160459\n",
      "[8500]\ttraining's l1: 0.0407758\tvalid_1's l1: 0.160342\n",
      "[8600]\ttraining's l1: 0.0402795\tvalid_1's l1: 0.160233\n",
      "[8700]\ttraining's l1: 0.0397433\tvalid_1's l1: 0.160141\n",
      "[8800]\ttraining's l1: 0.039266\tvalid_1's l1: 0.160031\n",
      "[8900]\ttraining's l1: 0.0387872\tvalid_1's l1: 0.159939\n",
      "[9000]\ttraining's l1: 0.0383598\tvalid_1's l1: 0.159852\n",
      "[9100]\ttraining's l1: 0.0379355\tvalid_1's l1: 0.159778\n",
      "[9200]\ttraining's l1: 0.0374912\tvalid_1's l1: 0.159708\n",
      "[9300]\ttraining's l1: 0.0370859\tvalid_1's l1: 0.159629\n",
      "[9400]\ttraining's l1: 0.0366565\tvalid_1's l1: 0.159546\n",
      "[9500]\ttraining's l1: 0.0362119\tvalid_1's l1: 0.159476\n",
      "[9600]\ttraining's l1: 0.0357904\tvalid_1's l1: 0.159411\n",
      "[9700]\ttraining's l1: 0.0353832\tvalid_1's l1: 0.159344\n",
      "[9800]\ttraining's l1: 0.0350085\tvalid_1's l1: 0.159278\n",
      "[9900]\ttraining's l1: 0.0346648\tvalid_1's l1: 0.159221\n",
      "[10000]\ttraining's l1: 0.0342997\tvalid_1's l1: 0.15917\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0342997\tvalid_1's l1: 0.15917\n",
      "2JHN Fold 2, logMAE: -1.8377863356440993\n",
      "*** Training Model for 2JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.658862\tvalid_1's l1: 0.669302\n",
      "[200]\ttraining's l1: 0.524415\tvalid_1's l1: 0.542133\n",
      "[300]\ttraining's l1: 0.467524\tvalid_1's l1: 0.490652\n",
      "[400]\ttraining's l1: 0.431551\tvalid_1's l1: 0.459585\n",
      "[500]\ttraining's l1: 0.404724\tvalid_1's l1: 0.437157\n",
      "[600]\ttraining's l1: 0.38462\tvalid_1's l1: 0.420762\n",
      "[700]\ttraining's l1: 0.369288\tvalid_1's l1: 0.408814\n",
      "[800]\ttraining's l1: 0.356342\tvalid_1's l1: 0.39879\n",
      "[900]\ttraining's l1: 0.344726\tvalid_1's l1: 0.390205\n",
      "[1000]\ttraining's l1: 0.334377\tvalid_1's l1: 0.382503\n",
      "[1100]\ttraining's l1: 0.326122\tvalid_1's l1: 0.37655\n",
      "[1200]\ttraining's l1: 0.31824\tvalid_1's l1: 0.371007\n",
      "[1300]\ttraining's l1: 0.311486\tvalid_1's l1: 0.366382\n",
      "[1400]\ttraining's l1: 0.304453\tvalid_1's l1: 0.361512\n",
      "[1500]\ttraining's l1: 0.298292\tvalid_1's l1: 0.357485\n",
      "[1600]\ttraining's l1: 0.292489\tvalid_1's l1: 0.353667\n",
      "[1700]\ttraining's l1: 0.287602\tvalid_1's l1: 0.350557\n",
      "[1800]\ttraining's l1: 0.282817\tvalid_1's l1: 0.34755\n",
      "[1900]\ttraining's l1: 0.278321\tvalid_1's l1: 0.344803\n",
      "[2000]\ttraining's l1: 0.273924\tvalid_1's l1: 0.34208\n",
      "[2100]\ttraining's l1: 0.270464\tvalid_1's l1: 0.339769\n",
      "[2200]\ttraining's l1: 0.267279\tvalid_1's l1: 0.337835\n",
      "[2300]\ttraining's l1: 0.263964\tvalid_1's l1: 0.335917\n",
      "[2400]\ttraining's l1: 0.260498\tvalid_1's l1: 0.33386\n",
      "[2500]\ttraining's l1: 0.257139\tvalid_1's l1: 0.331913\n",
      "[2600]\ttraining's l1: 0.253898\tvalid_1's l1: 0.33005\n",
      "[2700]\ttraining's l1: 0.250673\tvalid_1's l1: 0.32829\n",
      "[2800]\ttraining's l1: 0.247677\tvalid_1's l1: 0.32665\n",
      "[2900]\ttraining's l1: 0.244843\tvalid_1's l1: 0.325118\n",
      "[3000]\ttraining's l1: 0.242112\tvalid_1's l1: 0.323648\n",
      "[3100]\ttraining's l1: 0.239215\tvalid_1's l1: 0.322047\n",
      "[3200]\ttraining's l1: 0.236496\tvalid_1's l1: 0.320637\n",
      "[3300]\ttraining's l1: 0.234034\tvalid_1's l1: 0.319381\n",
      "[3400]\ttraining's l1: 0.231644\tvalid_1's l1: 0.318184\n",
      "[3500]\ttraining's l1: 0.228929\tvalid_1's l1: 0.316764\n",
      "[3600]\ttraining's l1: 0.226373\tvalid_1's l1: 0.315452\n",
      "[3700]\ttraining's l1: 0.22414\tvalid_1's l1: 0.314331\n",
      "[3800]\ttraining's l1: 0.221917\tvalid_1's l1: 0.313251\n",
      "[3900]\ttraining's l1: 0.219884\tvalid_1's l1: 0.31224\n",
      "[4000]\ttraining's l1: 0.217616\tvalid_1's l1: 0.311169\n",
      "[4100]\ttraining's l1: 0.215524\tvalid_1's l1: 0.310173\n",
      "[4200]\ttraining's l1: 0.213421\tvalid_1's l1: 0.309162\n",
      "[4300]\ttraining's l1: 0.211466\tvalid_1's l1: 0.308265\n",
      "[4400]\ttraining's l1: 0.209482\tvalid_1's l1: 0.307378\n",
      "[4500]\ttraining's l1: 0.207532\tvalid_1's l1: 0.306446\n",
      "[4600]\ttraining's l1: 0.205535\tvalid_1's l1: 0.305534\n",
      "[4700]\ttraining's l1: 0.203509\tvalid_1's l1: 0.304613\n",
      "[4800]\ttraining's l1: 0.201807\tvalid_1's l1: 0.30387\n",
      "[4900]\ttraining's l1: 0.200029\tvalid_1's l1: 0.303073\n",
      "[5000]\ttraining's l1: 0.198171\tvalid_1's l1: 0.302193\n",
      "[5100]\ttraining's l1: 0.196522\tvalid_1's l1: 0.301451\n",
      "[5200]\ttraining's l1: 0.194812\tvalid_1's l1: 0.300692\n",
      "[5300]\ttraining's l1: 0.19306\tvalid_1's l1: 0.299924\n",
      "[5400]\ttraining's l1: 0.191299\tvalid_1's l1: 0.299164\n",
      "[5500]\ttraining's l1: 0.189639\tvalid_1's l1: 0.298449\n",
      "[5600]\ttraining's l1: 0.188084\tvalid_1's l1: 0.297848\n",
      "[5700]\ttraining's l1: 0.186579\tvalid_1's l1: 0.297244\n",
      "[5800]\ttraining's l1: 0.185032\tvalid_1's l1: 0.296592\n",
      "[5900]\ttraining's l1: 0.183562\tvalid_1's l1: 0.295972\n",
      "[6000]\ttraining's l1: 0.181985\tvalid_1's l1: 0.295281\n",
      "[6100]\ttraining's l1: 0.180489\tvalid_1's l1: 0.294671\n",
      "[6200]\ttraining's l1: 0.179007\tvalid_1's l1: 0.294087\n",
      "[6300]\ttraining's l1: 0.177556\tvalid_1's l1: 0.293499\n",
      "[6400]\ttraining's l1: 0.176347\tvalid_1's l1: 0.293021\n",
      "[6500]\ttraining's l1: 0.174964\tvalid_1's l1: 0.292496\n",
      "[6600]\ttraining's l1: 0.173609\tvalid_1's l1: 0.291969\n",
      "[6700]\ttraining's l1: 0.172225\tvalid_1's l1: 0.291416\n",
      "[6800]\ttraining's l1: 0.170831\tvalid_1's l1: 0.290874\n",
      "[6900]\ttraining's l1: 0.169575\tvalid_1's l1: 0.2904\n",
      "[7000]\ttraining's l1: 0.168265\tvalid_1's l1: 0.28989\n",
      "[7100]\ttraining's l1: 0.166873\tvalid_1's l1: 0.289364\n",
      "[7200]\ttraining's l1: 0.165696\tvalid_1's l1: 0.288939\n",
      "[7300]\ttraining's l1: 0.164468\tvalid_1's l1: 0.288496\n",
      "[7400]\ttraining's l1: 0.163177\tvalid_1's l1: 0.288013\n",
      "[7500]\ttraining's l1: 0.161989\tvalid_1's l1: 0.287576\n",
      "[7600]\ttraining's l1: 0.160697\tvalid_1's l1: 0.287141\n",
      "[7700]\ttraining's l1: 0.159439\tvalid_1's l1: 0.286664\n",
      "[7800]\ttraining's l1: 0.158216\tvalid_1's l1: 0.286215\n",
      "[7900]\ttraining's l1: 0.157077\tvalid_1's l1: 0.285799\n",
      "[8000]\ttraining's l1: 0.155965\tvalid_1's l1: 0.285405\n",
      "[8100]\ttraining's l1: 0.154707\tvalid_1's l1: 0.284932\n",
      "[8200]\ttraining's l1: 0.153612\tvalid_1's l1: 0.28453\n",
      "[8300]\ttraining's l1: 0.152533\tvalid_1's l1: 0.284152\n",
      "[8400]\ttraining's l1: 0.151499\tvalid_1's l1: 0.283768\n",
      "[8500]\ttraining's l1: 0.150429\tvalid_1's l1: 0.28337\n",
      "[8600]\ttraining's l1: 0.149437\tvalid_1's l1: 0.283032\n",
      "[8700]\ttraining's l1: 0.148423\tvalid_1's l1: 0.282685\n",
      "[8800]\ttraining's l1: 0.1474\tvalid_1's l1: 0.282337\n",
      "[8900]\ttraining's l1: 0.1464\tvalid_1's l1: 0.282016\n",
      "[9000]\ttraining's l1: 0.145487\tvalid_1's l1: 0.281732\n",
      "[9100]\ttraining's l1: 0.144535\tvalid_1's l1: 0.281399\n",
      "[9200]\ttraining's l1: 0.143538\tvalid_1's l1: 0.281051\n",
      "[9300]\ttraining's l1: 0.142523\tvalid_1's l1: 0.280712\n",
      "[9400]\ttraining's l1: 0.14155\tvalid_1's l1: 0.280384\n",
      "[9500]\ttraining's l1: 0.140597\tvalid_1's l1: 0.280056\n",
      "[9600]\ttraining's l1: 0.139786\tvalid_1's l1: 0.279798\n",
      "[9700]\ttraining's l1: 0.138885\tvalid_1's l1: 0.279487\n",
      "[9800]\ttraining's l1: 0.137908\tvalid_1's l1: 0.279167\n",
      "[9900]\ttraining's l1: 0.137036\tvalid_1's l1: 0.278895\n",
      "[10000]\ttraining's l1: 0.136204\tvalid_1's l1: 0.278634\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.136204\tvalid_1's l1: 0.278634\n",
      "2JHC Fold 0, logMAE: -1.2778552827906016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.651838\tvalid_1's l1: 0.665242\n",
      "[200]\ttraining's l1: 0.521942\tvalid_1's l1: 0.54315\n",
      "[300]\ttraining's l1: 0.465875\tvalid_1's l1: 0.492149\n",
      "[400]\ttraining's l1: 0.431617\tvalid_1's l1: 0.461886\n",
      "[500]\ttraining's l1: 0.407896\tvalid_1's l1: 0.441674\n",
      "[600]\ttraining's l1: 0.387796\tvalid_1's l1: 0.42511\n",
      "[700]\ttraining's l1: 0.372615\tvalid_1's l1: 0.413032\n",
      "[800]\ttraining's l1: 0.359883\tvalid_1's l1: 0.403152\n",
      "[900]\ttraining's l1: 0.348469\tvalid_1's l1: 0.394468\n",
      "[1000]\ttraining's l1: 0.337949\tvalid_1's l1: 0.386647\n",
      "[1100]\ttraining's l1: 0.328705\tvalid_1's l1: 0.379988\n",
      "[1200]\ttraining's l1: 0.32106\tvalid_1's l1: 0.37456\n",
      "[1300]\ttraining's l1: 0.314225\tvalid_1's l1: 0.370031\n",
      "[1400]\ttraining's l1: 0.307587\tvalid_1's l1: 0.365559\n",
      "[1500]\ttraining's l1: 0.301459\tvalid_1's l1: 0.361518\n",
      "[1600]\ttraining's l1: 0.295661\tvalid_1's l1: 0.357704\n",
      "[1700]\ttraining's l1: 0.290487\tvalid_1's l1: 0.354379\n",
      "[1800]\ttraining's l1: 0.285214\tvalid_1's l1: 0.350967\n",
      "[1900]\ttraining's l1: 0.280376\tvalid_1's l1: 0.347935\n",
      "[2000]\ttraining's l1: 0.275998\tvalid_1's l1: 0.345228\n",
      "[2100]\ttraining's l1: 0.271774\tvalid_1's l1: 0.342589\n",
      "[2200]\ttraining's l1: 0.26786\tvalid_1's l1: 0.340179\n",
      "[2300]\ttraining's l1: 0.263848\tvalid_1's l1: 0.337781\n",
      "[2400]\ttraining's l1: 0.260023\tvalid_1's l1: 0.33553\n",
      "[2500]\ttraining's l1: 0.256651\tvalid_1's l1: 0.333573\n",
      "[2600]\ttraining's l1: 0.253145\tvalid_1's l1: 0.331647\n",
      "[2700]\ttraining's l1: 0.249875\tvalid_1's l1: 0.329726\n",
      "[2800]\ttraining's l1: 0.246537\tvalid_1's l1: 0.327846\n",
      "[2900]\ttraining's l1: 0.243505\tvalid_1's l1: 0.326195\n",
      "[3000]\ttraining's l1: 0.240604\tvalid_1's l1: 0.324619\n",
      "[3100]\ttraining's l1: 0.237682\tvalid_1's l1: 0.323064\n",
      "[3200]\ttraining's l1: 0.234922\tvalid_1's l1: 0.321661\n",
      "[3300]\ttraining's l1: 0.231832\tvalid_1's l1: 0.320047\n",
      "[3400]\ttraining's l1: 0.229203\tvalid_1's l1: 0.31869\n",
      "[3500]\ttraining's l1: 0.226594\tvalid_1's l1: 0.317359\n",
      "[3600]\ttraining's l1: 0.223972\tvalid_1's l1: 0.316113\n",
      "[3700]\ttraining's l1: 0.221608\tvalid_1's l1: 0.314913\n",
      "[3800]\ttraining's l1: 0.219214\tvalid_1's l1: 0.313733\n",
      "[3900]\ttraining's l1: 0.216787\tvalid_1's l1: 0.312542\n",
      "[4000]\ttraining's l1: 0.214563\tvalid_1's l1: 0.311452\n",
      "[4100]\ttraining's l1: 0.212638\tvalid_1's l1: 0.310515\n",
      "[4200]\ttraining's l1: 0.210636\tvalid_1's l1: 0.309562\n",
      "[4300]\ttraining's l1: 0.208616\tvalid_1's l1: 0.308634\n",
      "[4400]\ttraining's l1: 0.206525\tvalid_1's l1: 0.307655\n",
      "[4500]\ttraining's l1: 0.204589\tvalid_1's l1: 0.306752\n",
      "[4600]\ttraining's l1: 0.202703\tvalid_1's l1: 0.305902\n",
      "[4700]\ttraining's l1: 0.20093\tvalid_1's l1: 0.305134\n",
      "[4800]\ttraining's l1: 0.19916\tvalid_1's l1: 0.304363\n",
      "[4900]\ttraining's l1: 0.197549\tvalid_1's l1: 0.303651\n",
      "[5000]\ttraining's l1: 0.195797\tvalid_1's l1: 0.302946\n",
      "[5100]\ttraining's l1: 0.194059\tvalid_1's l1: 0.302211\n",
      "[5200]\ttraining's l1: 0.192402\tvalid_1's l1: 0.301502\n",
      "[5300]\ttraining's l1: 0.190779\tvalid_1's l1: 0.300781\n",
      "[5400]\ttraining's l1: 0.189223\tvalid_1's l1: 0.300131\n",
      "[5500]\ttraining's l1: 0.187592\tvalid_1's l1: 0.299434\n",
      "[5600]\ttraining's l1: 0.185854\tvalid_1's l1: 0.298675\n",
      "[5700]\ttraining's l1: 0.184219\tvalid_1's l1: 0.298005\n",
      "[5800]\ttraining's l1: 0.182744\tvalid_1's l1: 0.29738\n",
      "[5900]\ttraining's l1: 0.181287\tvalid_1's l1: 0.296763\n",
      "[6000]\ttraining's l1: 0.179735\tvalid_1's l1: 0.296144\n",
      "[6100]\ttraining's l1: 0.17823\tvalid_1's l1: 0.295551\n",
      "[6200]\ttraining's l1: 0.176758\tvalid_1's l1: 0.294951\n",
      "[6300]\ttraining's l1: 0.175295\tvalid_1's l1: 0.294373\n",
      "[6400]\ttraining's l1: 0.173867\tvalid_1's l1: 0.293841\n",
      "[6500]\ttraining's l1: 0.172578\tvalid_1's l1: 0.293355\n",
      "[6600]\ttraining's l1: 0.171257\tvalid_1's l1: 0.292857\n",
      "[6700]\ttraining's l1: 0.169897\tvalid_1's l1: 0.292333\n",
      "[6800]\ttraining's l1: 0.168586\tvalid_1's l1: 0.291791\n",
      "[6900]\ttraining's l1: 0.167226\tvalid_1's l1: 0.291269\n",
      "[7000]\ttraining's l1: 0.166002\tvalid_1's l1: 0.290819\n",
      "[7100]\ttraining's l1: 0.16466\tvalid_1's l1: 0.29032\n",
      "[7200]\ttraining's l1: 0.163405\tvalid_1's l1: 0.289877\n",
      "[7300]\ttraining's l1: 0.16215\tvalid_1's l1: 0.289434\n",
      "[7400]\ttraining's l1: 0.160943\tvalid_1's l1: 0.288984\n",
      "[7500]\ttraining's l1: 0.159783\tvalid_1's l1: 0.288543\n",
      "[7600]\ttraining's l1: 0.158588\tvalid_1's l1: 0.2881\n",
      "[7700]\ttraining's l1: 0.157461\tvalid_1's l1: 0.287727\n",
      "[7800]\ttraining's l1: 0.156302\tvalid_1's l1: 0.287305\n",
      "[7900]\ttraining's l1: 0.155173\tvalid_1's l1: 0.286914\n",
      "[8000]\ttraining's l1: 0.154145\tvalid_1's l1: 0.286546\n",
      "[8100]\ttraining's l1: 0.152855\tvalid_1's l1: 0.286067\n",
      "[8200]\ttraining's l1: 0.15152\tvalid_1's l1: 0.285581\n",
      "[8300]\ttraining's l1: 0.150365\tvalid_1's l1: 0.285179\n",
      "[8400]\ttraining's l1: 0.149284\tvalid_1's l1: 0.284799\n",
      "[8500]\ttraining's l1: 0.148291\tvalid_1's l1: 0.28444\n",
      "[8600]\ttraining's l1: 0.147193\tvalid_1's l1: 0.284078\n",
      "[8700]\ttraining's l1: 0.146257\tvalid_1's l1: 0.28378\n",
      "[8800]\ttraining's l1: 0.145242\tvalid_1's l1: 0.283428\n",
      "[8900]\ttraining's l1: 0.144154\tvalid_1's l1: 0.283038\n",
      "[9000]\ttraining's l1: 0.143155\tvalid_1's l1: 0.282703\n",
      "[9100]\ttraining's l1: 0.142141\tvalid_1's l1: 0.282374\n",
      "[9200]\ttraining's l1: 0.141137\tvalid_1's l1: 0.282023\n",
      "[9300]\ttraining's l1: 0.140183\tvalid_1's l1: 0.281732\n",
      "[9400]\ttraining's l1: 0.139314\tvalid_1's l1: 0.28145\n",
      "[9500]\ttraining's l1: 0.138405\tvalid_1's l1: 0.28117\n",
      "[9600]\ttraining's l1: 0.137429\tvalid_1's l1: 0.280866\n",
      "[9700]\ttraining's l1: 0.136472\tvalid_1's l1: 0.280563\n",
      "[9800]\ttraining's l1: 0.135561\tvalid_1's l1: 0.280299\n",
      "[9900]\ttraining's l1: 0.134688\tvalid_1's l1: 0.280018\n",
      "[10000]\ttraining's l1: 0.1338\tvalid_1's l1: 0.279765\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.1338\tvalid_1's l1: 0.279765\n",
      "2JHC Fold 1, logMAE: -1.2738061910411105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.651393\tvalid_1's l1: 0.662877\n",
      "[200]\ttraining's l1: 0.520146\tvalid_1's l1: 0.539905\n",
      "[300]\ttraining's l1: 0.46554\tvalid_1's l1: 0.490431\n",
      "[400]\ttraining's l1: 0.431566\tvalid_1's l1: 0.461134\n",
      "[500]\ttraining's l1: 0.406712\tvalid_1's l1: 0.440116\n",
      "[600]\ttraining's l1: 0.387532\tvalid_1's l1: 0.424757\n",
      "[700]\ttraining's l1: 0.372413\tvalid_1's l1: 0.412751\n",
      "[800]\ttraining's l1: 0.358334\tvalid_1's l1: 0.401837\n",
      "[900]\ttraining's l1: 0.347672\tvalid_1's l1: 0.393813\n",
      "[1000]\ttraining's l1: 0.338247\tvalid_1's l1: 0.387009\n",
      "[1100]\ttraining's l1: 0.329534\tvalid_1's l1: 0.380707\n",
      "[1200]\ttraining's l1: 0.321349\tvalid_1's l1: 0.374903\n",
      "[1300]\ttraining's l1: 0.314006\tvalid_1's l1: 0.369784\n",
      "[1400]\ttraining's l1: 0.307801\tvalid_1's l1: 0.365749\n",
      "[1500]\ttraining's l1: 0.301927\tvalid_1's l1: 0.361837\n",
      "[1600]\ttraining's l1: 0.295827\tvalid_1's l1: 0.357763\n",
      "[1700]\ttraining's l1: 0.290005\tvalid_1's l1: 0.353998\n",
      "[1800]\ttraining's l1: 0.284974\tvalid_1's l1: 0.350756\n",
      "[1900]\ttraining's l1: 0.280079\tvalid_1's l1: 0.347654\n",
      "[2000]\ttraining's l1: 0.275566\tvalid_1's l1: 0.344753\n",
      "[2100]\ttraining's l1: 0.272042\tvalid_1's l1: 0.34257\n",
      "[2200]\ttraining's l1: 0.268626\tvalid_1's l1: 0.340487\n",
      "[2300]\ttraining's l1: 0.264813\tvalid_1's l1: 0.338126\n",
      "[2400]\ttraining's l1: 0.261178\tvalid_1's l1: 0.335973\n",
      "[2500]\ttraining's l1: 0.257787\tvalid_1's l1: 0.333947\n",
      "[2600]\ttraining's l1: 0.254401\tvalid_1's l1: 0.332006\n",
      "[2700]\ttraining's l1: 0.25128\tvalid_1's l1: 0.330186\n",
      "[2800]\ttraining's l1: 0.248263\tvalid_1's l1: 0.328452\n",
      "[2900]\ttraining's l1: 0.245307\tvalid_1's l1: 0.326812\n",
      "[3000]\ttraining's l1: 0.242536\tvalid_1's l1: 0.32529\n",
      "[3100]\ttraining's l1: 0.239783\tvalid_1's l1: 0.323777\n",
      "[3200]\ttraining's l1: 0.236794\tvalid_1's l1: 0.32217\n",
      "[3300]\ttraining's l1: 0.233933\tvalid_1's l1: 0.320606\n",
      "[3400]\ttraining's l1: 0.23129\tvalid_1's l1: 0.319226\n",
      "[3500]\ttraining's l1: 0.228827\tvalid_1's l1: 0.318004\n",
      "[3600]\ttraining's l1: 0.226389\tvalid_1's l1: 0.316804\n",
      "[3700]\ttraining's l1: 0.223869\tvalid_1's l1: 0.315544\n",
      "[3800]\ttraining's l1: 0.221553\tvalid_1's l1: 0.3144\n",
      "[3900]\ttraining's l1: 0.219349\tvalid_1's l1: 0.313333\n",
      "[4000]\ttraining's l1: 0.217209\tvalid_1's l1: 0.31225\n",
      "[4100]\ttraining's l1: 0.215193\tvalid_1's l1: 0.311344\n",
      "[4200]\ttraining's l1: 0.213154\tvalid_1's l1: 0.31039\n",
      "[4300]\ttraining's l1: 0.2112\tvalid_1's l1: 0.30949\n",
      "[4400]\ttraining's l1: 0.209211\tvalid_1's l1: 0.308521\n",
      "[4500]\ttraining's l1: 0.207176\tvalid_1's l1: 0.307596\n",
      "[4600]\ttraining's l1: 0.205135\tvalid_1's l1: 0.306673\n",
      "[4700]\ttraining's l1: 0.203356\tvalid_1's l1: 0.305894\n",
      "[4800]\ttraining's l1: 0.201632\tvalid_1's l1: 0.305163\n",
      "[4900]\ttraining's l1: 0.199717\tvalid_1's l1: 0.304312\n",
      "[5000]\ttraining's l1: 0.197798\tvalid_1's l1: 0.303446\n",
      "[5100]\ttraining's l1: 0.196061\tvalid_1's l1: 0.302696\n",
      "[5200]\ttraining's l1: 0.194244\tvalid_1's l1: 0.301883\n",
      "[5300]\ttraining's l1: 0.192293\tvalid_1's l1: 0.301073\n",
      "[5400]\ttraining's l1: 0.19058\tvalid_1's l1: 0.300341\n",
      "[5500]\ttraining's l1: 0.188982\tvalid_1's l1: 0.299639\n",
      "[5600]\ttraining's l1: 0.187349\tvalid_1's l1: 0.298947\n",
      "[5700]\ttraining's l1: 0.185777\tvalid_1's l1: 0.298295\n",
      "[5800]\ttraining's l1: 0.184173\tvalid_1's l1: 0.297628\n",
      "[5900]\ttraining's l1: 0.182647\tvalid_1's l1: 0.297028\n",
      "[6000]\ttraining's l1: 0.181223\tvalid_1's l1: 0.296418\n",
      "[6100]\ttraining's l1: 0.179666\tvalid_1's l1: 0.295737\n",
      "[6200]\ttraining's l1: 0.178218\tvalid_1's l1: 0.295132\n",
      "[6300]\ttraining's l1: 0.176749\tvalid_1's l1: 0.294515\n",
      "[6400]\ttraining's l1: 0.175204\tvalid_1's l1: 0.293876\n",
      "[6500]\ttraining's l1: 0.173787\tvalid_1's l1: 0.293285\n",
      "[6600]\ttraining's l1: 0.172469\tvalid_1's l1: 0.292746\n",
      "[6700]\ttraining's l1: 0.171179\tvalid_1's l1: 0.292224\n",
      "[6800]\ttraining's l1: 0.169664\tvalid_1's l1: 0.291624\n",
      "[6900]\ttraining's l1: 0.168428\tvalid_1's l1: 0.291129\n",
      "[7000]\ttraining's l1: 0.167144\tvalid_1's l1: 0.290613\n",
      "[7100]\ttraining's l1: 0.165833\tvalid_1's l1: 0.290086\n",
      "[7200]\ttraining's l1: 0.164528\tvalid_1's l1: 0.28956\n",
      "[7300]\ttraining's l1: 0.163163\tvalid_1's l1: 0.289053\n",
      "[7400]\ttraining's l1: 0.161997\tvalid_1's l1: 0.288646\n",
      "[7500]\ttraining's l1: 0.160741\tvalid_1's l1: 0.288189\n",
      "[7600]\ttraining's l1: 0.15954\tvalid_1's l1: 0.287737\n",
      "[7700]\ttraining's l1: 0.158417\tvalid_1's l1: 0.287326\n",
      "[7800]\ttraining's l1: 0.157333\tvalid_1's l1: 0.28692\n",
      "[7900]\ttraining's l1: 0.156149\tvalid_1's l1: 0.286495\n",
      "[8000]\ttraining's l1: 0.154804\tvalid_1's l1: 0.285979\n",
      "[8100]\ttraining's l1: 0.153594\tvalid_1's l1: 0.285538\n",
      "[8200]\ttraining's l1: 0.152531\tvalid_1's l1: 0.285165\n",
      "[8300]\ttraining's l1: 0.151442\tvalid_1's l1: 0.2848\n",
      "[8400]\ttraining's l1: 0.150302\tvalid_1's l1: 0.284407\n",
      "[8500]\ttraining's l1: 0.149143\tvalid_1's l1: 0.284013\n",
      "[8600]\ttraining's l1: 0.148068\tvalid_1's l1: 0.283644\n",
      "[8700]\ttraining's l1: 0.147077\tvalid_1's l1: 0.283318\n",
      "[8800]\ttraining's l1: 0.146112\tvalid_1's l1: 0.282995\n",
      "[8900]\ttraining's l1: 0.145059\tvalid_1's l1: 0.282655\n",
      "[9000]\ttraining's l1: 0.144104\tvalid_1's l1: 0.282348\n",
      "[9100]\ttraining's l1: 0.143131\tvalid_1's l1: 0.282033\n",
      "[9200]\ttraining's l1: 0.142034\tvalid_1's l1: 0.281663\n",
      "[9300]\ttraining's l1: 0.14112\tvalid_1's l1: 0.281363\n",
      "[9400]\ttraining's l1: 0.140255\tvalid_1's l1: 0.281079\n",
      "[9500]\ttraining's l1: 0.139343\tvalid_1's l1: 0.280775\n",
      "[9600]\ttraining's l1: 0.138402\tvalid_1's l1: 0.280468\n",
      "[9700]\ttraining's l1: 0.137521\tvalid_1's l1: 0.280199\n",
      "[9800]\ttraining's l1: 0.13664\tvalid_1's l1: 0.279908\n",
      "[9900]\ttraining's l1: 0.135751\tvalid_1's l1: 0.279611\n",
      "[10000]\ttraining's l1: 0.134824\tvalid_1's l1: 0.279289\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.134824\tvalid_1's l1: 0.279289\n",
      "2JHC Fold 2, logMAE: -1.2755063384453953\n",
      "*** Training Model for 3JHH ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'r_x_1', 'r_x_2', 'r_x_3',\n",
      "       'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8', 'r_x_9', 'r_x_10',\n",
      "       'r_x_11', 'r_x_12', 'r_y_2', 'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6',\n",
      "       'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10', 'r_y_11', 'r_y_12', 'r_z_3',\n",
      "       'r_z_4', 'r_z_5', 'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10',\n",
      "       'r_z_11', 'r_z_12'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.323254\tvalid_1's l1: 0.332075\n",
      "[200]\ttraining's l1: 0.272794\tvalid_1's l1: 0.286579\n",
      "[300]\ttraining's l1: 0.248424\tvalid_1's l1: 0.265607\n",
      "[400]\ttraining's l1: 0.229921\tvalid_1's l1: 0.250239\n",
      "[500]\ttraining's l1: 0.216253\tvalid_1's l1: 0.239249\n",
      "[600]\ttraining's l1: 0.205487\tvalid_1's l1: 0.230986\n",
      "[700]\ttraining's l1: 0.196787\tvalid_1's l1: 0.224482\n",
      "[800]\ttraining's l1: 0.189754\tvalid_1's l1: 0.219455\n",
      "[900]\ttraining's l1: 0.183365\tvalid_1's l1: 0.214999\n",
      "[1000]\ttraining's l1: 0.177945\tvalid_1's l1: 0.211448\n",
      "[1100]\ttraining's l1: 0.17305\tvalid_1's l1: 0.208284\n",
      "[1200]\ttraining's l1: 0.168882\tvalid_1's l1: 0.205684\n",
      "[1300]\ttraining's l1: 0.165047\tvalid_1's l1: 0.203316\n",
      "[1400]\ttraining's l1: 0.161381\tvalid_1's l1: 0.201165\n",
      "[1500]\ttraining's l1: 0.157959\tvalid_1's l1: 0.199142\n",
      "[1600]\ttraining's l1: 0.154683\tvalid_1's l1: 0.197236\n",
      "[1700]\ttraining's l1: 0.151694\tvalid_1's l1: 0.195548\n",
      "[1800]\ttraining's l1: 0.148961\tvalid_1's l1: 0.193994\n",
      "[1900]\ttraining's l1: 0.146398\tvalid_1's l1: 0.192571\n",
      "[2000]\ttraining's l1: 0.143969\tvalid_1's l1: 0.19128\n",
      "[2100]\ttraining's l1: 0.141219\tvalid_1's l1: 0.18981\n",
      "[2200]\ttraining's l1: 0.138896\tvalid_1's l1: 0.188553\n",
      "[2300]\ttraining's l1: 0.136592\tvalid_1's l1: 0.187364\n",
      "[2400]\ttraining's l1: 0.134436\tvalid_1's l1: 0.186272\n",
      "[2500]\ttraining's l1: 0.132457\tvalid_1's l1: 0.18528\n",
      "[2600]\ttraining's l1: 0.130485\tvalid_1's l1: 0.18431\n",
      "[2700]\ttraining's l1: 0.128622\tvalid_1's l1: 0.183416\n",
      "[2800]\ttraining's l1: 0.126797\tvalid_1's l1: 0.182542\n",
      "[2900]\ttraining's l1: 0.125036\tvalid_1's l1: 0.181739\n",
      "[3000]\ttraining's l1: 0.123443\tvalid_1's l1: 0.180991\n",
      "[3100]\ttraining's l1: 0.121747\tvalid_1's l1: 0.180212\n",
      "[3200]\ttraining's l1: 0.120217\tvalid_1's l1: 0.179487\n",
      "[3300]\ttraining's l1: 0.118773\tvalid_1's l1: 0.178833\n",
      "[3400]\ttraining's l1: 0.117378\tvalid_1's l1: 0.178216\n",
      "[3500]\ttraining's l1: 0.115899\tvalid_1's l1: 0.177577\n",
      "[3600]\ttraining's l1: 0.114494\tvalid_1's l1: 0.176995\n",
      "[3700]\ttraining's l1: 0.113219\tvalid_1's l1: 0.176446\n",
      "[3800]\ttraining's l1: 0.1119\tvalid_1's l1: 0.175909\n",
      "[3900]\ttraining's l1: 0.110627\tvalid_1's l1: 0.175387\n",
      "[4000]\ttraining's l1: 0.109388\tvalid_1's l1: 0.174864\n",
      "[4100]\ttraining's l1: 0.107814\tvalid_1's l1: 0.174172\n",
      "[4200]\ttraining's l1: 0.106545\tvalid_1's l1: 0.17366\n",
      "[4300]\ttraining's l1: 0.105326\tvalid_1's l1: 0.173152\n",
      "[4400]\ttraining's l1: 0.104115\tvalid_1's l1: 0.172692\n",
      "[4500]\ttraining's l1: 0.103013\tvalid_1's l1: 0.172259\n",
      "[4600]\ttraining's l1: 0.101962\tvalid_1's l1: 0.171856\n",
      "[4700]\ttraining's l1: 0.100873\tvalid_1's l1: 0.171447\n",
      "[4800]\ttraining's l1: 0.0997929\tvalid_1's l1: 0.171037\n",
      "[4900]\ttraining's l1: 0.0987218\tvalid_1's l1: 0.170658\n",
      "[5000]\ttraining's l1: 0.0976793\tvalid_1's l1: 0.170276\n",
      "[5100]\ttraining's l1: 0.096656\tvalid_1's l1: 0.169904\n",
      "[5200]\ttraining's l1: 0.0956961\tvalid_1's l1: 0.16954\n",
      "[5300]\ttraining's l1: 0.0946971\tvalid_1's l1: 0.169158\n",
      "[5400]\ttraining's l1: 0.093713\tvalid_1's l1: 0.168787\n",
      "[5500]\ttraining's l1: 0.0927568\tvalid_1's l1: 0.168437\n",
      "[5600]\ttraining's l1: 0.0918436\tvalid_1's l1: 0.168135\n",
      "[5700]\ttraining's l1: 0.0909796\tvalid_1's l1: 0.167835\n",
      "[5800]\ttraining's l1: 0.090074\tvalid_1's l1: 0.167522\n",
      "[5900]\ttraining's l1: 0.0892374\tvalid_1's l1: 0.167227\n",
      "[6000]\ttraining's l1: 0.0883859\tvalid_1's l1: 0.16693\n",
      "[6100]\ttraining's l1: 0.0873228\tvalid_1's l1: 0.166503\n",
      "[6200]\ttraining's l1: 0.0863664\tvalid_1's l1: 0.166151\n",
      "[6300]\ttraining's l1: 0.0854361\tvalid_1's l1: 0.165825\n",
      "[6400]\ttraining's l1: 0.084577\tvalid_1's l1: 0.165537\n",
      "[6500]\ttraining's l1: 0.0837514\tvalid_1's l1: 0.165265\n",
      "[6600]\ttraining's l1: 0.0829398\tvalid_1's l1: 0.164996\n",
      "[6700]\ttraining's l1: 0.0821869\tvalid_1's l1: 0.164742\n",
      "[6800]\ttraining's l1: 0.0814408\tvalid_1's l1: 0.16448\n",
      "[6900]\ttraining's l1: 0.0806844\tvalid_1's l1: 0.164224\n",
      "[7000]\ttraining's l1: 0.0799713\tvalid_1's l1: 0.163992\n",
      "[7100]\ttraining's l1: 0.0792752\tvalid_1's l1: 0.163763\n",
      "[7200]\ttraining's l1: 0.0785728\tvalid_1's l1: 0.163547\n",
      "[7300]\ttraining's l1: 0.0778594\tvalid_1's l1: 0.163315\n",
      "[7400]\ttraining's l1: 0.0771844\tvalid_1's l1: 0.163098\n",
      "[7500]\ttraining's l1: 0.0764939\tvalid_1's l1: 0.162876\n",
      "[7600]\ttraining's l1: 0.075867\tvalid_1's l1: 0.162677\n",
      "[7700]\ttraining's l1: 0.075228\tvalid_1's l1: 0.162474\n",
      "[7800]\ttraining's l1: 0.0745842\tvalid_1's l1: 0.162295\n",
      "[7900]\ttraining's l1: 0.0739559\tvalid_1's l1: 0.162104\n",
      "[8000]\ttraining's l1: 0.0733759\tvalid_1's l1: 0.16194\n",
      "[8100]\ttraining's l1: 0.0726215\tvalid_1's l1: 0.161677\n",
      "[8200]\ttraining's l1: 0.0719476\tvalid_1's l1: 0.161466\n",
      "[8300]\ttraining's l1: 0.0713076\tvalid_1's l1: 0.16128\n",
      "[8400]\ttraining's l1: 0.0706998\tvalid_1's l1: 0.161099\n",
      "[8500]\ttraining's l1: 0.070133\tvalid_1's l1: 0.160946\n",
      "[8600]\ttraining's l1: 0.0695677\tvalid_1's l1: 0.160783\n",
      "[8700]\ttraining's l1: 0.0689933\tvalid_1's l1: 0.160604\n",
      "[8800]\ttraining's l1: 0.0684568\tvalid_1's l1: 0.16045\n",
      "[8900]\ttraining's l1: 0.0679145\tvalid_1's l1: 0.160303\n",
      "[9000]\ttraining's l1: 0.0673136\tvalid_1's l1: 0.160128\n",
      "[9100]\ttraining's l1: 0.0667993\tvalid_1's l1: 0.159982\n",
      "[9200]\ttraining's l1: 0.0662685\tvalid_1's l1: 0.159834\n",
      "[9300]\ttraining's l1: 0.0657396\tvalid_1's l1: 0.159698\n",
      "[9400]\ttraining's l1: 0.0652353\tvalid_1's l1: 0.159566\n",
      "[9500]\ttraining's l1: 0.064753\tvalid_1's l1: 0.159429\n",
      "[9600]\ttraining's l1: 0.0643344\tvalid_1's l1: 0.159322\n",
      "[9700]\ttraining's l1: 0.0638619\tvalid_1's l1: 0.159201\n",
      "[9800]\ttraining's l1: 0.0634132\tvalid_1's l1: 0.159082\n",
      "[9900]\ttraining's l1: 0.062987\tvalid_1's l1: 0.15896\n",
      "[10000]\ttraining's l1: 0.0625252\tvalid_1's l1: 0.158839\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0625252\tvalid_1's l1: 0.158839\n",
      "3JHH Fold 0, logMAE: -1.8398562483972116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.318827\tvalid_1's l1: 0.328688\n",
      "[200]\ttraining's l1: 0.269746\tvalid_1's l1: 0.284035\n",
      "[300]\ttraining's l1: 0.246028\tvalid_1's l1: 0.263393\n",
      "[400]\ttraining's l1: 0.229818\tvalid_1's l1: 0.25\n",
      "[500]\ttraining's l1: 0.217873\tvalid_1's l1: 0.240518\n",
      "[600]\ttraining's l1: 0.208127\tvalid_1's l1: 0.233104\n",
      "[700]\ttraining's l1: 0.199522\tvalid_1's l1: 0.2267\n",
      "[800]\ttraining's l1: 0.192586\tvalid_1's l1: 0.221744\n",
      "[900]\ttraining's l1: 0.186235\tvalid_1's l1: 0.217318\n",
      "[1000]\ttraining's l1: 0.180841\tvalid_1's l1: 0.213718\n",
      "[1100]\ttraining's l1: 0.175928\tvalid_1's l1: 0.210486\n",
      "[1200]\ttraining's l1: 0.171398\tvalid_1's l1: 0.207671\n",
      "[1300]\ttraining's l1: 0.16701\tvalid_1's l1: 0.204984\n",
      "[1400]\ttraining's l1: 0.163285\tvalid_1's l1: 0.202636\n",
      "[1500]\ttraining's l1: 0.159817\tvalid_1's l1: 0.200608\n",
      "[1600]\ttraining's l1: 0.156579\tvalid_1's l1: 0.198654\n",
      "[1700]\ttraining's l1: 0.153602\tvalid_1's l1: 0.197032\n",
      "[1800]\ttraining's l1: 0.150713\tvalid_1's l1: 0.195389\n",
      "[1900]\ttraining's l1: 0.14809\tvalid_1's l1: 0.193918\n",
      "[2000]\ttraining's l1: 0.1458\tvalid_1's l1: 0.192714\n",
      "[2100]\ttraining's l1: 0.142981\tvalid_1's l1: 0.19112\n",
      "[2200]\ttraining's l1: 0.14053\tvalid_1's l1: 0.189806\n",
      "[2300]\ttraining's l1: 0.13811\tvalid_1's l1: 0.188537\n",
      "[2400]\ttraining's l1: 0.135756\tvalid_1's l1: 0.18731\n",
      "[2500]\ttraining's l1: 0.133719\tvalid_1's l1: 0.186282\n",
      "[2600]\ttraining's l1: 0.131652\tvalid_1's l1: 0.185237\n",
      "[2700]\ttraining's l1: 0.1296\tvalid_1's l1: 0.184241\n",
      "[2800]\ttraining's l1: 0.127595\tvalid_1's l1: 0.183287\n",
      "[2900]\ttraining's l1: 0.125827\tvalid_1's l1: 0.182461\n",
      "[3000]\ttraining's l1: 0.124074\tvalid_1's l1: 0.181619\n",
      "[3100]\ttraining's l1: 0.122393\tvalid_1's l1: 0.180824\n",
      "[3200]\ttraining's l1: 0.120797\tvalid_1's l1: 0.180065\n",
      "[3300]\ttraining's l1: 0.119233\tvalid_1's l1: 0.179353\n",
      "[3400]\ttraining's l1: 0.117622\tvalid_1's l1: 0.17866\n",
      "[3500]\ttraining's l1: 0.116108\tvalid_1's l1: 0.177994\n",
      "[3600]\ttraining's l1: 0.114597\tvalid_1's l1: 0.177349\n",
      "[3700]\ttraining's l1: 0.113232\tvalid_1's l1: 0.176765\n",
      "[3800]\ttraining's l1: 0.111822\tvalid_1's l1: 0.176165\n",
      "[3900]\ttraining's l1: 0.110482\tvalid_1's l1: 0.175593\n",
      "[4000]\ttraining's l1: 0.109149\tvalid_1's l1: 0.175042\n",
      "[4100]\ttraining's l1: 0.10758\tvalid_1's l1: 0.174379\n",
      "[4200]\ttraining's l1: 0.106162\tvalid_1's l1: 0.173823\n",
      "[4300]\ttraining's l1: 0.104959\tvalid_1's l1: 0.17335\n",
      "[4400]\ttraining's l1: 0.103751\tvalid_1's l1: 0.172903\n",
      "[4500]\ttraining's l1: 0.102542\tvalid_1's l1: 0.172439\n",
      "[4600]\ttraining's l1: 0.101399\tvalid_1's l1: 0.17199\n",
      "[4700]\ttraining's l1: 0.100246\tvalid_1's l1: 0.171548\n",
      "[4800]\ttraining's l1: 0.0991232\tvalid_1's l1: 0.171099\n",
      "[4900]\ttraining's l1: 0.0981234\tvalid_1's l1: 0.170694\n",
      "[5000]\ttraining's l1: 0.0970547\tvalid_1's l1: 0.170281\n",
      "[5100]\ttraining's l1: 0.0960198\tvalid_1's l1: 0.169874\n",
      "[5200]\ttraining's l1: 0.0949835\tvalid_1's l1: 0.169517\n",
      "[5300]\ttraining's l1: 0.0939998\tvalid_1's l1: 0.169154\n",
      "[5400]\ttraining's l1: 0.0931016\tvalid_1's l1: 0.168811\n",
      "[5500]\ttraining's l1: 0.0921993\tvalid_1's l1: 0.168487\n",
      "[5600]\ttraining's l1: 0.0913364\tvalid_1's l1: 0.168166\n",
      "[5700]\ttraining's l1: 0.090412\tvalid_1's l1: 0.167862\n",
      "[5800]\ttraining's l1: 0.0895563\tvalid_1's l1: 0.167576\n",
      "[5900]\ttraining's l1: 0.0887502\tvalid_1's l1: 0.167303\n",
      "[6000]\ttraining's l1: 0.0879999\tvalid_1's l1: 0.167053\n",
      "[6100]\ttraining's l1: 0.0868072\tvalid_1's l1: 0.166592\n",
      "[6200]\ttraining's l1: 0.0858744\tvalid_1's l1: 0.166246\n",
      "[6300]\ttraining's l1: 0.0850207\tvalid_1's l1: 0.16595\n",
      "[6400]\ttraining's l1: 0.0842662\tvalid_1's l1: 0.16567\n",
      "[6500]\ttraining's l1: 0.083482\tvalid_1's l1: 0.165379\n",
      "[6600]\ttraining's l1: 0.0827405\tvalid_1's l1: 0.165113\n",
      "[6700]\ttraining's l1: 0.0820136\tvalid_1's l1: 0.164864\n",
      "[6800]\ttraining's l1: 0.0812702\tvalid_1's l1: 0.164611\n",
      "[6900]\ttraining's l1: 0.0805913\tvalid_1's l1: 0.164375\n",
      "[7000]\ttraining's l1: 0.0798766\tvalid_1's l1: 0.164128\n",
      "[7100]\ttraining's l1: 0.0791838\tvalid_1's l1: 0.163918\n",
      "[7200]\ttraining's l1: 0.0785152\tvalid_1's l1: 0.163702\n",
      "[7300]\ttraining's l1: 0.0778343\tvalid_1's l1: 0.163486\n",
      "[7400]\ttraining's l1: 0.0771593\tvalid_1's l1: 0.163269\n",
      "[7500]\ttraining's l1: 0.0765113\tvalid_1's l1: 0.16305\n",
      "[7600]\ttraining's l1: 0.0758548\tvalid_1's l1: 0.162825\n",
      "[7700]\ttraining's l1: 0.0752081\tvalid_1's l1: 0.162646\n",
      "[7800]\ttraining's l1: 0.0746813\tvalid_1's l1: 0.16247\n",
      "[7900]\ttraining's l1: 0.0740521\tvalid_1's l1: 0.162264\n",
      "[8000]\ttraining's l1: 0.0735218\tvalid_1's l1: 0.162093\n",
      "[8100]\ttraining's l1: 0.0727116\tvalid_1's l1: 0.161831\n",
      "[8200]\ttraining's l1: 0.0720306\tvalid_1's l1: 0.161621\n",
      "[8300]\ttraining's l1: 0.0713826\tvalid_1's l1: 0.161414\n",
      "[8400]\ttraining's l1: 0.0707789\tvalid_1's l1: 0.161227\n",
      "[8500]\ttraining's l1: 0.0701555\tvalid_1's l1: 0.161046\n",
      "[8600]\ttraining's l1: 0.0695849\tvalid_1's l1: 0.160876\n",
      "[8700]\ttraining's l1: 0.0690088\tvalid_1's l1: 0.160702\n",
      "[8800]\ttraining's l1: 0.0684175\tvalid_1's l1: 0.160535\n",
      "[8900]\ttraining's l1: 0.0678551\tvalid_1's l1: 0.160389\n",
      "[9000]\ttraining's l1: 0.0672854\tvalid_1's l1: 0.160226\n",
      "[9100]\ttraining's l1: 0.0667316\tvalid_1's l1: 0.160075\n",
      "[9200]\ttraining's l1: 0.0661921\tvalid_1's l1: 0.159933\n",
      "[9300]\ttraining's l1: 0.0656422\tvalid_1's l1: 0.159792\n",
      "[9400]\ttraining's l1: 0.0651165\tvalid_1's l1: 0.159647\n",
      "[9500]\ttraining's l1: 0.064653\tvalid_1's l1: 0.159509\n",
      "[9600]\ttraining's l1: 0.0641691\tvalid_1's l1: 0.159391\n",
      "[9700]\ttraining's l1: 0.0636779\tvalid_1's l1: 0.159256\n",
      "[9800]\ttraining's l1: 0.0632039\tvalid_1's l1: 0.159139\n",
      "[9900]\ttraining's l1: 0.0627456\tvalid_1's l1: 0.15902\n",
      "[10000]\ttraining's l1: 0.0623028\tvalid_1's l1: 0.158902\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0623028\tvalid_1's l1: 0.158902\n",
      "3JHH Fold 1, logMAE: -1.8394690427435416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.321347\tvalid_1's l1: 0.330068\n",
      "[200]\ttraining's l1: 0.272635\tvalid_1's l1: 0.286358\n",
      "[300]\ttraining's l1: 0.246774\tvalid_1's l1: 0.263703\n",
      "[400]\ttraining's l1: 0.230153\tvalid_1's l1: 0.249968\n",
      "[500]\ttraining's l1: 0.21719\tvalid_1's l1: 0.23971\n",
      "[600]\ttraining's l1: 0.206937\tvalid_1's l1: 0.231916\n",
      "[700]\ttraining's l1: 0.198574\tvalid_1's l1: 0.225887\n",
      "[800]\ttraining's l1: 0.191468\tvalid_1's l1: 0.220764\n",
      "[900]\ttraining's l1: 0.185162\tvalid_1's l1: 0.21639\n",
      "[1000]\ttraining's l1: 0.179318\tvalid_1's l1: 0.212549\n",
      "[1100]\ttraining's l1: 0.174204\tvalid_1's l1: 0.209223\n",
      "[1200]\ttraining's l1: 0.169902\tvalid_1's l1: 0.206579\n",
      "[1300]\ttraining's l1: 0.165827\tvalid_1's l1: 0.204089\n",
      "[1400]\ttraining's l1: 0.16212\tvalid_1's l1: 0.201907\n",
      "[1500]\ttraining's l1: 0.158657\tvalid_1's l1: 0.199891\n",
      "[1600]\ttraining's l1: 0.15539\tvalid_1's l1: 0.197974\n",
      "[1700]\ttraining's l1: 0.152327\tvalid_1's l1: 0.196223\n",
      "[1800]\ttraining's l1: 0.149335\tvalid_1's l1: 0.194553\n",
      "[1900]\ttraining's l1: 0.146732\tvalid_1's l1: 0.193116\n",
      "[2000]\ttraining's l1: 0.144255\tvalid_1's l1: 0.191805\n",
      "[2100]\ttraining's l1: 0.141902\tvalid_1's l1: 0.19053\n",
      "[2200]\ttraining's l1: 0.139648\tvalid_1's l1: 0.189276\n",
      "[2300]\ttraining's l1: 0.137353\tvalid_1's l1: 0.188079\n",
      "[2400]\ttraining's l1: 0.135241\tvalid_1's l1: 0.18698\n",
      "[2500]\ttraining's l1: 0.133184\tvalid_1's l1: 0.185963\n",
      "[2600]\ttraining's l1: 0.131\tvalid_1's l1: 0.184858\n",
      "[2700]\ttraining's l1: 0.129146\tvalid_1's l1: 0.183931\n",
      "[2800]\ttraining's l1: 0.1272\tvalid_1's l1: 0.182965\n",
      "[2900]\ttraining's l1: 0.125169\tvalid_1's l1: 0.181979\n",
      "[3000]\ttraining's l1: 0.123495\tvalid_1's l1: 0.18119\n",
      "[3100]\ttraining's l1: 0.121832\tvalid_1's l1: 0.180424\n",
      "[3200]\ttraining's l1: 0.120114\tvalid_1's l1: 0.179637\n",
      "[3300]\ttraining's l1: 0.118588\tvalid_1's l1: 0.178937\n",
      "[3400]\ttraining's l1: 0.117037\tvalid_1's l1: 0.178258\n",
      "[3500]\ttraining's l1: 0.115622\tvalid_1's l1: 0.177642\n",
      "[3600]\ttraining's l1: 0.114164\tvalid_1's l1: 0.177001\n",
      "[3700]\ttraining's l1: 0.112659\tvalid_1's l1: 0.17637\n",
      "[3800]\ttraining's l1: 0.111308\tvalid_1's l1: 0.175824\n",
      "[3900]\ttraining's l1: 0.109994\tvalid_1's l1: 0.175284\n",
      "[4000]\ttraining's l1: 0.10879\tvalid_1's l1: 0.17477\n",
      "[4100]\ttraining's l1: 0.107286\tvalid_1's l1: 0.174163\n",
      "[4200]\ttraining's l1: 0.105971\tvalid_1's l1: 0.173634\n",
      "[4300]\ttraining's l1: 0.104638\tvalid_1's l1: 0.173114\n",
      "[4400]\ttraining's l1: 0.103444\tvalid_1's l1: 0.172652\n",
      "[4500]\ttraining's l1: 0.102284\tvalid_1's l1: 0.172163\n",
      "[4600]\ttraining's l1: 0.101169\tvalid_1's l1: 0.171737\n",
      "[4700]\ttraining's l1: 0.100055\tvalid_1's l1: 0.171312\n",
      "[4800]\ttraining's l1: 0.0989662\tvalid_1's l1: 0.170909\n",
      "[4900]\ttraining's l1: 0.0979168\tvalid_1's l1: 0.170533\n",
      "[5000]\ttraining's l1: 0.0968244\tvalid_1's l1: 0.170137\n",
      "[5100]\ttraining's l1: 0.0958692\tvalid_1's l1: 0.169768\n",
      "[5200]\ttraining's l1: 0.0948091\tvalid_1's l1: 0.169384\n",
      "[5300]\ttraining's l1: 0.0938916\tvalid_1's l1: 0.16904\n",
      "[5400]\ttraining's l1: 0.0929351\tvalid_1's l1: 0.168699\n",
      "[5500]\ttraining's l1: 0.0919983\tvalid_1's l1: 0.168371\n",
      "[5600]\ttraining's l1: 0.0911134\tvalid_1's l1: 0.168069\n",
      "[5700]\ttraining's l1: 0.0901783\tvalid_1's l1: 0.167733\n",
      "[5800]\ttraining's l1: 0.0893707\tvalid_1's l1: 0.167452\n",
      "[5900]\ttraining's l1: 0.0885415\tvalid_1's l1: 0.16717\n",
      "[6000]\ttraining's l1: 0.0877625\tvalid_1's l1: 0.166913\n",
      "[6100]\ttraining's l1: 0.0867383\tvalid_1's l1: 0.166532\n",
      "[6200]\ttraining's l1: 0.0857982\tvalid_1's l1: 0.166217\n",
      "[6300]\ttraining's l1: 0.0848818\tvalid_1's l1: 0.165923\n",
      "[6400]\ttraining's l1: 0.0839778\tvalid_1's l1: 0.165631\n",
      "[6500]\ttraining's l1: 0.0831555\tvalid_1's l1: 0.165361\n",
      "[6600]\ttraining's l1: 0.0823247\tvalid_1's l1: 0.1651\n",
      "[6700]\ttraining's l1: 0.0814212\tvalid_1's l1: 0.164827\n",
      "[6800]\ttraining's l1: 0.0806472\tvalid_1's l1: 0.16457\n",
      "[6900]\ttraining's l1: 0.0799135\tvalid_1's l1: 0.164326\n",
      "[7000]\ttraining's l1: 0.0792112\tvalid_1's l1: 0.164099\n",
      "[7100]\ttraining's l1: 0.0784964\tvalid_1's l1: 0.163869\n",
      "[7200]\ttraining's l1: 0.0777691\tvalid_1's l1: 0.163645\n",
      "[7300]\ttraining's l1: 0.0770922\tvalid_1's l1: 0.163435\n",
      "[7400]\ttraining's l1: 0.0763836\tvalid_1's l1: 0.163217\n",
      "[7500]\ttraining's l1: 0.0758038\tvalid_1's l1: 0.163044\n",
      "[7600]\ttraining's l1: 0.0751475\tvalid_1's l1: 0.162848\n",
      "[7700]\ttraining's l1: 0.0744831\tvalid_1's l1: 0.16265\n",
      "[7800]\ttraining's l1: 0.073817\tvalid_1's l1: 0.16245\n",
      "[7900]\ttraining's l1: 0.0732455\tvalid_1's l1: 0.16229\n",
      "[8000]\ttraining's l1: 0.0726891\tvalid_1's l1: 0.162121\n",
      "[8100]\ttraining's l1: 0.071981\tvalid_1's l1: 0.161878\n",
      "[8200]\ttraining's l1: 0.0713129\tvalid_1's l1: 0.161668\n",
      "[8300]\ttraining's l1: 0.0706495\tvalid_1's l1: 0.161456\n",
      "[8400]\ttraining's l1: 0.0699867\tvalid_1's l1: 0.161254\n",
      "[8500]\ttraining's l1: 0.0693685\tvalid_1's l1: 0.161063\n",
      "[8600]\ttraining's l1: 0.0687603\tvalid_1's l1: 0.160895\n",
      "[8700]\ttraining's l1: 0.0681586\tvalid_1's l1: 0.160725\n",
      "[8800]\ttraining's l1: 0.0675774\tvalid_1's l1: 0.160575\n",
      "[8900]\ttraining's l1: 0.067043\tvalid_1's l1: 0.160426\n",
      "[9000]\ttraining's l1: 0.0664722\tvalid_1's l1: 0.160272\n",
      "[9100]\ttraining's l1: 0.065929\tvalid_1's l1: 0.16013\n",
      "[9200]\ttraining's l1: 0.0653871\tvalid_1's l1: 0.159976\n",
      "[9300]\ttraining's l1: 0.0648758\tvalid_1's l1: 0.159838\n",
      "[9400]\ttraining's l1: 0.0643624\tvalid_1's l1: 0.159697\n",
      "[9500]\ttraining's l1: 0.0638902\tvalid_1's l1: 0.159568\n",
      "[9600]\ttraining's l1: 0.0634333\tvalid_1's l1: 0.159446\n",
      "[9700]\ttraining's l1: 0.0629758\tvalid_1's l1: 0.159315\n",
      "[9800]\ttraining's l1: 0.0625157\tvalid_1's l1: 0.159194\n",
      "[9900]\ttraining's l1: 0.0620547\tvalid_1's l1: 0.159061\n",
      "[10000]\ttraining's l1: 0.0615944\tvalid_1's l1: 0.158929\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0615944\tvalid_1's l1: 0.158929\n",
      "3JHH Fold 2, logMAE: -1.8393008143870124\n",
      "*** Training Model for 3JHC ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
      "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
      "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
      "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
      "       'r_z_13', 'r_z_14', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
      "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
      "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
      "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
      "       'r_z_13', 'r_z_14'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.621158\tvalid_1's l1: 0.63125\n",
      "[200]\ttraining's l1: 0.523015\tvalid_1's l1: 0.53834\n",
      "[300]\ttraining's l1: 0.479319\tvalid_1's l1: 0.498484\n",
      "[400]\ttraining's l1: 0.447118\tvalid_1's l1: 0.4701\n",
      "[500]\ttraining's l1: 0.423923\tvalid_1's l1: 0.450413\n",
      "[600]\ttraining's l1: 0.406709\tvalid_1's l1: 0.436168\n",
      "[700]\ttraining's l1: 0.392632\tvalid_1's l1: 0.424952\n",
      "[800]\ttraining's l1: 0.381166\tvalid_1's l1: 0.416234\n",
      "[900]\ttraining's l1: 0.369979\tvalid_1's l1: 0.407545\n",
      "[1000]\ttraining's l1: 0.359982\tvalid_1's l1: 0.400182\n",
      "[1100]\ttraining's l1: 0.351226\tvalid_1's l1: 0.393639\n",
      "[1200]\ttraining's l1: 0.343503\tvalid_1's l1: 0.388177\n",
      "[1300]\ttraining's l1: 0.336003\tvalid_1's l1: 0.382876\n",
      "[1400]\ttraining's l1: 0.32926\tvalid_1's l1: 0.378191\n",
      "[1500]\ttraining's l1: 0.322905\tvalid_1's l1: 0.37389\n",
      "[1600]\ttraining's l1: 0.317419\tvalid_1's l1: 0.370305\n",
      "[1700]\ttraining's l1: 0.312168\tvalid_1's l1: 0.366839\n",
      "[1800]\ttraining's l1: 0.307054\tvalid_1's l1: 0.363528\n",
      "[1900]\ttraining's l1: 0.302244\tvalid_1's l1: 0.360585\n",
      "[2000]\ttraining's l1: 0.298026\tvalid_1's l1: 0.358026\n",
      "[2100]\ttraining's l1: 0.294084\tvalid_1's l1: 0.355814\n",
      "[2200]\ttraining's l1: 0.290397\tvalid_1's l1: 0.35358\n",
      "[2300]\ttraining's l1: 0.287126\tvalid_1's l1: 0.351623\n",
      "[2400]\ttraining's l1: 0.283764\tvalid_1's l1: 0.34965\n",
      "[2500]\ttraining's l1: 0.280144\tvalid_1's l1: 0.347646\n",
      "[2600]\ttraining's l1: 0.277128\tvalid_1's l1: 0.345958\n",
      "[2700]\ttraining's l1: 0.273811\tvalid_1's l1: 0.34411\n",
      "[2800]\ttraining's l1: 0.270509\tvalid_1's l1: 0.342313\n",
      "[2900]\ttraining's l1: 0.267668\tvalid_1's l1: 0.340753\n",
      "[3000]\ttraining's l1: 0.264893\tvalid_1's l1: 0.339247\n",
      "[3100]\ttraining's l1: 0.261735\tvalid_1's l1: 0.337572\n",
      "[3200]\ttraining's l1: 0.258945\tvalid_1's l1: 0.336153\n",
      "[3300]\ttraining's l1: 0.256225\tvalid_1's l1: 0.33474\n",
      "[3400]\ttraining's l1: 0.253549\tvalid_1's l1: 0.33337\n",
      "[3500]\ttraining's l1: 0.251026\tvalid_1's l1: 0.332123\n",
      "[3600]\ttraining's l1: 0.248705\tvalid_1's l1: 0.331015\n",
      "[3700]\ttraining's l1: 0.24616\tvalid_1's l1: 0.329779\n",
      "[3800]\ttraining's l1: 0.243741\tvalid_1's l1: 0.328593\n",
      "[3900]\ttraining's l1: 0.241421\tvalid_1's l1: 0.327494\n",
      "[4000]\ttraining's l1: 0.239192\tvalid_1's l1: 0.326466\n",
      "[4100]\ttraining's l1: 0.236586\tvalid_1's l1: 0.325266\n",
      "[4200]\ttraining's l1: 0.234467\tvalid_1's l1: 0.324371\n",
      "[4300]\ttraining's l1: 0.232091\tvalid_1's l1: 0.32333\n",
      "[4400]\ttraining's l1: 0.229753\tvalid_1's l1: 0.322308\n",
      "[4500]\ttraining's l1: 0.227619\tvalid_1's l1: 0.321347\n",
      "[4600]\ttraining's l1: 0.225543\tvalid_1's l1: 0.320511\n",
      "[4700]\ttraining's l1: 0.223408\tvalid_1's l1: 0.319599\n",
      "[4800]\ttraining's l1: 0.221399\tvalid_1's l1: 0.318747\n",
      "[4900]\ttraining's l1: 0.219496\tvalid_1's l1: 0.317955\n",
      "[5000]\ttraining's l1: 0.217609\tvalid_1's l1: 0.317136\n",
      "[5100]\ttraining's l1: 0.215683\tvalid_1's l1: 0.316392\n",
      "[5200]\ttraining's l1: 0.213725\tvalid_1's l1: 0.315578\n",
      "[5300]\ttraining's l1: 0.212011\tvalid_1's l1: 0.314927\n",
      "[5400]\ttraining's l1: 0.210298\tvalid_1's l1: 0.314214\n",
      "[5500]\ttraining's l1: 0.208453\tvalid_1's l1: 0.313463\n",
      "[5600]\ttraining's l1: 0.206666\tvalid_1's l1: 0.312804\n",
      "[5700]\ttraining's l1: 0.205075\tvalid_1's l1: 0.312167\n",
      "[5800]\ttraining's l1: 0.203502\tvalid_1's l1: 0.311565\n",
      "[5900]\ttraining's l1: 0.201878\tvalid_1's l1: 0.310979\n",
      "[6000]\ttraining's l1: 0.20019\tvalid_1's l1: 0.310322\n",
      "[6100]\ttraining's l1: 0.198335\tvalid_1's l1: 0.309659\n",
      "[6200]\ttraining's l1: 0.196655\tvalid_1's l1: 0.309068\n",
      "[6300]\ttraining's l1: 0.195057\tvalid_1's l1: 0.308496\n",
      "[6400]\ttraining's l1: 0.193509\tvalid_1's l1: 0.307927\n",
      "[6500]\ttraining's l1: 0.192096\tvalid_1's l1: 0.307425\n",
      "[6600]\ttraining's l1: 0.190543\tvalid_1's l1: 0.306861\n",
      "[6700]\ttraining's l1: 0.189155\tvalid_1's l1: 0.30636\n",
      "[6800]\ttraining's l1: 0.18771\tvalid_1's l1: 0.305871\n",
      "[6900]\ttraining's l1: 0.186272\tvalid_1's l1: 0.305382\n",
      "[7000]\ttraining's l1: 0.18483\tvalid_1's l1: 0.304882\n",
      "[7100]\ttraining's l1: 0.183522\tvalid_1's l1: 0.304425\n",
      "[7200]\ttraining's l1: 0.182223\tvalid_1's l1: 0.303977\n",
      "[7300]\ttraining's l1: 0.180871\tvalid_1's l1: 0.303514\n",
      "[7400]\ttraining's l1: 0.179466\tvalid_1's l1: 0.303067\n",
      "[7500]\ttraining's l1: 0.178082\tvalid_1's l1: 0.302603\n",
      "[7600]\ttraining's l1: 0.176783\tvalid_1's l1: 0.302173\n",
      "[7700]\ttraining's l1: 0.175485\tvalid_1's l1: 0.301742\n",
      "[7800]\ttraining's l1: 0.174312\tvalid_1's l1: 0.301383\n",
      "[7900]\ttraining's l1: 0.173102\tvalid_1's l1: 0.300984\n",
      "[8000]\ttraining's l1: 0.171874\tvalid_1's l1: 0.300603\n",
      "[8100]\ttraining's l1: 0.170311\tvalid_1's l1: 0.300118\n",
      "[8200]\ttraining's l1: 0.169119\tvalid_1's l1: 0.299771\n",
      "[8300]\ttraining's l1: 0.167922\tvalid_1's l1: 0.2994\n",
      "[8400]\ttraining's l1: 0.166741\tvalid_1's l1: 0.29904\n",
      "[8500]\ttraining's l1: 0.165523\tvalid_1's l1: 0.298672\n",
      "[8600]\ttraining's l1: 0.164333\tvalid_1's l1: 0.29827\n",
      "[8700]\ttraining's l1: 0.16318\tvalid_1's l1: 0.297934\n",
      "[8800]\ttraining's l1: 0.162063\tvalid_1's l1: 0.297621\n",
      "[8900]\ttraining's l1: 0.160886\tvalid_1's l1: 0.297258\n",
      "[9000]\ttraining's l1: 0.159802\tvalid_1's l1: 0.296935\n",
      "[9100]\ttraining's l1: 0.158733\tvalid_1's l1: 0.296605\n",
      "[9200]\ttraining's l1: 0.157767\tvalid_1's l1: 0.296341\n",
      "[9300]\ttraining's l1: 0.15675\tvalid_1's l1: 0.296013\n",
      "[9400]\ttraining's l1: 0.15572\tvalid_1's l1: 0.295723\n",
      "[9500]\ttraining's l1: 0.154739\tvalid_1's l1: 0.295448\n",
      "[9600]\ttraining's l1: 0.153734\tvalid_1's l1: 0.295164\n",
      "[9700]\ttraining's l1: 0.152635\tvalid_1's l1: 0.294864\n",
      "[9800]\ttraining's l1: 0.151795\tvalid_1's l1: 0.294637\n",
      "[9900]\ttraining's l1: 0.150775\tvalid_1's l1: 0.294372\n",
      "[10000]\ttraining's l1: 0.149781\tvalid_1's l1: 0.294093\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.149781\tvalid_1's l1: 0.294093\n",
      "3JHC Fold 0, logMAE: -1.223858956315757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.621979\tvalid_1's l1: 0.632212\n",
      "[200]\ttraining's l1: 0.522221\tvalid_1's l1: 0.537978\n",
      "[300]\ttraining's l1: 0.478026\tvalid_1's l1: 0.498113\n",
      "[400]\ttraining's l1: 0.44779\tvalid_1's l1: 0.471513\n",
      "[500]\ttraining's l1: 0.424733\tvalid_1's l1: 0.451697\n",
      "[600]\ttraining's l1: 0.407233\tvalid_1's l1: 0.437178\n",
      "[700]\ttraining's l1: 0.392366\tvalid_1's l1: 0.425188\n",
      "[800]\ttraining's l1: 0.380236\tvalid_1's l1: 0.415748\n",
      "[900]\ttraining's l1: 0.369227\tvalid_1's l1: 0.407385\n",
      "[1000]\ttraining's l1: 0.359479\tvalid_1's l1: 0.399928\n",
      "[1100]\ttraining's l1: 0.351349\tvalid_1's l1: 0.393938\n",
      "[1200]\ttraining's l1: 0.343784\tvalid_1's l1: 0.38853\n",
      "[1300]\ttraining's l1: 0.336591\tvalid_1's l1: 0.383389\n",
      "[1400]\ttraining's l1: 0.330422\tvalid_1's l1: 0.379214\n",
      "[1500]\ttraining's l1: 0.32424\tvalid_1's l1: 0.374949\n",
      "[1600]\ttraining's l1: 0.318475\tvalid_1's l1: 0.371162\n",
      "[1700]\ttraining's l1: 0.313147\tvalid_1's l1: 0.367697\n",
      "[1800]\ttraining's l1: 0.308212\tvalid_1's l1: 0.364548\n",
      "[1900]\ttraining's l1: 0.303205\tvalid_1's l1: 0.3614\n",
      "[2000]\ttraining's l1: 0.2988\tvalid_1's l1: 0.358675\n",
      "[2100]\ttraining's l1: 0.295176\tvalid_1's l1: 0.356455\n",
      "[2200]\ttraining's l1: 0.291621\tvalid_1's l1: 0.3544\n",
      "[2300]\ttraining's l1: 0.288036\tvalid_1's l1: 0.352236\n",
      "[2400]\ttraining's l1: 0.284463\tvalid_1's l1: 0.350177\n",
      "[2500]\ttraining's l1: 0.281098\tvalid_1's l1: 0.34825\n",
      "[2600]\ttraining's l1: 0.277687\tvalid_1's l1: 0.346318\n",
      "[2700]\ttraining's l1: 0.27451\tvalid_1's l1: 0.344529\n",
      "[2800]\ttraining's l1: 0.271441\tvalid_1's l1: 0.342935\n",
      "[2900]\ttraining's l1: 0.268402\tvalid_1's l1: 0.341247\n",
      "[3000]\ttraining's l1: 0.265154\tvalid_1's l1: 0.339469\n",
      "[3100]\ttraining's l1: 0.262432\tvalid_1's l1: 0.338076\n",
      "[3200]\ttraining's l1: 0.259749\tvalid_1's l1: 0.336706\n",
      "[3300]\ttraining's l1: 0.257016\tvalid_1's l1: 0.335332\n",
      "[3400]\ttraining's l1: 0.254252\tvalid_1's l1: 0.333911\n",
      "[3500]\ttraining's l1: 0.251578\tvalid_1's l1: 0.332571\n",
      "[3600]\ttraining's l1: 0.249243\tvalid_1's l1: 0.33143\n",
      "[3700]\ttraining's l1: 0.246796\tvalid_1's l1: 0.330212\n",
      "[3800]\ttraining's l1: 0.244455\tvalid_1's l1: 0.329096\n",
      "[3900]\ttraining's l1: 0.242161\tvalid_1's l1: 0.327992\n",
      "[4000]\ttraining's l1: 0.239813\tvalid_1's l1: 0.326866\n",
      "[4100]\ttraining's l1: 0.236985\tvalid_1's l1: 0.325551\n",
      "[4200]\ttraining's l1: 0.234601\tvalid_1's l1: 0.324478\n",
      "[4300]\ttraining's l1: 0.232243\tvalid_1's l1: 0.323414\n",
      "[4400]\ttraining's l1: 0.229974\tvalid_1's l1: 0.322345\n",
      "[4500]\ttraining's l1: 0.227886\tvalid_1's l1: 0.321394\n",
      "[4600]\ttraining's l1: 0.225661\tvalid_1's l1: 0.320397\n",
      "[4700]\ttraining's l1: 0.223733\tvalid_1's l1: 0.319581\n",
      "[4800]\ttraining's l1: 0.221658\tvalid_1's l1: 0.318628\n",
      "[4900]\ttraining's l1: 0.219417\tvalid_1's l1: 0.317629\n",
      "[5000]\ttraining's l1: 0.217411\tvalid_1's l1: 0.316796\n",
      "[5100]\ttraining's l1: 0.215505\tvalid_1's l1: 0.315983\n",
      "[5200]\ttraining's l1: 0.213707\tvalid_1's l1: 0.315265\n",
      "[5300]\ttraining's l1: 0.211904\tvalid_1's l1: 0.314524\n",
      "[5400]\ttraining's l1: 0.20985\tvalid_1's l1: 0.313682\n",
      "[5500]\ttraining's l1: 0.207966\tvalid_1's l1: 0.312873\n",
      "[5600]\ttraining's l1: 0.206283\tvalid_1's l1: 0.312209\n",
      "[5700]\ttraining's l1: 0.204599\tvalid_1's l1: 0.311547\n",
      "[5800]\ttraining's l1: 0.202796\tvalid_1's l1: 0.310852\n",
      "[5900]\ttraining's l1: 0.201136\tvalid_1's l1: 0.310199\n",
      "[6000]\ttraining's l1: 0.199513\tvalid_1's l1: 0.309585\n",
      "[6100]\ttraining's l1: 0.197556\tvalid_1's l1: 0.308785\n",
      "[6200]\ttraining's l1: 0.195959\tvalid_1's l1: 0.308173\n",
      "[6300]\ttraining's l1: 0.194537\tvalid_1's l1: 0.307632\n",
      "[6400]\ttraining's l1: 0.193118\tvalid_1's l1: 0.307107\n",
      "[6500]\ttraining's l1: 0.191661\tvalid_1's l1: 0.306539\n",
      "[6600]\ttraining's l1: 0.19015\tvalid_1's l1: 0.305992\n",
      "[6700]\ttraining's l1: 0.188714\tvalid_1's l1: 0.305462\n",
      "[6800]\ttraining's l1: 0.187342\tvalid_1's l1: 0.304957\n",
      "[6900]\ttraining's l1: 0.185993\tvalid_1's l1: 0.304478\n",
      "[7000]\ttraining's l1: 0.184664\tvalid_1's l1: 0.30401\n",
      "[7100]\ttraining's l1: 0.183289\tvalid_1's l1: 0.303505\n",
      "[7200]\ttraining's l1: 0.181971\tvalid_1's l1: 0.303072\n",
      "[7300]\ttraining's l1: 0.180667\tvalid_1's l1: 0.302572\n",
      "[7400]\ttraining's l1: 0.179356\tvalid_1's l1: 0.302192\n",
      "[7500]\ttraining's l1: 0.177968\tvalid_1's l1: 0.301719\n",
      "[7600]\ttraining's l1: 0.176721\tvalid_1's l1: 0.301314\n",
      "[7700]\ttraining's l1: 0.175482\tvalid_1's l1: 0.300901\n",
      "[7800]\ttraining's l1: 0.174314\tvalid_1's l1: 0.300491\n",
      "[7900]\ttraining's l1: 0.17318\tvalid_1's l1: 0.300105\n",
      "[8000]\ttraining's l1: 0.171984\tvalid_1's l1: 0.299702\n",
      "[8100]\ttraining's l1: 0.170478\tvalid_1's l1: 0.299175\n",
      "[8200]\ttraining's l1: 0.16921\tvalid_1's l1: 0.29876\n",
      "[8300]\ttraining's l1: 0.167943\tvalid_1's l1: 0.298355\n",
      "[8400]\ttraining's l1: 0.166728\tvalid_1's l1: 0.297959\n",
      "[8500]\ttraining's l1: 0.165558\tvalid_1's l1: 0.297581\n",
      "[8600]\ttraining's l1: 0.164456\tvalid_1's l1: 0.297256\n",
      "[8700]\ttraining's l1: 0.163327\tvalid_1's l1: 0.296916\n",
      "[8800]\ttraining's l1: 0.162225\tvalid_1's l1: 0.296567\n",
      "[8900]\ttraining's l1: 0.16104\tvalid_1's l1: 0.296188\n",
      "[9000]\ttraining's l1: 0.159982\tvalid_1's l1: 0.295885\n",
      "[9100]\ttraining's l1: 0.158849\tvalid_1's l1: 0.295542\n",
      "[9200]\ttraining's l1: 0.157863\tvalid_1's l1: 0.295252\n",
      "[9300]\ttraining's l1: 0.156874\tvalid_1's l1: 0.294958\n",
      "[9400]\ttraining's l1: 0.155871\tvalid_1's l1: 0.29467\n",
      "[9500]\ttraining's l1: 0.154956\tvalid_1's l1: 0.294392\n",
      "[9600]\ttraining's l1: 0.154015\tvalid_1's l1: 0.294116\n",
      "[9700]\ttraining's l1: 0.153105\tvalid_1's l1: 0.293841\n",
      "[9800]\ttraining's l1: 0.152079\tvalid_1's l1: 0.293531\n",
      "[9900]\ttraining's l1: 0.151169\tvalid_1's l1: 0.293279\n",
      "[10000]\ttraining's l1: 0.150232\tvalid_1's l1: 0.293004\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.150232\tvalid_1's l1: 0.293004\n",
      "3JHC Fold 1, logMAE: -1.2275677110081091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.622624\tvalid_1's l1: 0.633764\n",
      "[200]\ttraining's l1: 0.520455\tvalid_1's l1: 0.537579\n",
      "[300]\ttraining's l1: 0.477532\tvalid_1's l1: 0.498626\n",
      "[400]\ttraining's l1: 0.447495\tvalid_1's l1: 0.472008\n",
      "[500]\ttraining's l1: 0.424724\tvalid_1's l1: 0.452629\n",
      "[600]\ttraining's l1: 0.406689\tvalid_1's l1: 0.437557\n",
      "[700]\ttraining's l1: 0.391606\tvalid_1's l1: 0.425459\n",
      "[800]\ttraining's l1: 0.379466\tvalid_1's l1: 0.415848\n",
      "[900]\ttraining's l1: 0.368864\tvalid_1's l1: 0.407858\n",
      "[1000]\ttraining's l1: 0.359286\tvalid_1's l1: 0.400703\n",
      "[1100]\ttraining's l1: 0.351038\tvalid_1's l1: 0.394763\n",
      "[1200]\ttraining's l1: 0.343568\tvalid_1's l1: 0.389444\n",
      "[1300]\ttraining's l1: 0.336142\tvalid_1's l1: 0.384255\n",
      "[1400]\ttraining's l1: 0.329685\tvalid_1's l1: 0.379756\n",
      "[1500]\ttraining's l1: 0.323796\tvalid_1's l1: 0.375829\n",
      "[1600]\ttraining's l1: 0.318231\tvalid_1's l1: 0.372151\n",
      "[1700]\ttraining's l1: 0.313334\tvalid_1's l1: 0.368982\n",
      "[1800]\ttraining's l1: 0.308278\tvalid_1's l1: 0.365762\n",
      "[1900]\ttraining's l1: 0.303539\tvalid_1's l1: 0.362859\n",
      "[2000]\ttraining's l1: 0.299162\tvalid_1's l1: 0.360161\n",
      "[2100]\ttraining's l1: 0.295382\tvalid_1's l1: 0.357988\n",
      "[2200]\ttraining's l1: 0.291667\tvalid_1's l1: 0.355753\n",
      "[2300]\ttraining's l1: 0.287818\tvalid_1's l1: 0.353511\n",
      "[2400]\ttraining's l1: 0.284002\tvalid_1's l1: 0.351313\n",
      "[2500]\ttraining's l1: 0.280277\tvalid_1's l1: 0.349201\n",
      "[2600]\ttraining's l1: 0.276627\tvalid_1's l1: 0.34719\n",
      "[2700]\ttraining's l1: 0.273138\tvalid_1's l1: 0.345196\n",
      "[2800]\ttraining's l1: 0.270031\tvalid_1's l1: 0.343548\n",
      "[2900]\ttraining's l1: 0.266894\tvalid_1's l1: 0.34189\n",
      "[3000]\ttraining's l1: 0.263734\tvalid_1's l1: 0.340213\n",
      "[3100]\ttraining's l1: 0.260376\tvalid_1's l1: 0.338403\n",
      "[3200]\ttraining's l1: 0.257429\tvalid_1's l1: 0.336855\n",
      "[3300]\ttraining's l1: 0.254483\tvalid_1's l1: 0.335262\n",
      "[3400]\ttraining's l1: 0.251756\tvalid_1's l1: 0.333857\n",
      "[3500]\ttraining's l1: 0.249329\tvalid_1's l1: 0.332661\n",
      "[3600]\ttraining's l1: 0.246776\tvalid_1's l1: 0.331408\n",
      "[3700]\ttraining's l1: 0.244488\tvalid_1's l1: 0.330294\n",
      "[3800]\ttraining's l1: 0.242107\tvalid_1's l1: 0.32918\n",
      "[3900]\ttraining's l1: 0.239859\tvalid_1's l1: 0.328076\n",
      "[4000]\ttraining's l1: 0.237707\tvalid_1's l1: 0.327119\n",
      "[4100]\ttraining's l1: 0.235364\tvalid_1's l1: 0.326083\n",
      "[4200]\ttraining's l1: 0.233063\tvalid_1's l1: 0.325097\n",
      "[4300]\ttraining's l1: 0.230658\tvalid_1's l1: 0.32399\n",
      "[4400]\ttraining's l1: 0.228573\tvalid_1's l1: 0.323071\n",
      "[4500]\ttraining's l1: 0.226435\tvalid_1's l1: 0.322148\n",
      "[4600]\ttraining's l1: 0.224162\tvalid_1's l1: 0.321105\n",
      "[4700]\ttraining's l1: 0.222\tvalid_1's l1: 0.320154\n",
      "[4800]\ttraining's l1: 0.22001\tvalid_1's l1: 0.319271\n",
      "[4900]\ttraining's l1: 0.217816\tvalid_1's l1: 0.318348\n",
      "[5000]\ttraining's l1: 0.215723\tvalid_1's l1: 0.317499\n",
      "[5100]\ttraining's l1: 0.213716\tvalid_1's l1: 0.316686\n",
      "[5200]\ttraining's l1: 0.211867\tvalid_1's l1: 0.315939\n",
      "[5300]\ttraining's l1: 0.209997\tvalid_1's l1: 0.315154\n",
      "[5400]\ttraining's l1: 0.208197\tvalid_1's l1: 0.314417\n",
      "[5500]\ttraining's l1: 0.206628\tvalid_1's l1: 0.313795\n",
      "[5600]\ttraining's l1: 0.204873\tvalid_1's l1: 0.313099\n",
      "[5700]\ttraining's l1: 0.203271\tvalid_1's l1: 0.3125\n",
      "[5800]\ttraining's l1: 0.201727\tvalid_1's l1: 0.311866\n",
      "[5900]\ttraining's l1: 0.200147\tvalid_1's l1: 0.311268\n",
      "[6000]\ttraining's l1: 0.19847\tvalid_1's l1: 0.310595\n",
      "[6100]\ttraining's l1: 0.196613\tvalid_1's l1: 0.309903\n",
      "[6200]\ttraining's l1: 0.195029\tvalid_1's l1: 0.309296\n",
      "[6300]\ttraining's l1: 0.193493\tvalid_1's l1: 0.308732\n",
      "[6400]\ttraining's l1: 0.191979\tvalid_1's l1: 0.308216\n",
      "[6500]\ttraining's l1: 0.190544\tvalid_1's l1: 0.307704\n",
      "[6600]\ttraining's l1: 0.189091\tvalid_1's l1: 0.307156\n",
      "[6700]\ttraining's l1: 0.187742\tvalid_1's l1: 0.306686\n",
      "[6800]\ttraining's l1: 0.186351\tvalid_1's l1: 0.306168\n",
      "[6900]\ttraining's l1: 0.185018\tvalid_1's l1: 0.305703\n",
      "[7000]\ttraining's l1: 0.183644\tvalid_1's l1: 0.305229\n",
      "[7100]\ttraining's l1: 0.182315\tvalid_1's l1: 0.304771\n",
      "[7200]\ttraining's l1: 0.181021\tvalid_1's l1: 0.304334\n",
      "[7300]\ttraining's l1: 0.179714\tvalid_1's l1: 0.303872\n",
      "[7400]\ttraining's l1: 0.178383\tvalid_1's l1: 0.303426\n",
      "[7500]\ttraining's l1: 0.177092\tvalid_1's l1: 0.302983\n",
      "[7600]\ttraining's l1: 0.175867\tvalid_1's l1: 0.302584\n",
      "[7700]\ttraining's l1: 0.174669\tvalid_1's l1: 0.302191\n",
      "[7800]\ttraining's l1: 0.17346\tvalid_1's l1: 0.30176\n",
      "[7900]\ttraining's l1: 0.1723\tvalid_1's l1: 0.301369\n",
      "[8000]\ttraining's l1: 0.171133\tvalid_1's l1: 0.301017\n",
      "[8100]\ttraining's l1: 0.169868\tvalid_1's l1: 0.30061\n",
      "[8200]\ttraining's l1: 0.168609\tvalid_1's l1: 0.300196\n",
      "[8300]\ttraining's l1: 0.167246\tvalid_1's l1: 0.299765\n",
      "[8400]\ttraining's l1: 0.166004\tvalid_1's l1: 0.299393\n",
      "[8500]\ttraining's l1: 0.164712\tvalid_1's l1: 0.299002\n",
      "[8600]\ttraining's l1: 0.163539\tvalid_1's l1: 0.298603\n",
      "[8700]\ttraining's l1: 0.16233\tvalid_1's l1: 0.298217\n",
      "[8800]\ttraining's l1: 0.161159\tvalid_1's l1: 0.29788\n",
      "[8900]\ttraining's l1: 0.160097\tvalid_1's l1: 0.297566\n",
      "[9000]\ttraining's l1: 0.158894\tvalid_1's l1: 0.297214\n",
      "[9100]\ttraining's l1: 0.15782\tvalid_1's l1: 0.296869\n",
      "[9200]\ttraining's l1: 0.156644\tvalid_1's l1: 0.296514\n",
      "[9300]\ttraining's l1: 0.155534\tvalid_1's l1: 0.296173\n",
      "[9400]\ttraining's l1: 0.154505\tvalid_1's l1: 0.295884\n",
      "[9500]\ttraining's l1: 0.153485\tvalid_1's l1: 0.295608\n",
      "[9600]\ttraining's l1: 0.152526\tvalid_1's l1: 0.295332\n",
      "[9700]\ttraining's l1: 0.151485\tvalid_1's l1: 0.295025\n",
      "[9800]\ttraining's l1: 0.150501\tvalid_1's l1: 0.294741\n",
      "[9900]\ttraining's l1: 0.14948\tvalid_1's l1: 0.294438\n",
      "[10000]\ttraining's l1: 0.148546\tvalid_1's l1: 0.294171\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.148546\tvalid_1's l1: 0.294171\n",
      "3JHC Fold 2, logMAE: -1.2235907861637174\n",
      "*** Training Model for 3JHN ***\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
      "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
      "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
      "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
      "       'r_z_13', 'r_z_14', 'scalar_coupling_constant'],\n",
      "      dtype='object')\n",
      "Index(['atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8',\n",
      "       'atom_9', 'atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14',\n",
      "       'r_x_1', 'r_x_2', 'r_x_3', 'r_x_4', 'r_x_5', 'r_x_6', 'r_x_7', 'r_x_8',\n",
      "       'r_x_9', 'r_x_10', 'r_x_11', 'r_x_12', 'r_x_13', 'r_x_14', 'r_y_2',\n",
      "       'r_y_3', 'r_y_4', 'r_y_5', 'r_y_6', 'r_y_7', 'r_y_8', 'r_y_9', 'r_y_10',\n",
      "       'r_y_11', 'r_y_12', 'r_y_13', 'r_y_14', 'r_z_3', 'r_z_4', 'r_z_5',\n",
      "       'r_z_6', 'r_z_7', 'r_z_8', 'r_z_9', 'r_z_10', 'r_z_11', 'r_z_12',\n",
      "       'r_z_13', 'r_z_14'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.208741\tvalid_1's l1: 0.223863\n",
      "[200]\ttraining's l1: 0.176328\tvalid_1's l1: 0.197332\n",
      "[300]\ttraining's l1: 0.158458\tvalid_1's l1: 0.184723\n",
      "[400]\ttraining's l1: 0.146232\tvalid_1's l1: 0.176713\n",
      "[500]\ttraining's l1: 0.136886\tvalid_1's l1: 0.171119\n",
      "[600]\ttraining's l1: 0.129683\tvalid_1's l1: 0.166971\n",
      "[700]\ttraining's l1: 0.12339\tvalid_1's l1: 0.163612\n",
      "[800]\ttraining's l1: 0.118348\tvalid_1's l1: 0.161228\n",
      "[900]\ttraining's l1: 0.113375\tvalid_1's l1: 0.158953\n",
      "[1000]\ttraining's l1: 0.109087\tvalid_1's l1: 0.157075\n",
      "[1100]\ttraining's l1: 0.105183\tvalid_1's l1: 0.155482\n",
      "[1200]\ttraining's l1: 0.101541\tvalid_1's l1: 0.153919\n",
      "[1300]\ttraining's l1: 0.0985799\tvalid_1's l1: 0.1528\n",
      "[1400]\ttraining's l1: 0.0956796\tvalid_1's l1: 0.151785\n",
      "[1500]\ttraining's l1: 0.093155\tvalid_1's l1: 0.150922\n",
      "[1600]\ttraining's l1: 0.0906393\tvalid_1's l1: 0.150109\n",
      "[1700]\ttraining's l1: 0.0884213\tvalid_1's l1: 0.149328\n",
      "[1800]\ttraining's l1: 0.0863778\tvalid_1's l1: 0.148717\n",
      "[1900]\ttraining's l1: 0.0845721\tvalid_1's l1: 0.148164\n",
      "[2000]\ttraining's l1: 0.0827453\tvalid_1's l1: 0.147633\n",
      "[2100]\ttraining's l1: 0.0805862\tvalid_1's l1: 0.146559\n",
      "[2200]\ttraining's l1: 0.0790389\tvalid_1's l1: 0.145921\n",
      "[2300]\ttraining's l1: 0.0774994\tvalid_1's l1: 0.145385\n",
      "[2400]\ttraining's l1: 0.0761785\tvalid_1's l1: 0.144841\n",
      "[2500]\ttraining's l1: 0.0747177\tvalid_1's l1: 0.144309\n",
      "[2600]\ttraining's l1: 0.0735304\tvalid_1's l1: 0.143865\n",
      "[2700]\ttraining's l1: 0.0721312\tvalid_1's l1: 0.14341\n",
      "[2800]\ttraining's l1: 0.0709507\tvalid_1's l1: 0.142945\n",
      "[2900]\ttraining's l1: 0.0695481\tvalid_1's l1: 0.142566\n",
      "[3000]\ttraining's l1: 0.0682649\tvalid_1's l1: 0.14222\n",
      "[3100]\ttraining's l1: 0.0668666\tvalid_1's l1: 0.141863\n",
      "[3200]\ttraining's l1: 0.0655828\tvalid_1's l1: 0.141552\n",
      "[3300]\ttraining's l1: 0.0643356\tvalid_1's l1: 0.141244\n",
      "[3400]\ttraining's l1: 0.063214\tvalid_1's l1: 0.140941\n",
      "[3500]\ttraining's l1: 0.0621475\tvalid_1's l1: 0.140671\n",
      "[3600]\ttraining's l1: 0.0609801\tvalid_1's l1: 0.140387\n",
      "[3700]\ttraining's l1: 0.0599524\tvalid_1's l1: 0.140133\n",
      "[3800]\ttraining's l1: 0.0589836\tvalid_1's l1: 0.139891\n",
      "[3900]\ttraining's l1: 0.0579679\tvalid_1's l1: 0.139667\n",
      "[4000]\ttraining's l1: 0.0568904\tvalid_1's l1: 0.139426\n",
      "[4100]\ttraining's l1: 0.055503\tvalid_1's l1: 0.139021\n",
      "[4200]\ttraining's l1: 0.0541814\tvalid_1's l1: 0.138663\n",
      "[4300]\ttraining's l1: 0.0529986\tvalid_1's l1: 0.138405\n",
      "[4400]\ttraining's l1: 0.0519626\tvalid_1's l1: 0.138147\n",
      "[4500]\ttraining's l1: 0.0509959\tvalid_1's l1: 0.13795\n",
      "[4600]\ttraining's l1: 0.0500483\tvalid_1's l1: 0.137733\n",
      "[4700]\ttraining's l1: 0.0491406\tvalid_1's l1: 0.137541\n",
      "[4800]\ttraining's l1: 0.0483426\tvalid_1's l1: 0.13735\n",
      "[4900]\ttraining's l1: 0.0474703\tvalid_1's l1: 0.137159\n",
      "[5000]\ttraining's l1: 0.0466893\tvalid_1's l1: 0.137017\n",
      "[5100]\ttraining's l1: 0.045983\tvalid_1's l1: 0.136911\n",
      "[5200]\ttraining's l1: 0.0452416\tvalid_1's l1: 0.136739\n",
      "[5300]\ttraining's l1: 0.0446378\tvalid_1's l1: 0.136617\n",
      "[5400]\ttraining's l1: 0.043941\tvalid_1's l1: 0.136477\n",
      "[5500]\ttraining's l1: 0.0432993\tvalid_1's l1: 0.136346\n",
      "[5600]\ttraining's l1: 0.0427173\tvalid_1's l1: 0.13623\n",
      "[5700]\ttraining's l1: 0.042102\tvalid_1's l1: 0.136122\n",
      "[5800]\ttraining's l1: 0.041537\tvalid_1's l1: 0.136013\n",
      "[5900]\ttraining's l1: 0.0409964\tvalid_1's l1: 0.135907\n",
      "[6000]\ttraining's l1: 0.0404555\tvalid_1's l1: 0.135817\n",
      "[6100]\ttraining's l1: 0.0395554\tvalid_1's l1: 0.135581\n",
      "[6200]\ttraining's l1: 0.0388664\tvalid_1's l1: 0.135427\n",
      "[6300]\ttraining's l1: 0.0382291\tvalid_1's l1: 0.135299\n",
      "[6400]\ttraining's l1: 0.0376414\tvalid_1's l1: 0.135186\n",
      "[6500]\ttraining's l1: 0.0370601\tvalid_1's l1: 0.135079\n",
      "[6600]\ttraining's l1: 0.0365036\tvalid_1's l1: 0.134993\n",
      "[6700]\ttraining's l1: 0.0359881\tvalid_1's l1: 0.134888\n",
      "[6800]\ttraining's l1: 0.03548\tvalid_1's l1: 0.134796\n",
      "[6900]\ttraining's l1: 0.0349386\tvalid_1's l1: 0.134695\n",
      "[7000]\ttraining's l1: 0.0344173\tvalid_1's l1: 0.134623\n",
      "[7100]\ttraining's l1: 0.0339165\tvalid_1's l1: 0.134538\n",
      "[7200]\ttraining's l1: 0.0334303\tvalid_1's l1: 0.134472\n",
      "[7300]\ttraining's l1: 0.0329888\tvalid_1's l1: 0.134393\n",
      "[7400]\ttraining's l1: 0.0325603\tvalid_1's l1: 0.134325\n",
      "[7500]\ttraining's l1: 0.0321467\tvalid_1's l1: 0.13426\n",
      "[7600]\ttraining's l1: 0.0317667\tvalid_1's l1: 0.134214\n",
      "[7700]\ttraining's l1: 0.0313286\tvalid_1's l1: 0.134151\n",
      "[7800]\ttraining's l1: 0.0309289\tvalid_1's l1: 0.134081\n",
      "[7900]\ttraining's l1: 0.0305615\tvalid_1's l1: 0.134025\n",
      "[8000]\ttraining's l1: 0.0301909\tvalid_1's l1: 0.13398\n",
      "[8100]\ttraining's l1: 0.0294578\tvalid_1's l1: 0.133841\n",
      "[8200]\ttraining's l1: 0.0289379\tvalid_1's l1: 0.133735\n",
      "[8300]\ttraining's l1: 0.0284342\tvalid_1's l1: 0.133656\n",
      "[8400]\ttraining's l1: 0.0280072\tvalid_1's l1: 0.133586\n",
      "[8500]\ttraining's l1: 0.0275058\tvalid_1's l1: 0.133504\n",
      "[8600]\ttraining's l1: 0.027078\tvalid_1's l1: 0.133438\n",
      "[8700]\ttraining's l1: 0.0266906\tvalid_1's l1: 0.133389\n",
      "[8800]\ttraining's l1: 0.0262715\tvalid_1's l1: 0.133319\n",
      "[8900]\ttraining's l1: 0.0259204\tvalid_1's l1: 0.133259\n",
      "[9000]\ttraining's l1: 0.0255961\tvalid_1's l1: 0.13321\n",
      "[9100]\ttraining's l1: 0.0252745\tvalid_1's l1: 0.133162\n",
      "[9200]\ttraining's l1: 0.0249426\tvalid_1's l1: 0.133111\n",
      "[9300]\ttraining's l1: 0.0246342\tvalid_1's l1: 0.13306\n",
      "[9400]\ttraining's l1: 0.0242913\tvalid_1's l1: 0.133019\n",
      "[9500]\ttraining's l1: 0.023992\tvalid_1's l1: 0.132982\n",
      "[9600]\ttraining's l1: 0.023678\tvalid_1's l1: 0.13294\n",
      "[9700]\ttraining's l1: 0.0234224\tvalid_1's l1: 0.132908\n",
      "[9800]\ttraining's l1: 0.0231315\tvalid_1's l1: 0.132876\n",
      "[9900]\ttraining's l1: 0.0228655\tvalid_1's l1: 0.132841\n",
      "[10000]\ttraining's l1: 0.0225857\tvalid_1's l1: 0.132804\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0225857\tvalid_1's l1: 0.132804\n",
      "3JHN Fold 0, logMAE: -2.0188770657206034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.206438\tvalid_1's l1: 0.223199\n",
      "[200]\ttraining's l1: 0.173979\tvalid_1's l1: 0.197216\n",
      "[300]\ttraining's l1: 0.156746\tvalid_1's l1: 0.184868\n",
      "[400]\ttraining's l1: 0.144556\tvalid_1's l1: 0.177161\n",
      "[500]\ttraining's l1: 0.135011\tvalid_1's l1: 0.171283\n",
      "[600]\ttraining's l1: 0.127276\tvalid_1's l1: 0.167066\n",
      "[700]\ttraining's l1: 0.121147\tvalid_1's l1: 0.163921\n",
      "[800]\ttraining's l1: 0.11617\tvalid_1's l1: 0.161558\n",
      "[900]\ttraining's l1: 0.111421\tvalid_1's l1: 0.159261\n",
      "[1000]\ttraining's l1: 0.107755\tvalid_1's l1: 0.15757\n",
      "[1100]\ttraining's l1: 0.104132\tvalid_1's l1: 0.156031\n",
      "[1200]\ttraining's l1: 0.100686\tvalid_1's l1: 0.15463\n",
      "[1300]\ttraining's l1: 0.0977518\tvalid_1's l1: 0.153459\n",
      "[1400]\ttraining's l1: 0.0949924\tvalid_1's l1: 0.152415\n",
      "[1500]\ttraining's l1: 0.0924589\tvalid_1's l1: 0.151464\n",
      "[1600]\ttraining's l1: 0.0899486\tvalid_1's l1: 0.150592\n",
      "[1700]\ttraining's l1: 0.0876754\tvalid_1's l1: 0.149835\n",
      "[1800]\ttraining's l1: 0.0855855\tvalid_1's l1: 0.149145\n",
      "[1900]\ttraining's l1: 0.083624\tvalid_1's l1: 0.148482\n",
      "[2000]\ttraining's l1: 0.0819661\tvalid_1's l1: 0.14797\n",
      "[2100]\ttraining's l1: 0.079653\tvalid_1's l1: 0.146998\n",
      "[2200]\ttraining's l1: 0.0774782\tvalid_1's l1: 0.146216\n",
      "[2300]\ttraining's l1: 0.075378\tvalid_1's l1: 0.145432\n",
      "[2400]\ttraining's l1: 0.0733381\tvalid_1's l1: 0.144658\n",
      "[2500]\ttraining's l1: 0.0714365\tvalid_1's l1: 0.144029\n",
      "[2600]\ttraining's l1: 0.0698074\tvalid_1's l1: 0.143476\n",
      "[2700]\ttraining's l1: 0.0682416\tvalid_1's l1: 0.143026\n",
      "[2800]\ttraining's l1: 0.0665157\tvalid_1's l1: 0.142494\n",
      "[2900]\ttraining's l1: 0.0649999\tvalid_1's l1: 0.142033\n",
      "[3000]\ttraining's l1: 0.0635899\tvalid_1's l1: 0.14167\n",
      "[3100]\ttraining's l1: 0.0621547\tvalid_1's l1: 0.141267\n",
      "[3200]\ttraining's l1: 0.0608609\tvalid_1's l1: 0.140903\n",
      "[3300]\ttraining's l1: 0.0597494\tvalid_1's l1: 0.140618\n",
      "[3400]\ttraining's l1: 0.0585584\tvalid_1's l1: 0.140292\n",
      "[3500]\ttraining's l1: 0.0575122\tvalid_1's l1: 0.140045\n",
      "[3600]\ttraining's l1: 0.0564955\tvalid_1's l1: 0.139815\n",
      "[3700]\ttraining's l1: 0.0553924\tvalid_1's l1: 0.139545\n",
      "[3800]\ttraining's l1: 0.0543982\tvalid_1's l1: 0.139304\n",
      "[3900]\ttraining's l1: 0.0533709\tvalid_1's l1: 0.139082\n",
      "[4000]\ttraining's l1: 0.0524947\tvalid_1's l1: 0.138886\n",
      "[4100]\ttraining's l1: 0.0517333\tvalid_1's l1: 0.138652\n",
      "[4200]\ttraining's l1: 0.0511429\tvalid_1's l1: 0.138518\n",
      "[4300]\ttraining's l1: 0.0505897\tvalid_1's l1: 0.138406\n",
      "[4400]\ttraining's l1: 0.0500772\tvalid_1's l1: 0.138262\n",
      "[4500]\ttraining's l1: 0.0496141\tvalid_1's l1: 0.138161\n",
      "[4600]\ttraining's l1: 0.0490913\tvalid_1's l1: 0.138027\n",
      "[4700]\ttraining's l1: 0.0485908\tvalid_1's l1: 0.137917\n",
      "[4800]\ttraining's l1: 0.0481088\tvalid_1's l1: 0.137809\n",
      "[4900]\ttraining's l1: 0.0476483\tvalid_1's l1: 0.137704\n",
      "[5000]\ttraining's l1: 0.0472142\tvalid_1's l1: 0.137625\n",
      "[5100]\ttraining's l1: 0.0467644\tvalid_1's l1: 0.137536\n",
      "[5200]\ttraining's l1: 0.0463321\tvalid_1's l1: 0.137462\n",
      "[5300]\ttraining's l1: 0.0458952\tvalid_1's l1: 0.137351\n",
      "[5400]\ttraining's l1: 0.0454853\tvalid_1's l1: 0.137268\n",
      "[5500]\ttraining's l1: 0.0450428\tvalid_1's l1: 0.13717\n",
      "[5600]\ttraining's l1: 0.0446116\tvalid_1's l1: 0.137085\n",
      "[5700]\ttraining's l1: 0.0442544\tvalid_1's l1: 0.137003\n",
      "[5800]\ttraining's l1: 0.0438624\tvalid_1's l1: 0.136913\n",
      "[5900]\ttraining's l1: 0.0434597\tvalid_1's l1: 0.136823\n",
      "[6000]\ttraining's l1: 0.0430838\tvalid_1's l1: 0.136755\n",
      "[6100]\ttraining's l1: 0.0420236\tvalid_1's l1: 0.136499\n",
      "[6200]\ttraining's l1: 0.0412042\tvalid_1's l1: 0.13631\n",
      "[6300]\ttraining's l1: 0.0403753\tvalid_1's l1: 0.136138\n",
      "[6400]\ttraining's l1: 0.0395978\tvalid_1's l1: 0.135988\n",
      "[6500]\ttraining's l1: 0.0388294\tvalid_1's l1: 0.135871\n",
      "[6600]\ttraining's l1: 0.0381115\tvalid_1's l1: 0.135737\n",
      "[6700]\ttraining's l1: 0.0374456\tvalid_1's l1: 0.135606\n",
      "[6800]\ttraining's l1: 0.0368746\tvalid_1's l1: 0.13549\n",
      "[6900]\ttraining's l1: 0.0362311\tvalid_1's l1: 0.135375\n",
      "[7000]\ttraining's l1: 0.0356131\tvalid_1's l1: 0.135268\n",
      "[7100]\ttraining's l1: 0.035038\tvalid_1's l1: 0.135173\n",
      "[7200]\ttraining's l1: 0.0345265\tvalid_1's l1: 0.135096\n",
      "[7300]\ttraining's l1: 0.0340282\tvalid_1's l1: 0.134996\n",
      "[7400]\ttraining's l1: 0.0335183\tvalid_1's l1: 0.13491\n",
      "[7500]\ttraining's l1: 0.0330529\tvalid_1's l1: 0.134828\n",
      "[7600]\ttraining's l1: 0.0326401\tvalid_1's l1: 0.134763\n",
      "[7700]\ttraining's l1: 0.0321772\tvalid_1's l1: 0.134687\n",
      "[7800]\ttraining's l1: 0.0317378\tvalid_1's l1: 0.134631\n",
      "[7900]\ttraining's l1: 0.0313449\tvalid_1's l1: 0.134573\n",
      "[8000]\ttraining's l1: 0.0309344\tvalid_1's l1: 0.134522\n",
      "[8100]\ttraining's l1: 0.0301758\tvalid_1's l1: 0.134323\n",
      "[8200]\ttraining's l1: 0.0296223\tvalid_1's l1: 0.134173\n",
      "[8300]\ttraining's l1: 0.0292176\tvalid_1's l1: 0.134075\n",
      "[8400]\ttraining's l1: 0.0287377\tvalid_1's l1: 0.133978\n",
      "[8500]\ttraining's l1: 0.0282734\tvalid_1's l1: 0.13389\n",
      "[8600]\ttraining's l1: 0.027835\tvalid_1's l1: 0.133811\n",
      "[8700]\ttraining's l1: 0.0274413\tvalid_1's l1: 0.133745\n",
      "[8800]\ttraining's l1: 0.0270707\tvalid_1's l1: 0.133683\n",
      "[8900]\ttraining's l1: 0.0266563\tvalid_1's l1: 0.133597\n",
      "[9000]\ttraining's l1: 0.026267\tvalid_1's l1: 0.133534\n",
      "[9100]\ttraining's l1: 0.0259466\tvalid_1's l1: 0.133476\n",
      "[9200]\ttraining's l1: 0.0256206\tvalid_1's l1: 0.133425\n",
      "[9300]\ttraining's l1: 0.0252882\tvalid_1's l1: 0.133382\n",
      "[9400]\ttraining's l1: 0.024953\tvalid_1's l1: 0.13334\n",
      "[9500]\ttraining's l1: 0.024635\tvalid_1's l1: 0.133298\n",
      "[9600]\ttraining's l1: 0.024315\tvalid_1's l1: 0.133262\n",
      "[9700]\ttraining's l1: 0.0240194\tvalid_1's l1: 0.133223\n",
      "[9800]\ttraining's l1: 0.023723\tvalid_1's l1: 0.133178\n",
      "[9900]\ttraining's l1: 0.0234487\tvalid_1's l1: 0.133143\n",
      "[10000]\ttraining's l1: 0.0231877\tvalid_1's l1: 0.133114\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0231877\tvalid_1's l1: 0.133114\n",
      "3JHN Fold 1, logMAE: -2.016552399273031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramFiles\\Anaconda\\lib\\site-packages\\lightgbm\\basic.py:1209: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['atom_10', 'atom_11', 'atom_12', 'atom_13', 'atom_14', 'atom_2', 'atom_3', 'atom_4', 'atom_5', 'atom_6', 'atom_7', 'atom_8', 'atom_9']\n",
      "  'New categorical_feature is {}'.format(sorted(list(categorical_feature))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 1000 rounds.\n",
      "[100]\ttraining's l1: 0.208494\tvalid_1's l1: 0.225044\n",
      "[200]\ttraining's l1: 0.17427\tvalid_1's l1: 0.197542\n",
      "[300]\ttraining's l1: 0.156468\tvalid_1's l1: 0.184948\n",
      "[400]\ttraining's l1: 0.144543\tvalid_1's l1: 0.177156\n",
      "[500]\ttraining's l1: 0.135386\tvalid_1's l1: 0.17173\n",
      "[600]\ttraining's l1: 0.128244\tvalid_1's l1: 0.16766\n",
      "[700]\ttraining's l1: 0.122258\tvalid_1's l1: 0.164432\n",
      "[800]\ttraining's l1: 0.116776\tvalid_1's l1: 0.161554\n",
      "[900]\ttraining's l1: 0.111553\tvalid_1's l1: 0.159081\n",
      "[1000]\ttraining's l1: 0.10724\tvalid_1's l1: 0.157011\n",
      "[1100]\ttraining's l1: 0.103363\tvalid_1's l1: 0.155376\n",
      "[1200]\ttraining's l1: 0.100088\tvalid_1's l1: 0.154038\n",
      "[1300]\ttraining's l1: 0.096911\tvalid_1's l1: 0.15281\n",
      "[1400]\ttraining's l1: 0.0941978\tvalid_1's l1: 0.15178\n",
      "[1500]\ttraining's l1: 0.0917038\tvalid_1's l1: 0.150837\n",
      "[1600]\ttraining's l1: 0.0893208\tvalid_1's l1: 0.14995\n",
      "[1700]\ttraining's l1: 0.0869548\tvalid_1's l1: 0.149184\n",
      "[1800]\ttraining's l1: 0.0850566\tvalid_1's l1: 0.148588\n",
      "[1900]\ttraining's l1: 0.0830485\tvalid_1's l1: 0.147992\n",
      "[2000]\ttraining's l1: 0.0812361\tvalid_1's l1: 0.147488\n",
      "[2100]\ttraining's l1: 0.0785374\tvalid_1's l1: 0.146431\n",
      "[2200]\ttraining's l1: 0.0762739\tvalid_1's l1: 0.145487\n",
      "[2300]\ttraining's l1: 0.0742292\tvalid_1's l1: 0.144743\n",
      "[2400]\ttraining's l1: 0.0724196\tvalid_1's l1: 0.144052\n",
      "[2500]\ttraining's l1: 0.070499\tvalid_1's l1: 0.143381\n",
      "[2600]\ttraining's l1: 0.068702\tvalid_1's l1: 0.142749\n",
      "[2700]\ttraining's l1: 0.0669781\tvalid_1's l1: 0.142285\n",
      "[2800]\ttraining's l1: 0.0652888\tvalid_1's l1: 0.141806\n",
      "[2900]\ttraining's l1: 0.0638832\tvalid_1's l1: 0.141365\n",
      "[3000]\ttraining's l1: 0.0623573\tvalid_1's l1: 0.140963\n",
      "[3100]\ttraining's l1: 0.0610086\tvalid_1's l1: 0.140606\n",
      "[3200]\ttraining's l1: 0.0596675\tvalid_1's l1: 0.140237\n",
      "[3300]\ttraining's l1: 0.0584916\tvalid_1's l1: 0.139928\n",
      "[3400]\ttraining's l1: 0.0573755\tvalid_1's l1: 0.139607\n",
      "[3500]\ttraining's l1: 0.0563684\tvalid_1's l1: 0.13938\n",
      "[3600]\ttraining's l1: 0.055213\tvalid_1's l1: 0.139107\n",
      "[3700]\ttraining's l1: 0.0541912\tvalid_1's l1: 0.13885\n",
      "[3800]\ttraining's l1: 0.0531933\tvalid_1's l1: 0.13864\n",
      "[3900]\ttraining's l1: 0.0523855\tvalid_1's l1: 0.13847\n",
      "[4000]\ttraining's l1: 0.0515342\tvalid_1's l1: 0.138293\n",
      "[4100]\ttraining's l1: 0.0502075\tvalid_1's l1: 0.137796\n",
      "[4200]\ttraining's l1: 0.0492199\tvalid_1's l1: 0.137492\n",
      "[4300]\ttraining's l1: 0.0483374\tvalid_1's l1: 0.137273\n",
      "[4400]\ttraining's l1: 0.0474572\tvalid_1's l1: 0.137087\n",
      "[4500]\ttraining's l1: 0.0466116\tvalid_1's l1: 0.136894\n",
      "[4600]\ttraining's l1: 0.045799\tvalid_1's l1: 0.136742\n",
      "[4700]\ttraining's l1: 0.0449455\tvalid_1's l1: 0.136547\n",
      "[4800]\ttraining's l1: 0.0442353\tvalid_1's l1: 0.136374\n",
      "[4900]\ttraining's l1: 0.0435024\tvalid_1's l1: 0.136241\n",
      "[5000]\ttraining's l1: 0.0428785\tvalid_1's l1: 0.136086\n",
      "[5100]\ttraining's l1: 0.042245\tvalid_1's l1: 0.135982\n",
      "[5200]\ttraining's l1: 0.0416328\tvalid_1's l1: 0.135846\n",
      "[5300]\ttraining's l1: 0.0409445\tvalid_1's l1: 0.135709\n",
      "[5400]\ttraining's l1: 0.0403603\tvalid_1's l1: 0.135615\n",
      "[5500]\ttraining's l1: 0.0398338\tvalid_1's l1: 0.135523\n",
      "[5600]\ttraining's l1: 0.0393504\tvalid_1's l1: 0.135453\n",
      "[5700]\ttraining's l1: 0.0388293\tvalid_1's l1: 0.13535\n",
      "[5800]\ttraining's l1: 0.0382674\tvalid_1's l1: 0.135265\n",
      "[5900]\ttraining's l1: 0.0377374\tvalid_1's l1: 0.135185\n",
      "[6000]\ttraining's l1: 0.0373011\tvalid_1's l1: 0.135111\n",
      "[6100]\ttraining's l1: 0.0364143\tvalid_1's l1: 0.134921\n",
      "[6200]\ttraining's l1: 0.0356933\tvalid_1's l1: 0.134782\n",
      "[6300]\ttraining's l1: 0.0349918\tvalid_1's l1: 0.134654\n",
      "[6400]\ttraining's l1: 0.0343626\tvalid_1's l1: 0.13454\n",
      "[6500]\ttraining's l1: 0.0337553\tvalid_1's l1: 0.134436\n",
      "[6600]\ttraining's l1: 0.033202\tvalid_1's l1: 0.13434\n",
      "[6700]\ttraining's l1: 0.0326617\tvalid_1's l1: 0.134261\n",
      "[6800]\ttraining's l1: 0.0321661\tvalid_1's l1: 0.134186\n",
      "[6900]\ttraining's l1: 0.0316702\tvalid_1's l1: 0.134096\n",
      "[7000]\ttraining's l1: 0.0312202\tvalid_1's l1: 0.134032\n",
      "[7100]\ttraining's l1: 0.0307453\tvalid_1's l1: 0.133963\n",
      "[7200]\ttraining's l1: 0.030364\tvalid_1's l1: 0.133904\n",
      "[7300]\ttraining's l1: 0.0299522\tvalid_1's l1: 0.133843\n",
      "[7400]\ttraining's l1: 0.029547\tvalid_1's l1: 0.133784\n",
      "[7500]\ttraining's l1: 0.0291356\tvalid_1's l1: 0.133718\n",
      "[7600]\ttraining's l1: 0.0287619\tvalid_1's l1: 0.133677\n",
      "[7700]\ttraining's l1: 0.0283953\tvalid_1's l1: 0.133629\n",
      "[7800]\ttraining's l1: 0.0280403\tvalid_1's l1: 0.133573\n",
      "[7900]\ttraining's l1: 0.027677\tvalid_1's l1: 0.133527\n",
      "[8000]\ttraining's l1: 0.0273834\tvalid_1's l1: 0.133481\n",
      "[8100]\ttraining's l1: 0.0267961\tvalid_1's l1: 0.133361\n",
      "[8200]\ttraining's l1: 0.0263519\tvalid_1's l1: 0.133261\n",
      "[8300]\ttraining's l1: 0.0259143\tvalid_1's l1: 0.133178\n",
      "[8400]\ttraining's l1: 0.025527\tvalid_1's l1: 0.133112\n",
      "[8500]\ttraining's l1: 0.0251665\tvalid_1's l1: 0.133062\n",
      "[8600]\ttraining's l1: 0.0248018\tvalid_1's l1: 0.132996\n",
      "[8700]\ttraining's l1: 0.0244249\tvalid_1's l1: 0.132946\n",
      "[8800]\ttraining's l1: 0.0241005\tvalid_1's l1: 0.132895\n",
      "[8900]\ttraining's l1: 0.0237653\tvalid_1's l1: 0.13285\n",
      "[9000]\ttraining's l1: 0.0234731\tvalid_1's l1: 0.132813\n",
      "[9100]\ttraining's l1: 0.0231701\tvalid_1's l1: 0.132779\n",
      "[9200]\ttraining's l1: 0.0228638\tvalid_1's l1: 0.132738\n",
      "[9300]\ttraining's l1: 0.022585\tvalid_1's l1: 0.132704\n",
      "[9400]\ttraining's l1: 0.0222943\tvalid_1's l1: 0.132668\n",
      "[9500]\ttraining's l1: 0.0220113\tvalid_1's l1: 0.132633\n",
      "[9600]\ttraining's l1: 0.0217731\tvalid_1's l1: 0.1326\n",
      "[9700]\ttraining's l1: 0.0215311\tvalid_1's l1: 0.132585\n",
      "[9800]\ttraining's l1: 0.0212768\tvalid_1's l1: 0.132564\n",
      "[9900]\ttraining's l1: 0.0210248\tvalid_1's l1: 0.132525\n",
      "[10000]\ttraining's l1: 0.0207858\tvalid_1's l1: 0.132503\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[10000]\ttraining's l1: 0.0207858\tvalid_1's l1: 0.132503\n",
      "3JHN Fold 2, logMAE: -2.021146734305482\n"
     ]
    }
   ],
   "source": [
    "N_FOLDS = 3\n",
    "submission = submission_csv.copy()\n",
    "\n",
    "cv_scores = {}\n",
    "for coupling_type in model_params.keys():\n",
    "    cv_score = train_and_predict_for_one_coupling_type(\n",
    "        coupling_type, submission, n_atoms=model_params[coupling_type], n_folds=N_FOLDS)\n",
    "    cv_scores[coupling_type] = cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>cv_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1JHN</td>\n",
       "      <td>-0.837573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1JHC</td>\n",
       "      <td>-0.312970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2JHH</td>\n",
       "      <td>-1.751563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2JHN</td>\n",
       "      <td>-1.828418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2JHC</td>\n",
       "      <td>-1.275723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3JHH</td>\n",
       "      <td>-1.839542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3JHC</td>\n",
       "      <td>-1.225006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3JHN</td>\n",
       "      <td>-2.018859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  cv_score\n",
       "0  1JHN -0.837573\n",
       "1  1JHC -0.312970\n",
       "2  2JHH -1.751563\n",
       "3  2JHN -1.828418\n",
       "4  2JHC -1.275723\n",
       "5  3JHH -1.839542\n",
       "6  3JHC -1.225006\n",
       "7  3JHN -2.018859"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'type': list(cv_scores.keys()), 'cv_score': list(cv_scores.values())})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And cv mean score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.3862067347999287"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(cv_scores.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check for all cells to be filled with predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[submission['scalar_coupling_constant'] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scalar_coupling_constant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4658147</th>\n",
       "      <td>13.625594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658148</th>\n",
       "      <td>183.647156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658149</th>\n",
       "      <td>-0.077270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658150</th>\n",
       "      <td>183.647156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658151</th>\n",
       "      <td>13.625594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658152</th>\n",
       "      <td>91.264854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658153</th>\n",
       "      <td>2.290939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658154</th>\n",
       "      <td>-7.328668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658155</th>\n",
       "      <td>-9.696672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4658156</th>\n",
       "      <td>91.373657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         scalar_coupling_constant\n",
       "id                               \n",
       "4658147  13.625594               \n",
       "4658148  183.647156              \n",
       "4658149 -0.077270                \n",
       "4658150  183.647156              \n",
       "4658151  13.625594               \n",
       "4658152  91.264854               \n",
       "4658153  2.290939                \n",
       "4658154 -7.328668                \n",
       "4658155 -9.696672                \n",
       "4658156  91.373657               "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(f'{SUBMISSIONS_PATH}/submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 629.99978,
   "position": {
    "height": "40px",
    "left": "1388px",
    "right": "20px",
    "top": "8px",
    "width": "515.99px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
